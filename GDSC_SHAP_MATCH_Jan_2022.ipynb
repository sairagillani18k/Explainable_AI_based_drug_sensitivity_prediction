{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GDSC_SHAP_MATCH_Jan_2022.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nUKnNK5yijh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HWrCH3Oz7q0",
        "outputId": "bc12ceef-6984-4bf8-f172-7f043ff70000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvVgNYe30mP1",
        "outputId": "5b3f9bc8-6712-45fb-eaca-074879d9f782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  topmer.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "PV45jIaS3hm0",
        "outputId": "0a218907-2d0c-4016-edd2-089fb54a3068"
      },
      "source": [
        "#df = pd.read_csv('/content/drive/MyDrive/Thesis2_Dec2021/data_genes/GeneExpression_sourcefile.csv')\n",
        "#del df[\"Unnamed: 0\"]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdc7ac8d-a3a8-468d-9596-a057239a0599\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>ENSG00000000003</th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000460</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>ENSG00000001167</th>\n",
              "      <th>ENSG00000001460</th>\n",
              "      <th>ENSG00000001461</th>\n",
              "      <th>ENSG00000001497</th>\n",
              "      <th>ENSG00000001561</th>\n",
              "      <th>ENSG00000001617</th>\n",
              "      <th>ENSG00000001626</th>\n",
              "      <th>ENSG00000001629</th>\n",
              "      <th>ENSG00000001631</th>\n",
              "      <th>ENSG00000002016</th>\n",
              "      <th>ENSG00000002330</th>\n",
              "      <th>ENSG00000002549</th>\n",
              "      <th>ENSG00000002586</th>\n",
              "      <th>ENSG00000002587</th>\n",
              "      <th>ENSG00000002726</th>\n",
              "      <th>ENSG00000002745</th>\n",
              "      <th>ENSG00000002746</th>\n",
              "      <th>ENSG00000002822</th>\n",
              "      <th>ENSG00000002834</th>\n",
              "      <th>ENSG00000002919</th>\n",
              "      <th>ENSG00000002933</th>\n",
              "      <th>ENSG00000003056</th>\n",
              "      <th>ENSG00000003096</th>\n",
              "      <th>ENSG00000003137</th>\n",
              "      <th>ENSG00000003147</th>\n",
              "      <th>ENSG00000003249</th>\n",
              "      <th>ENSG00000003393</th>\n",
              "      <th>ENSG00000003400</th>\n",
              "      <th>ENSG00000003402</th>\n",
              "      <th>ENSG00000003436</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000260347</th>\n",
              "      <th>ENSG00000260359</th>\n",
              "      <th>ENSG00000260432</th>\n",
              "      <th>ENSG00000260461</th>\n",
              "      <th>ENSG00000260495</th>\n",
              "      <th>ENSG00000260539</th>\n",
              "      <th>ENSG00000260612</th>\n",
              "      <th>ENSG00000260880</th>\n",
              "      <th>ENSG00000261215</th>\n",
              "      <th>ENSG00000261253</th>\n",
              "      <th>ENSG00000261351</th>\n",
              "      <th>ENSG00000261434</th>\n",
              "      <th>ENSG00000261452</th>\n",
              "      <th>ENSG00000261649</th>\n",
              "      <th>ENSG00000261685</th>\n",
              "      <th>ENSG00000261701</th>\n",
              "      <th>ENSG00000261742</th>\n",
              "      <th>ENSG00000261803</th>\n",
              "      <th>ENSG00000261819</th>\n",
              "      <th>ENSG00000261857</th>\n",
              "      <th>ENSG00000261925</th>\n",
              "      <th>ENSG00000262152</th>\n",
              "      <th>ENSG00000262557</th>\n",
              "      <th>ENSG00000262628</th>\n",
              "      <th>ENSG00000263002</th>\n",
              "      <th>ENSG00000263417</th>\n",
              "      <th>ENSG00000263574</th>\n",
              "      <th>ENSG00000263843</th>\n",
              "      <th>ENSG00000264247</th>\n",
              "      <th>ENSG00000264424</th>\n",
              "      <th>ENSG00000264575</th>\n",
              "      <th>ENSG00000265060</th>\n",
              "      <th>ENSG00000265246</th>\n",
              "      <th>ENSG00000265298</th>\n",
              "      <th>ENSG00000265480</th>\n",
              "      <th>ENSG00000265929</th>\n",
              "      <th>ENSG00000266066</th>\n",
              "      <th>ENSG00000266282</th>\n",
              "      <th>ENSG00000266433</th>\n",
              "      <th>ENSG00000266753</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>906826</td>\n",
              "      <td>7.632023</td>\n",
              "      <td>2.964585</td>\n",
              "      <td>10.379553</td>\n",
              "      <td>3.614794</td>\n",
              "      <td>3.380681</td>\n",
              "      <td>3.324692</td>\n",
              "      <td>3.566350</td>\n",
              "      <td>8.204530</td>\n",
              "      <td>5.235118</td>\n",
              "      <td>5.369039</td>\n",
              "      <td>3.596993</td>\n",
              "      <td>7.641756</td>\n",
              "      <td>4.549065</td>\n",
              "      <td>4.488261</td>\n",
              "      <td>4.118309</td>\n",
              "      <td>3.024970</td>\n",
              "      <td>8.296444</td>\n",
              "      <td>3.646615</td>\n",
              "      <td>3.780467</td>\n",
              "      <td>7.458409</td>\n",
              "      <td>6.453926</td>\n",
              "      <td>9.460478</td>\n",
              "      <td>3.517445</td>\n",
              "      <td>3.350498</td>\n",
              "      <td>3.741032</td>\n",
              "      <td>2.661393</td>\n",
              "      <td>5.200431</td>\n",
              "      <td>4.931681</td>\n",
              "      <td>4.767457</td>\n",
              "      <td>2.975821</td>\n",
              "      <td>9.792014</td>\n",
              "      <td>6.213763</td>\n",
              "      <td>3.440152</td>\n",
              "      <td>4.075371</td>\n",
              "      <td>3.689651</td>\n",
              "      <td>3.947773</td>\n",
              "      <td>2.831262</td>\n",
              "      <td>5.463531</td>\n",
              "      <td>12.091616</td>\n",
              "      <td>...</td>\n",
              "      <td>3.183110</td>\n",
              "      <td>4.633899</td>\n",
              "      <td>3.077504</td>\n",
              "      <td>3.019080</td>\n",
              "      <td>3.081601</td>\n",
              "      <td>5.945066</td>\n",
              "      <td>2.939461</td>\n",
              "      <td>2.927571</td>\n",
              "      <td>2.991526</td>\n",
              "      <td>2.906636</td>\n",
              "      <td>3.901483</td>\n",
              "      <td>3.435723</td>\n",
              "      <td>3.051134</td>\n",
              "      <td>3.529562</td>\n",
              "      <td>3.030229</td>\n",
              "      <td>2.790461</td>\n",
              "      <td>2.801037</td>\n",
              "      <td>3.178122</td>\n",
              "      <td>6.975354</td>\n",
              "      <td>3.588889</td>\n",
              "      <td>3.029979</td>\n",
              "      <td>3.665788</td>\n",
              "      <td>3.389938</td>\n",
              "      <td>3.134197</td>\n",
              "      <td>4.841169</td>\n",
              "      <td>3.005416</td>\n",
              "      <td>2.939461</td>\n",
              "      <td>4.059000</td>\n",
              "      <td>3.411250</td>\n",
              "      <td>2.628932</td>\n",
              "      <td>6.786925</td>\n",
              "      <td>2.997054</td>\n",
              "      <td>3.109774</td>\n",
              "      <td>7.882377</td>\n",
              "      <td>3.331134</td>\n",
              "      <td>2.852537</td>\n",
              "      <td>3.130696</td>\n",
              "      <td>9.986616</td>\n",
              "      <td>3.073724</td>\n",
              "      <td>7.284733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>687983</td>\n",
              "      <td>7.548671</td>\n",
              "      <td>2.777716</td>\n",
              "      <td>11.807341</td>\n",
              "      <td>4.066887</td>\n",
              "      <td>3.732485</td>\n",
              "      <td>3.152404</td>\n",
              "      <td>7.827172</td>\n",
              "      <td>6.616972</td>\n",
              "      <td>5.809264</td>\n",
              "      <td>7.209653</td>\n",
              "      <td>3.753548</td>\n",
              "      <td>5.715404</td>\n",
              "      <td>4.306627</td>\n",
              "      <td>6.030564</td>\n",
              "      <td>3.951478</td>\n",
              "      <td>3.123943</td>\n",
              "      <td>8.313609</td>\n",
              "      <td>3.858846</td>\n",
              "      <td>3.921778</td>\n",
              "      <td>7.479327</td>\n",
              "      <td>6.742826</td>\n",
              "      <td>9.474606</td>\n",
              "      <td>3.044297</td>\n",
              "      <td>3.210050</td>\n",
              "      <td>2.729453</td>\n",
              "      <td>2.788262</td>\n",
              "      <td>6.139840</td>\n",
              "      <td>4.525647</td>\n",
              "      <td>5.246301</td>\n",
              "      <td>3.035024</td>\n",
              "      <td>8.845537</td>\n",
              "      <td>3.241823</td>\n",
              "      <td>3.073604</td>\n",
              "      <td>4.547098</td>\n",
              "      <td>4.062049</td>\n",
              "      <td>4.017758</td>\n",
              "      <td>2.788942</td>\n",
              "      <td>4.662621</td>\n",
              "      <td>3.470365</td>\n",
              "      <td>...</td>\n",
              "      <td>4.343442</td>\n",
              "      <td>2.618501</td>\n",
              "      <td>2.879343</td>\n",
              "      <td>3.331508</td>\n",
              "      <td>3.285192</td>\n",
              "      <td>6.798999</td>\n",
              "      <td>3.027941</td>\n",
              "      <td>3.191654</td>\n",
              "      <td>2.962621</td>\n",
              "      <td>3.074109</td>\n",
              "      <td>4.923347</td>\n",
              "      <td>3.345257</td>\n",
              "      <td>7.026350</td>\n",
              "      <td>3.599434</td>\n",
              "      <td>3.132953</td>\n",
              "      <td>2.778059</td>\n",
              "      <td>2.861326</td>\n",
              "      <td>2.996229</td>\n",
              "      <td>8.721021</td>\n",
              "      <td>3.419746</td>\n",
              "      <td>3.118254</td>\n",
              "      <td>3.053174</td>\n",
              "      <td>3.577202</td>\n",
              "      <td>3.327528</td>\n",
              "      <td>4.570476</td>\n",
              "      <td>2.878796</td>\n",
              "      <td>3.003163</td>\n",
              "      <td>3.572520</td>\n",
              "      <td>3.586613</td>\n",
              "      <td>2.783441</td>\n",
              "      <td>5.317911</td>\n",
              "      <td>3.263745</td>\n",
              "      <td>3.059424</td>\n",
              "      <td>8.681302</td>\n",
              "      <td>2.992611</td>\n",
              "      <td>2.776771</td>\n",
              "      <td>3.260982</td>\n",
              "      <td>9.002814</td>\n",
              "      <td>3.000182</td>\n",
              "      <td>8.504804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>910927</td>\n",
              "      <td>8.712338</td>\n",
              "      <td>2.643508</td>\n",
              "      <td>9.880733</td>\n",
              "      <td>3.956230</td>\n",
              "      <td>3.236620</td>\n",
              "      <td>3.241246</td>\n",
              "      <td>2.931034</td>\n",
              "      <td>8.191246</td>\n",
              "      <td>5.426841</td>\n",
              "      <td>5.120747</td>\n",
              "      <td>3.946064</td>\n",
              "      <td>5.601235</td>\n",
              "      <td>3.832190</td>\n",
              "      <td>4.548564</td>\n",
              "      <td>4.440084</td>\n",
              "      <td>2.896733</td>\n",
              "      <td>7.938611</td>\n",
              "      <td>3.811614</td>\n",
              "      <td>3.597864</td>\n",
              "      <td>7.419672</td>\n",
              "      <td>5.655691</td>\n",
              "      <td>10.011329</td>\n",
              "      <td>3.924394</td>\n",
              "      <td>3.215727</td>\n",
              "      <td>2.699162</td>\n",
              "      <td>2.902831</td>\n",
              "      <td>5.393870</td>\n",
              "      <td>4.145480</td>\n",
              "      <td>4.645800</td>\n",
              "      <td>2.846260</td>\n",
              "      <td>8.868636</td>\n",
              "      <td>3.054858</td>\n",
              "      <td>3.082341</td>\n",
              "      <td>3.032266</td>\n",
              "      <td>4.007929</td>\n",
              "      <td>3.784884</td>\n",
              "      <td>3.191751</td>\n",
              "      <td>5.519212</td>\n",
              "      <td>10.236172</td>\n",
              "      <td>...</td>\n",
              "      <td>3.160929</td>\n",
              "      <td>2.966000</td>\n",
              "      <td>2.979303</td>\n",
              "      <td>3.338575</td>\n",
              "      <td>3.036464</td>\n",
              "      <td>7.318819</td>\n",
              "      <td>2.984301</td>\n",
              "      <td>3.278479</td>\n",
              "      <td>3.255958</td>\n",
              "      <td>2.964270</td>\n",
              "      <td>3.883598</td>\n",
              "      <td>3.154062</td>\n",
              "      <td>7.501269</td>\n",
              "      <td>3.347474</td>\n",
              "      <td>2.752734</td>\n",
              "      <td>2.661848</td>\n",
              "      <td>2.718044</td>\n",
              "      <td>2.828840</td>\n",
              "      <td>8.304669</td>\n",
              "      <td>3.449147</td>\n",
              "      <td>2.775777</td>\n",
              "      <td>3.226808</td>\n",
              "      <td>3.384858</td>\n",
              "      <td>3.326309</td>\n",
              "      <td>4.214729</td>\n",
              "      <td>2.985562</td>\n",
              "      <td>3.083179</td>\n",
              "      <td>3.482183</td>\n",
              "      <td>3.725436</td>\n",
              "      <td>2.603604</td>\n",
              "      <td>3.143006</td>\n",
              "      <td>3.112145</td>\n",
              "      <td>2.930254</td>\n",
              "      <td>8.707886</td>\n",
              "      <td>2.886574</td>\n",
              "      <td>2.685307</td>\n",
              "      <td>3.176239</td>\n",
              "      <td>9.113243</td>\n",
              "      <td>2.916274</td>\n",
              "      <td>7.059092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1240138</td>\n",
              "      <td>7.797142</td>\n",
              "      <td>2.817923</td>\n",
              "      <td>9.883471</td>\n",
              "      <td>4.063701</td>\n",
              "      <td>3.558414</td>\n",
              "      <td>3.101247</td>\n",
              "      <td>7.211707</td>\n",
              "      <td>8.630643</td>\n",
              "      <td>5.617714</td>\n",
              "      <td>4.996434</td>\n",
              "      <td>3.378736</td>\n",
              "      <td>6.752791</td>\n",
              "      <td>3.512547</td>\n",
              "      <td>5.309896</td>\n",
              "      <td>4.210272</td>\n",
              "      <td>2.950093</td>\n",
              "      <td>7.231354</td>\n",
              "      <td>3.772951</td>\n",
              "      <td>3.220164</td>\n",
              "      <td>7.731137</td>\n",
              "      <td>5.259367</td>\n",
              "      <td>8.173147</td>\n",
              "      <td>2.957085</td>\n",
              "      <td>3.396187</td>\n",
              "      <td>2.732190</td>\n",
              "      <td>3.000899</td>\n",
              "      <td>5.447174</td>\n",
              "      <td>4.971736</td>\n",
              "      <td>4.558836</td>\n",
              "      <td>2.965398</td>\n",
              "      <td>8.974729</td>\n",
              "      <td>3.349643</td>\n",
              "      <td>3.431314</td>\n",
              "      <td>7.487131</td>\n",
              "      <td>3.577693</td>\n",
              "      <td>3.898134</td>\n",
              "      <td>3.110345</td>\n",
              "      <td>6.322941</td>\n",
              "      <td>7.625778</td>\n",
              "      <td>...</td>\n",
              "      <td>3.079667</td>\n",
              "      <td>4.609837</td>\n",
              "      <td>3.699916</td>\n",
              "      <td>3.426935</td>\n",
              "      <td>3.153041</td>\n",
              "      <td>5.597614</td>\n",
              "      <td>3.145512</td>\n",
              "      <td>2.816586</td>\n",
              "      <td>3.107612</td>\n",
              "      <td>2.875945</td>\n",
              "      <td>4.028170</td>\n",
              "      <td>3.184647</td>\n",
              "      <td>6.743810</td>\n",
              "      <td>4.000042</td>\n",
              "      <td>2.934522</td>\n",
              "      <td>2.690589</td>\n",
              "      <td>2.757298</td>\n",
              "      <td>2.935488</td>\n",
              "      <td>7.776016</td>\n",
              "      <td>3.349624</td>\n",
              "      <td>2.927550</td>\n",
              "      <td>3.110801</td>\n",
              "      <td>2.771725</td>\n",
              "      <td>2.921903</td>\n",
              "      <td>4.060761</td>\n",
              "      <td>3.054339</td>\n",
              "      <td>2.932036</td>\n",
              "      <td>3.722306</td>\n",
              "      <td>2.996834</td>\n",
              "      <td>2.619540</td>\n",
              "      <td>3.153896</td>\n",
              "      <td>3.151576</td>\n",
              "      <td>2.850726</td>\n",
              "      <td>7.872535</td>\n",
              "      <td>3.812119</td>\n",
              "      <td>3.436412</td>\n",
              "      <td>3.074432</td>\n",
              "      <td>9.958284</td>\n",
              "      <td>3.256500</td>\n",
              "      <td>7.318125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1240139</td>\n",
              "      <td>7.729268</td>\n",
              "      <td>2.957739</td>\n",
              "      <td>10.418840</td>\n",
              "      <td>4.341500</td>\n",
              "      <td>3.840373</td>\n",
              "      <td>3.001802</td>\n",
              "      <td>3.375422</td>\n",
              "      <td>8.296950</td>\n",
              "      <td>5.669418</td>\n",
              "      <td>4.180205</td>\n",
              "      <td>3.203597</td>\n",
              "      <td>6.188655</td>\n",
              "      <td>4.273850</td>\n",
              "      <td>5.625257</td>\n",
              "      <td>3.625219</td>\n",
              "      <td>3.121881</td>\n",
              "      <td>8.765057</td>\n",
              "      <td>3.727983</td>\n",
              "      <td>3.974085</td>\n",
              "      <td>6.998981</td>\n",
              "      <td>4.611395</td>\n",
              "      <td>9.169078</td>\n",
              "      <td>4.031050</td>\n",
              "      <td>3.410705</td>\n",
              "      <td>2.841949</td>\n",
              "      <td>2.803782</td>\n",
              "      <td>5.383349</td>\n",
              "      <td>5.402952</td>\n",
              "      <td>5.456692</td>\n",
              "      <td>2.964560</td>\n",
              "      <td>10.500454</td>\n",
              "      <td>3.001589</td>\n",
              "      <td>3.014507</td>\n",
              "      <td>3.739111</td>\n",
              "      <td>3.380808</td>\n",
              "      <td>4.278098</td>\n",
              "      <td>3.258932</td>\n",
              "      <td>4.953957</td>\n",
              "      <td>8.346107</td>\n",
              "      <td>...</td>\n",
              "      <td>3.950427</td>\n",
              "      <td>3.216579</td>\n",
              "      <td>2.737720</td>\n",
              "      <td>2.988535</td>\n",
              "      <td>3.250894</td>\n",
              "      <td>7.515529</td>\n",
              "      <td>2.891633</td>\n",
              "      <td>2.978996</td>\n",
              "      <td>2.976623</td>\n",
              "      <td>3.061091</td>\n",
              "      <td>3.685472</td>\n",
              "      <td>3.190658</td>\n",
              "      <td>3.590825</td>\n",
              "      <td>3.362089</td>\n",
              "      <td>2.995701</td>\n",
              "      <td>2.659010</td>\n",
              "      <td>2.676646</td>\n",
              "      <td>2.790924</td>\n",
              "      <td>7.626892</td>\n",
              "      <td>3.639602</td>\n",
              "      <td>3.061956</td>\n",
              "      <td>3.285372</td>\n",
              "      <td>3.247671</td>\n",
              "      <td>3.474086</td>\n",
              "      <td>4.869199</td>\n",
              "      <td>2.935180</td>\n",
              "      <td>2.888721</td>\n",
              "      <td>3.603264</td>\n",
              "      <td>3.211679</td>\n",
              "      <td>2.450375</td>\n",
              "      <td>3.652660</td>\n",
              "      <td>2.918475</td>\n",
              "      <td>2.849537</td>\n",
              "      <td>8.945953</td>\n",
              "      <td>3.412586</td>\n",
              "      <td>2.951270</td>\n",
              "      <td>3.213545</td>\n",
              "      <td>9.938978</td>\n",
              "      <td>3.396126</td>\n",
              "      <td>7.726867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>1298157</td>\n",
              "      <td>8.441628</td>\n",
              "      <td>2.639276</td>\n",
              "      <td>11.463742</td>\n",
              "      <td>4.425849</td>\n",
              "      <td>4.384732</td>\n",
              "      <td>3.229511</td>\n",
              "      <td>3.571204</td>\n",
              "      <td>8.193000</td>\n",
              "      <td>5.671600</td>\n",
              "      <td>4.943996</td>\n",
              "      <td>3.770408</td>\n",
              "      <td>7.360238</td>\n",
              "      <td>4.358331</td>\n",
              "      <td>3.726872</td>\n",
              "      <td>4.842286</td>\n",
              "      <td>3.126138</td>\n",
              "      <td>8.280024</td>\n",
              "      <td>3.329482</td>\n",
              "      <td>4.020879</td>\n",
              "      <td>7.234464</td>\n",
              "      <td>5.759933</td>\n",
              "      <td>8.012117</td>\n",
              "      <td>3.212582</td>\n",
              "      <td>3.362995</td>\n",
              "      <td>2.889998</td>\n",
              "      <td>2.939662</td>\n",
              "      <td>4.674459</td>\n",
              "      <td>4.807316</td>\n",
              "      <td>4.982202</td>\n",
              "      <td>2.999066</td>\n",
              "      <td>9.680311</td>\n",
              "      <td>3.443071</td>\n",
              "      <td>3.249699</td>\n",
              "      <td>3.419884</td>\n",
              "      <td>3.646099</td>\n",
              "      <td>3.949115</td>\n",
              "      <td>3.013525</td>\n",
              "      <td>4.955624</td>\n",
              "      <td>8.552384</td>\n",
              "      <td>...</td>\n",
              "      <td>3.525425</td>\n",
              "      <td>5.838142</td>\n",
              "      <td>3.108675</td>\n",
              "      <td>3.272440</td>\n",
              "      <td>3.797733</td>\n",
              "      <td>6.525171</td>\n",
              "      <td>3.063422</td>\n",
              "      <td>3.145192</td>\n",
              "      <td>3.290301</td>\n",
              "      <td>3.430804</td>\n",
              "      <td>3.882161</td>\n",
              "      <td>3.413045</td>\n",
              "      <td>3.369182</td>\n",
              "      <td>3.372263</td>\n",
              "      <td>3.823720</td>\n",
              "      <td>2.967707</td>\n",
              "      <td>2.660243</td>\n",
              "      <td>3.015918</td>\n",
              "      <td>7.600110</td>\n",
              "      <td>3.657931</td>\n",
              "      <td>3.132416</td>\n",
              "      <td>3.390231</td>\n",
              "      <td>3.562632</td>\n",
              "      <td>3.402212</td>\n",
              "      <td>4.540545</td>\n",
              "      <td>2.921340</td>\n",
              "      <td>3.041490</td>\n",
              "      <td>4.045301</td>\n",
              "      <td>3.507341</td>\n",
              "      <td>2.595066</td>\n",
              "      <td>5.097882</td>\n",
              "      <td>3.102979</td>\n",
              "      <td>3.243552</td>\n",
              "      <td>8.110421</td>\n",
              "      <td>3.343723</td>\n",
              "      <td>2.959009</td>\n",
              "      <td>3.007502</td>\n",
              "      <td>9.332193</td>\n",
              "      <td>3.435411</td>\n",
              "      <td>10.392042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>1480372</td>\n",
              "      <td>8.422922</td>\n",
              "      <td>2.879890</td>\n",
              "      <td>10.557777</td>\n",
              "      <td>3.550390</td>\n",
              "      <td>4.247189</td>\n",
              "      <td>3.176336</td>\n",
              "      <td>3.321811</td>\n",
              "      <td>8.901706</td>\n",
              "      <td>4.684851</td>\n",
              "      <td>4.215908</td>\n",
              "      <td>3.432197</td>\n",
              "      <td>4.556123</td>\n",
              "      <td>4.361337</td>\n",
              "      <td>4.813846</td>\n",
              "      <td>4.791299</td>\n",
              "      <td>3.094036</td>\n",
              "      <td>8.644983</td>\n",
              "      <td>4.045898</td>\n",
              "      <td>3.605055</td>\n",
              "      <td>7.525257</td>\n",
              "      <td>7.810126</td>\n",
              "      <td>8.113801</td>\n",
              "      <td>3.892474</td>\n",
              "      <td>3.315494</td>\n",
              "      <td>2.764505</td>\n",
              "      <td>2.785968</td>\n",
              "      <td>4.338340</td>\n",
              "      <td>4.739177</td>\n",
              "      <td>5.037259</td>\n",
              "      <td>2.921308</td>\n",
              "      <td>9.848256</td>\n",
              "      <td>5.355027</td>\n",
              "      <td>3.647747</td>\n",
              "      <td>4.413179</td>\n",
              "      <td>3.730797</td>\n",
              "      <td>3.696454</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>4.889988</td>\n",
              "      <td>3.318492</td>\n",
              "      <td>...</td>\n",
              "      <td>3.509842</td>\n",
              "      <td>2.945893</td>\n",
              "      <td>2.897693</td>\n",
              "      <td>2.938409</td>\n",
              "      <td>2.959839</td>\n",
              "      <td>5.791348</td>\n",
              "      <td>2.774638</td>\n",
              "      <td>3.657118</td>\n",
              "      <td>3.087958</td>\n",
              "      <td>3.468064</td>\n",
              "      <td>4.287674</td>\n",
              "      <td>3.425382</td>\n",
              "      <td>3.452500</td>\n",
              "      <td>3.704773</td>\n",
              "      <td>3.264937</td>\n",
              "      <td>2.897396</td>\n",
              "      <td>2.763486</td>\n",
              "      <td>2.836450</td>\n",
              "      <td>8.070651</td>\n",
              "      <td>3.715302</td>\n",
              "      <td>3.045340</td>\n",
              "      <td>3.016188</td>\n",
              "      <td>4.370638</td>\n",
              "      <td>3.841095</td>\n",
              "      <td>4.062441</td>\n",
              "      <td>2.834466</td>\n",
              "      <td>2.777204</td>\n",
              "      <td>4.012017</td>\n",
              "      <td>3.557362</td>\n",
              "      <td>2.443743</td>\n",
              "      <td>4.243448</td>\n",
              "      <td>3.034131</td>\n",
              "      <td>3.031143</td>\n",
              "      <td>9.161868</td>\n",
              "      <td>3.412558</td>\n",
              "      <td>2.974475</td>\n",
              "      <td>3.088841</td>\n",
              "      <td>10.742651</td>\n",
              "      <td>3.317945</td>\n",
              "      <td>6.203929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>1298533</td>\n",
              "      <td>8.089255</td>\n",
              "      <td>2.521169</td>\n",
              "      <td>10.792750</td>\n",
              "      <td>4.443337</td>\n",
              "      <td>3.071359</td>\n",
              "      <td>3.238305</td>\n",
              "      <td>5.209472</td>\n",
              "      <td>8.073389</td>\n",
              "      <td>5.643811</td>\n",
              "      <td>5.040952</td>\n",
              "      <td>3.344979</td>\n",
              "      <td>6.669064</td>\n",
              "      <td>3.597366</td>\n",
              "      <td>5.859500</td>\n",
              "      <td>4.286220</td>\n",
              "      <td>3.372714</td>\n",
              "      <td>7.830936</td>\n",
              "      <td>3.256537</td>\n",
              "      <td>4.540383</td>\n",
              "      <td>6.066356</td>\n",
              "      <td>7.182077</td>\n",
              "      <td>6.948601</td>\n",
              "      <td>7.073437</td>\n",
              "      <td>3.436440</td>\n",
              "      <td>2.813419</td>\n",
              "      <td>2.910087</td>\n",
              "      <td>6.683538</td>\n",
              "      <td>4.868739</td>\n",
              "      <td>4.611973</td>\n",
              "      <td>2.759914</td>\n",
              "      <td>10.354026</td>\n",
              "      <td>3.361741</td>\n",
              "      <td>3.174112</td>\n",
              "      <td>7.346287</td>\n",
              "      <td>3.652134</td>\n",
              "      <td>4.544815</td>\n",
              "      <td>3.064199</td>\n",
              "      <td>6.645925</td>\n",
              "      <td>8.224078</td>\n",
              "      <td>...</td>\n",
              "      <td>3.357575</td>\n",
              "      <td>3.867752</td>\n",
              "      <td>3.028672</td>\n",
              "      <td>3.581341</td>\n",
              "      <td>4.196880</td>\n",
              "      <td>7.234274</td>\n",
              "      <td>3.039980</td>\n",
              "      <td>3.730557</td>\n",
              "      <td>3.125049</td>\n",
              "      <td>3.525079</td>\n",
              "      <td>3.531308</td>\n",
              "      <td>3.229062</td>\n",
              "      <td>3.505198</td>\n",
              "      <td>3.980961</td>\n",
              "      <td>2.958662</td>\n",
              "      <td>2.660811</td>\n",
              "      <td>2.605696</td>\n",
              "      <td>3.340643</td>\n",
              "      <td>7.826121</td>\n",
              "      <td>4.278568</td>\n",
              "      <td>2.959811</td>\n",
              "      <td>4.133042</td>\n",
              "      <td>4.213764</td>\n",
              "      <td>3.221974</td>\n",
              "      <td>4.686370</td>\n",
              "      <td>2.887736</td>\n",
              "      <td>3.049697</td>\n",
              "      <td>4.393847</td>\n",
              "      <td>3.532841</td>\n",
              "      <td>2.603842</td>\n",
              "      <td>5.084844</td>\n",
              "      <td>2.981869</td>\n",
              "      <td>3.703721</td>\n",
              "      <td>8.473612</td>\n",
              "      <td>3.640390</td>\n",
              "      <td>2.903894</td>\n",
              "      <td>2.847505</td>\n",
              "      <td>8.544696</td>\n",
              "      <td>3.174515</td>\n",
              "      <td>7.119213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>930299</td>\n",
              "      <td>3.112333</td>\n",
              "      <td>2.870468</td>\n",
              "      <td>9.873902</td>\n",
              "      <td>4.266828</td>\n",
              "      <td>3.230197</td>\n",
              "      <td>3.027742</td>\n",
              "      <td>3.407148</td>\n",
              "      <td>5.760610</td>\n",
              "      <td>5.834256</td>\n",
              "      <td>5.550722</td>\n",
              "      <td>3.272994</td>\n",
              "      <td>7.012936</td>\n",
              "      <td>3.629980</td>\n",
              "      <td>6.321085</td>\n",
              "      <td>5.754581</td>\n",
              "      <td>3.046196</td>\n",
              "      <td>8.088148</td>\n",
              "      <td>3.935535</td>\n",
              "      <td>3.327640</td>\n",
              "      <td>8.185968</td>\n",
              "      <td>5.663629</td>\n",
              "      <td>8.362776</td>\n",
              "      <td>5.063248</td>\n",
              "      <td>6.987454</td>\n",
              "      <td>2.693494</td>\n",
              "      <td>3.622282</td>\n",
              "      <td>5.794690</td>\n",
              "      <td>4.090673</td>\n",
              "      <td>4.800284</td>\n",
              "      <td>7.833970</td>\n",
              "      <td>8.839499</td>\n",
              "      <td>7.360885</td>\n",
              "      <td>2.992044</td>\n",
              "      <td>8.010674</td>\n",
              "      <td>4.008153</td>\n",
              "      <td>4.142386</td>\n",
              "      <td>2.912428</td>\n",
              "      <td>4.811472</td>\n",
              "      <td>3.536157</td>\n",
              "      <td>...</td>\n",
              "      <td>3.243715</td>\n",
              "      <td>2.689623</td>\n",
              "      <td>3.236872</td>\n",
              "      <td>3.432355</td>\n",
              "      <td>3.421215</td>\n",
              "      <td>7.751206</td>\n",
              "      <td>2.824329</td>\n",
              "      <td>3.143819</td>\n",
              "      <td>3.028617</td>\n",
              "      <td>3.244888</td>\n",
              "      <td>3.729339</td>\n",
              "      <td>3.326140</td>\n",
              "      <td>7.257399</td>\n",
              "      <td>3.477507</td>\n",
              "      <td>3.041844</td>\n",
              "      <td>2.470981</td>\n",
              "      <td>2.744415</td>\n",
              "      <td>2.763764</td>\n",
              "      <td>7.848633</td>\n",
              "      <td>3.853900</td>\n",
              "      <td>3.185840</td>\n",
              "      <td>2.910977</td>\n",
              "      <td>4.839607</td>\n",
              "      <td>3.116006</td>\n",
              "      <td>4.099547</td>\n",
              "      <td>3.029919</td>\n",
              "      <td>2.766441</td>\n",
              "      <td>3.871248</td>\n",
              "      <td>3.033338</td>\n",
              "      <td>2.531280</td>\n",
              "      <td>4.986124</td>\n",
              "      <td>2.992148</td>\n",
              "      <td>3.111383</td>\n",
              "      <td>8.468564</td>\n",
              "      <td>3.142641</td>\n",
              "      <td>2.857956</td>\n",
              "      <td>2.832840</td>\n",
              "      <td>9.900550</td>\n",
              "      <td>3.243563</td>\n",
              "      <td>7.622261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>905954</td>\n",
              "      <td>7.153127</td>\n",
              "      <td>2.834285</td>\n",
              "      <td>10.788218</td>\n",
              "      <td>4.100493</td>\n",
              "      <td>3.435795</td>\n",
              "      <td>3.330279</td>\n",
              "      <td>3.063284</td>\n",
              "      <td>8.191465</td>\n",
              "      <td>5.329834</td>\n",
              "      <td>5.877487</td>\n",
              "      <td>4.215433</td>\n",
              "      <td>8.179745</td>\n",
              "      <td>3.642221</td>\n",
              "      <td>3.772388</td>\n",
              "      <td>3.829010</td>\n",
              "      <td>2.974629</td>\n",
              "      <td>8.492699</td>\n",
              "      <td>4.311844</td>\n",
              "      <td>3.281952</td>\n",
              "      <td>4.967268</td>\n",
              "      <td>6.539451</td>\n",
              "      <td>9.611164</td>\n",
              "      <td>3.330025</td>\n",
              "      <td>3.576292</td>\n",
              "      <td>2.818373</td>\n",
              "      <td>2.721674</td>\n",
              "      <td>9.964246</td>\n",
              "      <td>3.965856</td>\n",
              "      <td>4.967207</td>\n",
              "      <td>3.266466</td>\n",
              "      <td>9.057700</td>\n",
              "      <td>3.923060</td>\n",
              "      <td>2.924887</td>\n",
              "      <td>4.646153</td>\n",
              "      <td>3.633279</td>\n",
              "      <td>4.682117</td>\n",
              "      <td>3.067121</td>\n",
              "      <td>5.155566</td>\n",
              "      <td>6.074918</td>\n",
              "      <td>...</td>\n",
              "      <td>3.273818</td>\n",
              "      <td>6.886046</td>\n",
              "      <td>3.098539</td>\n",
              "      <td>3.004521</td>\n",
              "      <td>2.998243</td>\n",
              "      <td>5.495573</td>\n",
              "      <td>2.961595</td>\n",
              "      <td>5.136811</td>\n",
              "      <td>3.074840</td>\n",
              "      <td>3.239312</td>\n",
              "      <td>4.405299</td>\n",
              "      <td>3.560002</td>\n",
              "      <td>6.473561</td>\n",
              "      <td>3.565383</td>\n",
              "      <td>3.198007</td>\n",
              "      <td>2.824467</td>\n",
              "      <td>2.690283</td>\n",
              "      <td>3.047576</td>\n",
              "      <td>8.762100</td>\n",
              "      <td>10.811478</td>\n",
              "      <td>3.435318</td>\n",
              "      <td>3.407199</td>\n",
              "      <td>3.764979</td>\n",
              "      <td>3.210291</td>\n",
              "      <td>4.095968</td>\n",
              "      <td>3.053006</td>\n",
              "      <td>3.074055</td>\n",
              "      <td>3.768554</td>\n",
              "      <td>3.745116</td>\n",
              "      <td>2.734454</td>\n",
              "      <td>4.362137</td>\n",
              "      <td>2.964605</td>\n",
              "      <td>3.300715</td>\n",
              "      <td>8.386096</td>\n",
              "      <td>2.927523</td>\n",
              "      <td>3.033662</td>\n",
              "      <td>2.817057</td>\n",
              "      <td>9.071943</td>\n",
              "      <td>3.324517</td>\n",
              "      <td>7.290293</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1018 rows × 17738 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdc7ac8d-a3a8-468d-9596-a057239a0599')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdc7ac8d-a3a8-468d-9596-a057239a0599 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdc7ac8d-a3a8-468d-9596-a057239a0599');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      COSMIC_ID  ENSG00000000003  ...  ENSG00000266433  ENSG00000266753\n",
              "0        906826         7.632023  ...         3.073724         7.284733\n",
              "1        687983         7.548671  ...         3.000182         8.504804\n",
              "2        910927         8.712338  ...         2.916274         7.059092\n",
              "3       1240138         7.797142  ...         3.256500         7.318125\n",
              "4       1240139         7.729268  ...         3.396126         7.726867\n",
              "...         ...              ...  ...              ...              ...\n",
              "1013    1298157         8.441628  ...         3.435411        10.392042\n",
              "1014    1480372         8.422922  ...         3.317945         6.203929\n",
              "1015    1298533         8.089255  ...         3.174515         7.119213\n",
              "1016     930299         3.112333  ...         3.243563         7.622261\n",
              "1017     905954         7.153127  ...         3.324517         7.290293\n",
              "\n",
              "[1018 rows x 17738 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "x9w_Izz0V1_w",
        "outputId": "48de646c-2d49-4ed5-8f4a-422c90f3271b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-05eaa1f2-3a51-4e54-aae1-c516e37bbf89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENSG00000000003</th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>ENSG00000001167</th>\n",
              "      <th>ENSG00000001460</th>\n",
              "      <th>ENSG00000001461</th>\n",
              "      <th>ENSG00000001497</th>\n",
              "      <th>ENSG00000001561</th>\n",
              "      <th>ENSG00000001617</th>\n",
              "      <th>ENSG00000001626</th>\n",
              "      <th>ENSG00000001629</th>\n",
              "      <th>ENSG00000001631</th>\n",
              "      <th>ENSG00000002016</th>\n",
              "      <th>ENSG00000002330</th>\n",
              "      <th>ENSG00000002549</th>\n",
              "      <th>ENSG00000002586</th>\n",
              "      <th>ENSG00000002587</th>\n",
              "      <th>ENSG00000002726</th>\n",
              "      <th>ENSG00000002745</th>\n",
              "      <th>ENSG00000002746</th>\n",
              "      <th>ENSG00000002822</th>\n",
              "      <th>ENSG00000002834</th>\n",
              "      <th>ENSG00000002919</th>\n",
              "      <th>ENSG00000002933</th>\n",
              "      <th>ENSG00000003056</th>\n",
              "      <th>ENSG00000003096</th>\n",
              "      <th>ENSG00000003137</th>\n",
              "      <th>ENSG00000003147</th>\n",
              "      <th>ENSG00000003249</th>\n",
              "      <th>ENSG00000003393</th>\n",
              "      <th>ENSG00000003400</th>\n",
              "      <th>ENSG00000003402</th>\n",
              "      <th>ENSG00000003436</th>\n",
              "      <th>ENSG00000003509</th>\n",
              "      <th>ENSG00000003756</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000260347</th>\n",
              "      <th>ENSG00000260359</th>\n",
              "      <th>ENSG00000260432</th>\n",
              "      <th>ENSG00000260461</th>\n",
              "      <th>ENSG00000260495</th>\n",
              "      <th>ENSG00000260539</th>\n",
              "      <th>ENSG00000260612</th>\n",
              "      <th>ENSG00000260880</th>\n",
              "      <th>ENSG00000261215</th>\n",
              "      <th>ENSG00000261253</th>\n",
              "      <th>ENSG00000261351</th>\n",
              "      <th>ENSG00000261434</th>\n",
              "      <th>ENSG00000261452</th>\n",
              "      <th>ENSG00000261649</th>\n",
              "      <th>ENSG00000261685</th>\n",
              "      <th>ENSG00000261701</th>\n",
              "      <th>ENSG00000261742</th>\n",
              "      <th>ENSG00000261803</th>\n",
              "      <th>ENSG00000261819</th>\n",
              "      <th>ENSG00000261857</th>\n",
              "      <th>ENSG00000261925</th>\n",
              "      <th>ENSG00000262152</th>\n",
              "      <th>ENSG00000262557</th>\n",
              "      <th>ENSG00000262628</th>\n",
              "      <th>ENSG00000263002</th>\n",
              "      <th>ENSG00000263417</th>\n",
              "      <th>ENSG00000263574</th>\n",
              "      <th>ENSG00000263843</th>\n",
              "      <th>ENSG00000264247</th>\n",
              "      <th>ENSG00000264424</th>\n",
              "      <th>ENSG00000264575</th>\n",
              "      <th>ENSG00000265060</th>\n",
              "      <th>ENSG00000265246</th>\n",
              "      <th>ENSG00000265298</th>\n",
              "      <th>ENSG00000265480</th>\n",
              "      <th>ENSG00000265929</th>\n",
              "      <th>ENSG00000266066</th>\n",
              "      <th>ENSG00000266282</th>\n",
              "      <th>ENSG00000266433</th>\n",
              "      <th>ENSG00000266753</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.632023</td>\n",
              "      <td>2.964585</td>\n",
              "      <td>10.379553</td>\n",
              "      <td>3.614794</td>\n",
              "      <td>3.324692</td>\n",
              "      <td>3.566350</td>\n",
              "      <td>8.204530</td>\n",
              "      <td>5.235118</td>\n",
              "      <td>5.369039</td>\n",
              "      <td>3.596993</td>\n",
              "      <td>7.641756</td>\n",
              "      <td>4.549065</td>\n",
              "      <td>4.488261</td>\n",
              "      <td>4.118309</td>\n",
              "      <td>3.024970</td>\n",
              "      <td>8.296444</td>\n",
              "      <td>3.646615</td>\n",
              "      <td>3.780467</td>\n",
              "      <td>7.458409</td>\n",
              "      <td>6.453926</td>\n",
              "      <td>9.460478</td>\n",
              "      <td>3.517445</td>\n",
              "      <td>3.350498</td>\n",
              "      <td>3.741032</td>\n",
              "      <td>2.661393</td>\n",
              "      <td>5.200431</td>\n",
              "      <td>4.931681</td>\n",
              "      <td>4.767457</td>\n",
              "      <td>2.975821</td>\n",
              "      <td>9.792014</td>\n",
              "      <td>6.213763</td>\n",
              "      <td>3.440152</td>\n",
              "      <td>4.075371</td>\n",
              "      <td>3.689651</td>\n",
              "      <td>3.947773</td>\n",
              "      <td>2.831262</td>\n",
              "      <td>5.463531</td>\n",
              "      <td>12.091616</td>\n",
              "      <td>5.804314</td>\n",
              "      <td>8.548148</td>\n",
              "      <td>...</td>\n",
              "      <td>3.183110</td>\n",
              "      <td>4.633899</td>\n",
              "      <td>3.077504</td>\n",
              "      <td>3.019080</td>\n",
              "      <td>3.081601</td>\n",
              "      <td>5.945066</td>\n",
              "      <td>2.939461</td>\n",
              "      <td>2.927571</td>\n",
              "      <td>2.991526</td>\n",
              "      <td>2.906636</td>\n",
              "      <td>3.901483</td>\n",
              "      <td>3.435723</td>\n",
              "      <td>3.051134</td>\n",
              "      <td>3.529562</td>\n",
              "      <td>3.030229</td>\n",
              "      <td>2.790461</td>\n",
              "      <td>2.801037</td>\n",
              "      <td>3.178122</td>\n",
              "      <td>6.975354</td>\n",
              "      <td>3.588889</td>\n",
              "      <td>3.029979</td>\n",
              "      <td>3.665788</td>\n",
              "      <td>3.389938</td>\n",
              "      <td>3.134197</td>\n",
              "      <td>4.841169</td>\n",
              "      <td>3.005416</td>\n",
              "      <td>2.939461</td>\n",
              "      <td>4.059000</td>\n",
              "      <td>3.411250</td>\n",
              "      <td>2.628932</td>\n",
              "      <td>6.786925</td>\n",
              "      <td>2.997054</td>\n",
              "      <td>3.109774</td>\n",
              "      <td>7.882377</td>\n",
              "      <td>3.331134</td>\n",
              "      <td>2.852537</td>\n",
              "      <td>3.130696</td>\n",
              "      <td>9.986616</td>\n",
              "      <td>3.073724</td>\n",
              "      <td>7.284733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.548671</td>\n",
              "      <td>2.777716</td>\n",
              "      <td>11.807341</td>\n",
              "      <td>4.066887</td>\n",
              "      <td>3.152404</td>\n",
              "      <td>7.827172</td>\n",
              "      <td>6.616972</td>\n",
              "      <td>5.809264</td>\n",
              "      <td>7.209653</td>\n",
              "      <td>3.753548</td>\n",
              "      <td>5.715404</td>\n",
              "      <td>4.306627</td>\n",
              "      <td>6.030564</td>\n",
              "      <td>3.951478</td>\n",
              "      <td>3.123943</td>\n",
              "      <td>8.313609</td>\n",
              "      <td>3.858846</td>\n",
              "      <td>3.921778</td>\n",
              "      <td>7.479327</td>\n",
              "      <td>6.742826</td>\n",
              "      <td>9.474606</td>\n",
              "      <td>3.044297</td>\n",
              "      <td>3.210050</td>\n",
              "      <td>2.729453</td>\n",
              "      <td>2.788262</td>\n",
              "      <td>6.139840</td>\n",
              "      <td>4.525647</td>\n",
              "      <td>5.246301</td>\n",
              "      <td>3.035024</td>\n",
              "      <td>8.845537</td>\n",
              "      <td>3.241823</td>\n",
              "      <td>3.073604</td>\n",
              "      <td>4.547098</td>\n",
              "      <td>4.062049</td>\n",
              "      <td>4.017758</td>\n",
              "      <td>2.788942</td>\n",
              "      <td>4.662621</td>\n",
              "      <td>3.470365</td>\n",
              "      <td>6.484788</td>\n",
              "      <td>8.736863</td>\n",
              "      <td>...</td>\n",
              "      <td>4.343442</td>\n",
              "      <td>2.618501</td>\n",
              "      <td>2.879343</td>\n",
              "      <td>3.331508</td>\n",
              "      <td>3.285192</td>\n",
              "      <td>6.798999</td>\n",
              "      <td>3.027941</td>\n",
              "      <td>3.191654</td>\n",
              "      <td>2.962621</td>\n",
              "      <td>3.074109</td>\n",
              "      <td>4.923347</td>\n",
              "      <td>3.345257</td>\n",
              "      <td>7.026350</td>\n",
              "      <td>3.599434</td>\n",
              "      <td>3.132953</td>\n",
              "      <td>2.778059</td>\n",
              "      <td>2.861326</td>\n",
              "      <td>2.996229</td>\n",
              "      <td>8.721021</td>\n",
              "      <td>3.419746</td>\n",
              "      <td>3.118254</td>\n",
              "      <td>3.053174</td>\n",
              "      <td>3.577202</td>\n",
              "      <td>3.327528</td>\n",
              "      <td>4.570476</td>\n",
              "      <td>2.878796</td>\n",
              "      <td>3.003163</td>\n",
              "      <td>3.572520</td>\n",
              "      <td>3.586613</td>\n",
              "      <td>2.783441</td>\n",
              "      <td>5.317911</td>\n",
              "      <td>3.263745</td>\n",
              "      <td>3.059424</td>\n",
              "      <td>8.681302</td>\n",
              "      <td>2.992611</td>\n",
              "      <td>2.776771</td>\n",
              "      <td>3.260982</td>\n",
              "      <td>9.002814</td>\n",
              "      <td>3.000182</td>\n",
              "      <td>8.504804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.712338</td>\n",
              "      <td>2.643508</td>\n",
              "      <td>9.880733</td>\n",
              "      <td>3.956230</td>\n",
              "      <td>3.241246</td>\n",
              "      <td>2.931034</td>\n",
              "      <td>8.191246</td>\n",
              "      <td>5.426841</td>\n",
              "      <td>5.120747</td>\n",
              "      <td>3.946064</td>\n",
              "      <td>5.601235</td>\n",
              "      <td>3.832190</td>\n",
              "      <td>4.548564</td>\n",
              "      <td>4.440084</td>\n",
              "      <td>2.896733</td>\n",
              "      <td>7.938611</td>\n",
              "      <td>3.811614</td>\n",
              "      <td>3.597864</td>\n",
              "      <td>7.419672</td>\n",
              "      <td>5.655691</td>\n",
              "      <td>10.011329</td>\n",
              "      <td>3.924394</td>\n",
              "      <td>3.215727</td>\n",
              "      <td>2.699162</td>\n",
              "      <td>2.902831</td>\n",
              "      <td>5.393870</td>\n",
              "      <td>4.145480</td>\n",
              "      <td>4.645800</td>\n",
              "      <td>2.846260</td>\n",
              "      <td>8.868636</td>\n",
              "      <td>3.054858</td>\n",
              "      <td>3.082341</td>\n",
              "      <td>3.032266</td>\n",
              "      <td>4.007929</td>\n",
              "      <td>3.784884</td>\n",
              "      <td>3.191751</td>\n",
              "      <td>5.519212</td>\n",
              "      <td>10.236172</td>\n",
              "      <td>5.672254</td>\n",
              "      <td>8.360662</td>\n",
              "      <td>...</td>\n",
              "      <td>3.160929</td>\n",
              "      <td>2.966000</td>\n",
              "      <td>2.979303</td>\n",
              "      <td>3.338575</td>\n",
              "      <td>3.036464</td>\n",
              "      <td>7.318819</td>\n",
              "      <td>2.984301</td>\n",
              "      <td>3.278479</td>\n",
              "      <td>3.255958</td>\n",
              "      <td>2.964270</td>\n",
              "      <td>3.883598</td>\n",
              "      <td>3.154062</td>\n",
              "      <td>7.501269</td>\n",
              "      <td>3.347474</td>\n",
              "      <td>2.752734</td>\n",
              "      <td>2.661848</td>\n",
              "      <td>2.718044</td>\n",
              "      <td>2.828840</td>\n",
              "      <td>8.304669</td>\n",
              "      <td>3.449147</td>\n",
              "      <td>2.775777</td>\n",
              "      <td>3.226808</td>\n",
              "      <td>3.384858</td>\n",
              "      <td>3.326309</td>\n",
              "      <td>4.214729</td>\n",
              "      <td>2.985562</td>\n",
              "      <td>3.083179</td>\n",
              "      <td>3.482183</td>\n",
              "      <td>3.725436</td>\n",
              "      <td>2.603604</td>\n",
              "      <td>3.143006</td>\n",
              "      <td>3.112145</td>\n",
              "      <td>2.930254</td>\n",
              "      <td>8.707886</td>\n",
              "      <td>2.886574</td>\n",
              "      <td>2.685307</td>\n",
              "      <td>3.176239</td>\n",
              "      <td>9.113243</td>\n",
              "      <td>2.916274</td>\n",
              "      <td>7.059092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.797142</td>\n",
              "      <td>2.817923</td>\n",
              "      <td>9.883471</td>\n",
              "      <td>4.063701</td>\n",
              "      <td>3.101247</td>\n",
              "      <td>7.211707</td>\n",
              "      <td>8.630643</td>\n",
              "      <td>5.617714</td>\n",
              "      <td>4.996434</td>\n",
              "      <td>3.378736</td>\n",
              "      <td>6.752791</td>\n",
              "      <td>3.512547</td>\n",
              "      <td>5.309896</td>\n",
              "      <td>4.210272</td>\n",
              "      <td>2.950093</td>\n",
              "      <td>7.231354</td>\n",
              "      <td>3.772951</td>\n",
              "      <td>3.220164</td>\n",
              "      <td>7.731137</td>\n",
              "      <td>5.259367</td>\n",
              "      <td>8.173147</td>\n",
              "      <td>2.957085</td>\n",
              "      <td>3.396187</td>\n",
              "      <td>2.732190</td>\n",
              "      <td>3.000899</td>\n",
              "      <td>5.447174</td>\n",
              "      <td>4.971736</td>\n",
              "      <td>4.558836</td>\n",
              "      <td>2.965398</td>\n",
              "      <td>8.974729</td>\n",
              "      <td>3.349643</td>\n",
              "      <td>3.431314</td>\n",
              "      <td>7.487131</td>\n",
              "      <td>3.577693</td>\n",
              "      <td>3.898134</td>\n",
              "      <td>3.110345</td>\n",
              "      <td>6.322941</td>\n",
              "      <td>7.625778</td>\n",
              "      <td>5.171895</td>\n",
              "      <td>7.201922</td>\n",
              "      <td>...</td>\n",
              "      <td>3.079667</td>\n",
              "      <td>4.609837</td>\n",
              "      <td>3.699916</td>\n",
              "      <td>3.426935</td>\n",
              "      <td>3.153041</td>\n",
              "      <td>5.597614</td>\n",
              "      <td>3.145512</td>\n",
              "      <td>2.816586</td>\n",
              "      <td>3.107612</td>\n",
              "      <td>2.875945</td>\n",
              "      <td>4.028170</td>\n",
              "      <td>3.184647</td>\n",
              "      <td>6.743810</td>\n",
              "      <td>4.000042</td>\n",
              "      <td>2.934522</td>\n",
              "      <td>2.690589</td>\n",
              "      <td>2.757298</td>\n",
              "      <td>2.935488</td>\n",
              "      <td>7.776016</td>\n",
              "      <td>3.349624</td>\n",
              "      <td>2.927550</td>\n",
              "      <td>3.110801</td>\n",
              "      <td>2.771725</td>\n",
              "      <td>2.921903</td>\n",
              "      <td>4.060761</td>\n",
              "      <td>3.054339</td>\n",
              "      <td>2.932036</td>\n",
              "      <td>3.722306</td>\n",
              "      <td>2.996834</td>\n",
              "      <td>2.619540</td>\n",
              "      <td>3.153896</td>\n",
              "      <td>3.151576</td>\n",
              "      <td>2.850726</td>\n",
              "      <td>7.872535</td>\n",
              "      <td>3.812119</td>\n",
              "      <td>3.436412</td>\n",
              "      <td>3.074432</td>\n",
              "      <td>9.958284</td>\n",
              "      <td>3.256500</td>\n",
              "      <td>7.318125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.729268</td>\n",
              "      <td>2.957739</td>\n",
              "      <td>10.418840</td>\n",
              "      <td>4.341500</td>\n",
              "      <td>3.001802</td>\n",
              "      <td>3.375422</td>\n",
              "      <td>8.296950</td>\n",
              "      <td>5.669418</td>\n",
              "      <td>4.180205</td>\n",
              "      <td>3.203597</td>\n",
              "      <td>6.188655</td>\n",
              "      <td>4.273850</td>\n",
              "      <td>5.625257</td>\n",
              "      <td>3.625219</td>\n",
              "      <td>3.121881</td>\n",
              "      <td>8.765057</td>\n",
              "      <td>3.727983</td>\n",
              "      <td>3.974085</td>\n",
              "      <td>6.998981</td>\n",
              "      <td>4.611395</td>\n",
              "      <td>9.169078</td>\n",
              "      <td>4.031050</td>\n",
              "      <td>3.410705</td>\n",
              "      <td>2.841949</td>\n",
              "      <td>2.803782</td>\n",
              "      <td>5.383349</td>\n",
              "      <td>5.402952</td>\n",
              "      <td>5.456692</td>\n",
              "      <td>2.964560</td>\n",
              "      <td>10.500454</td>\n",
              "      <td>3.001589</td>\n",
              "      <td>3.014507</td>\n",
              "      <td>3.739111</td>\n",
              "      <td>3.380808</td>\n",
              "      <td>4.278098</td>\n",
              "      <td>3.258932</td>\n",
              "      <td>4.953957</td>\n",
              "      <td>8.346107</td>\n",
              "      <td>6.512252</td>\n",
              "      <td>7.607464</td>\n",
              "      <td>...</td>\n",
              "      <td>3.950427</td>\n",
              "      <td>3.216579</td>\n",
              "      <td>2.737720</td>\n",
              "      <td>2.988535</td>\n",
              "      <td>3.250894</td>\n",
              "      <td>7.515529</td>\n",
              "      <td>2.891633</td>\n",
              "      <td>2.978996</td>\n",
              "      <td>2.976623</td>\n",
              "      <td>3.061091</td>\n",
              "      <td>3.685472</td>\n",
              "      <td>3.190658</td>\n",
              "      <td>3.590825</td>\n",
              "      <td>3.362089</td>\n",
              "      <td>2.995701</td>\n",
              "      <td>2.659010</td>\n",
              "      <td>2.676646</td>\n",
              "      <td>2.790924</td>\n",
              "      <td>7.626892</td>\n",
              "      <td>3.639602</td>\n",
              "      <td>3.061956</td>\n",
              "      <td>3.285372</td>\n",
              "      <td>3.247671</td>\n",
              "      <td>3.474086</td>\n",
              "      <td>4.869199</td>\n",
              "      <td>2.935180</td>\n",
              "      <td>2.888721</td>\n",
              "      <td>3.603264</td>\n",
              "      <td>3.211679</td>\n",
              "      <td>2.450375</td>\n",
              "      <td>3.652660</td>\n",
              "      <td>2.918475</td>\n",
              "      <td>2.849537</td>\n",
              "      <td>8.945953</td>\n",
              "      <td>3.412586</td>\n",
              "      <td>2.951270</td>\n",
              "      <td>3.213545</td>\n",
              "      <td>9.938978</td>\n",
              "      <td>3.396126</td>\n",
              "      <td>7.726867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>8.441628</td>\n",
              "      <td>2.639276</td>\n",
              "      <td>11.463742</td>\n",
              "      <td>4.425849</td>\n",
              "      <td>3.229511</td>\n",
              "      <td>3.571204</td>\n",
              "      <td>8.193000</td>\n",
              "      <td>5.671600</td>\n",
              "      <td>4.943996</td>\n",
              "      <td>3.770408</td>\n",
              "      <td>7.360238</td>\n",
              "      <td>4.358331</td>\n",
              "      <td>3.726872</td>\n",
              "      <td>4.842286</td>\n",
              "      <td>3.126138</td>\n",
              "      <td>8.280024</td>\n",
              "      <td>3.329482</td>\n",
              "      <td>4.020879</td>\n",
              "      <td>7.234464</td>\n",
              "      <td>5.759933</td>\n",
              "      <td>8.012117</td>\n",
              "      <td>3.212582</td>\n",
              "      <td>3.362995</td>\n",
              "      <td>2.889998</td>\n",
              "      <td>2.939662</td>\n",
              "      <td>4.674459</td>\n",
              "      <td>4.807316</td>\n",
              "      <td>4.982202</td>\n",
              "      <td>2.999066</td>\n",
              "      <td>9.680311</td>\n",
              "      <td>3.443071</td>\n",
              "      <td>3.249699</td>\n",
              "      <td>3.419884</td>\n",
              "      <td>3.646099</td>\n",
              "      <td>3.949115</td>\n",
              "      <td>3.013525</td>\n",
              "      <td>4.955624</td>\n",
              "      <td>8.552384</td>\n",
              "      <td>6.264426</td>\n",
              "      <td>8.211825</td>\n",
              "      <td>...</td>\n",
              "      <td>3.525425</td>\n",
              "      <td>5.838142</td>\n",
              "      <td>3.108675</td>\n",
              "      <td>3.272440</td>\n",
              "      <td>3.797733</td>\n",
              "      <td>6.525171</td>\n",
              "      <td>3.063422</td>\n",
              "      <td>3.145192</td>\n",
              "      <td>3.290301</td>\n",
              "      <td>3.430804</td>\n",
              "      <td>3.882161</td>\n",
              "      <td>3.413045</td>\n",
              "      <td>3.369182</td>\n",
              "      <td>3.372263</td>\n",
              "      <td>3.823720</td>\n",
              "      <td>2.967707</td>\n",
              "      <td>2.660243</td>\n",
              "      <td>3.015918</td>\n",
              "      <td>7.600110</td>\n",
              "      <td>3.657931</td>\n",
              "      <td>3.132416</td>\n",
              "      <td>3.390231</td>\n",
              "      <td>3.562632</td>\n",
              "      <td>3.402212</td>\n",
              "      <td>4.540545</td>\n",
              "      <td>2.921340</td>\n",
              "      <td>3.041490</td>\n",
              "      <td>4.045301</td>\n",
              "      <td>3.507341</td>\n",
              "      <td>2.595066</td>\n",
              "      <td>5.097882</td>\n",
              "      <td>3.102979</td>\n",
              "      <td>3.243552</td>\n",
              "      <td>8.110421</td>\n",
              "      <td>3.343723</td>\n",
              "      <td>2.959009</td>\n",
              "      <td>3.007502</td>\n",
              "      <td>9.332193</td>\n",
              "      <td>3.435411</td>\n",
              "      <td>10.392042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>8.422922</td>\n",
              "      <td>2.879890</td>\n",
              "      <td>10.557777</td>\n",
              "      <td>3.550390</td>\n",
              "      <td>3.176336</td>\n",
              "      <td>3.321811</td>\n",
              "      <td>8.901706</td>\n",
              "      <td>4.684851</td>\n",
              "      <td>4.215908</td>\n",
              "      <td>3.432197</td>\n",
              "      <td>4.556123</td>\n",
              "      <td>4.361337</td>\n",
              "      <td>4.813846</td>\n",
              "      <td>4.791299</td>\n",
              "      <td>3.094036</td>\n",
              "      <td>8.644983</td>\n",
              "      <td>4.045898</td>\n",
              "      <td>3.605055</td>\n",
              "      <td>7.525257</td>\n",
              "      <td>7.810126</td>\n",
              "      <td>8.113801</td>\n",
              "      <td>3.892474</td>\n",
              "      <td>3.315494</td>\n",
              "      <td>2.764505</td>\n",
              "      <td>2.785968</td>\n",
              "      <td>4.338340</td>\n",
              "      <td>4.739177</td>\n",
              "      <td>5.037259</td>\n",
              "      <td>2.921308</td>\n",
              "      <td>9.848256</td>\n",
              "      <td>5.355027</td>\n",
              "      <td>3.647747</td>\n",
              "      <td>4.413179</td>\n",
              "      <td>3.730797</td>\n",
              "      <td>3.696454</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>4.889988</td>\n",
              "      <td>3.318492</td>\n",
              "      <td>6.188865</td>\n",
              "      <td>7.171880</td>\n",
              "      <td>...</td>\n",
              "      <td>3.509842</td>\n",
              "      <td>2.945893</td>\n",
              "      <td>2.897693</td>\n",
              "      <td>2.938409</td>\n",
              "      <td>2.959839</td>\n",
              "      <td>5.791348</td>\n",
              "      <td>2.774638</td>\n",
              "      <td>3.657118</td>\n",
              "      <td>3.087958</td>\n",
              "      <td>3.468064</td>\n",
              "      <td>4.287674</td>\n",
              "      <td>3.425382</td>\n",
              "      <td>3.452500</td>\n",
              "      <td>3.704773</td>\n",
              "      <td>3.264937</td>\n",
              "      <td>2.897396</td>\n",
              "      <td>2.763486</td>\n",
              "      <td>2.836450</td>\n",
              "      <td>8.070651</td>\n",
              "      <td>3.715302</td>\n",
              "      <td>3.045340</td>\n",
              "      <td>3.016188</td>\n",
              "      <td>4.370638</td>\n",
              "      <td>3.841095</td>\n",
              "      <td>4.062441</td>\n",
              "      <td>2.834466</td>\n",
              "      <td>2.777204</td>\n",
              "      <td>4.012017</td>\n",
              "      <td>3.557362</td>\n",
              "      <td>2.443743</td>\n",
              "      <td>4.243448</td>\n",
              "      <td>3.034131</td>\n",
              "      <td>3.031143</td>\n",
              "      <td>9.161868</td>\n",
              "      <td>3.412558</td>\n",
              "      <td>2.974475</td>\n",
              "      <td>3.088841</td>\n",
              "      <td>10.742651</td>\n",
              "      <td>3.317945</td>\n",
              "      <td>6.203929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>8.089255</td>\n",
              "      <td>2.521169</td>\n",
              "      <td>10.792750</td>\n",
              "      <td>4.443337</td>\n",
              "      <td>3.238305</td>\n",
              "      <td>5.209472</td>\n",
              "      <td>8.073389</td>\n",
              "      <td>5.643811</td>\n",
              "      <td>5.040952</td>\n",
              "      <td>3.344979</td>\n",
              "      <td>6.669064</td>\n",
              "      <td>3.597366</td>\n",
              "      <td>5.859500</td>\n",
              "      <td>4.286220</td>\n",
              "      <td>3.372714</td>\n",
              "      <td>7.830936</td>\n",
              "      <td>3.256537</td>\n",
              "      <td>4.540383</td>\n",
              "      <td>6.066356</td>\n",
              "      <td>7.182077</td>\n",
              "      <td>6.948601</td>\n",
              "      <td>7.073437</td>\n",
              "      <td>3.436440</td>\n",
              "      <td>2.813419</td>\n",
              "      <td>2.910087</td>\n",
              "      <td>6.683538</td>\n",
              "      <td>4.868739</td>\n",
              "      <td>4.611973</td>\n",
              "      <td>2.759914</td>\n",
              "      <td>10.354026</td>\n",
              "      <td>3.361741</td>\n",
              "      <td>3.174112</td>\n",
              "      <td>7.346287</td>\n",
              "      <td>3.652134</td>\n",
              "      <td>4.544815</td>\n",
              "      <td>3.064199</td>\n",
              "      <td>6.645925</td>\n",
              "      <td>8.224078</td>\n",
              "      <td>5.834752</td>\n",
              "      <td>9.025969</td>\n",
              "      <td>...</td>\n",
              "      <td>3.357575</td>\n",
              "      <td>3.867752</td>\n",
              "      <td>3.028672</td>\n",
              "      <td>3.581341</td>\n",
              "      <td>4.196880</td>\n",
              "      <td>7.234274</td>\n",
              "      <td>3.039980</td>\n",
              "      <td>3.730557</td>\n",
              "      <td>3.125049</td>\n",
              "      <td>3.525079</td>\n",
              "      <td>3.531308</td>\n",
              "      <td>3.229062</td>\n",
              "      <td>3.505198</td>\n",
              "      <td>3.980961</td>\n",
              "      <td>2.958662</td>\n",
              "      <td>2.660811</td>\n",
              "      <td>2.605696</td>\n",
              "      <td>3.340643</td>\n",
              "      <td>7.826121</td>\n",
              "      <td>4.278568</td>\n",
              "      <td>2.959811</td>\n",
              "      <td>4.133042</td>\n",
              "      <td>4.213764</td>\n",
              "      <td>3.221974</td>\n",
              "      <td>4.686370</td>\n",
              "      <td>2.887736</td>\n",
              "      <td>3.049697</td>\n",
              "      <td>4.393847</td>\n",
              "      <td>3.532841</td>\n",
              "      <td>2.603842</td>\n",
              "      <td>5.084844</td>\n",
              "      <td>2.981869</td>\n",
              "      <td>3.703721</td>\n",
              "      <td>8.473612</td>\n",
              "      <td>3.640390</td>\n",
              "      <td>2.903894</td>\n",
              "      <td>2.847505</td>\n",
              "      <td>8.544696</td>\n",
              "      <td>3.174515</td>\n",
              "      <td>7.119213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>3.112333</td>\n",
              "      <td>2.870468</td>\n",
              "      <td>9.873902</td>\n",
              "      <td>4.266828</td>\n",
              "      <td>3.027742</td>\n",
              "      <td>3.407148</td>\n",
              "      <td>5.760610</td>\n",
              "      <td>5.834256</td>\n",
              "      <td>5.550722</td>\n",
              "      <td>3.272994</td>\n",
              "      <td>7.012936</td>\n",
              "      <td>3.629980</td>\n",
              "      <td>6.321085</td>\n",
              "      <td>5.754581</td>\n",
              "      <td>3.046196</td>\n",
              "      <td>8.088148</td>\n",
              "      <td>3.935535</td>\n",
              "      <td>3.327640</td>\n",
              "      <td>8.185968</td>\n",
              "      <td>5.663629</td>\n",
              "      <td>8.362776</td>\n",
              "      <td>5.063248</td>\n",
              "      <td>6.987454</td>\n",
              "      <td>2.693494</td>\n",
              "      <td>3.622282</td>\n",
              "      <td>5.794690</td>\n",
              "      <td>4.090673</td>\n",
              "      <td>4.800284</td>\n",
              "      <td>7.833970</td>\n",
              "      <td>8.839499</td>\n",
              "      <td>7.360885</td>\n",
              "      <td>2.992044</td>\n",
              "      <td>8.010674</td>\n",
              "      <td>4.008153</td>\n",
              "      <td>4.142386</td>\n",
              "      <td>2.912428</td>\n",
              "      <td>4.811472</td>\n",
              "      <td>3.536157</td>\n",
              "      <td>4.903923</td>\n",
              "      <td>7.748020</td>\n",
              "      <td>...</td>\n",
              "      <td>3.243715</td>\n",
              "      <td>2.689623</td>\n",
              "      <td>3.236872</td>\n",
              "      <td>3.432355</td>\n",
              "      <td>3.421215</td>\n",
              "      <td>7.751206</td>\n",
              "      <td>2.824329</td>\n",
              "      <td>3.143819</td>\n",
              "      <td>3.028617</td>\n",
              "      <td>3.244888</td>\n",
              "      <td>3.729339</td>\n",
              "      <td>3.326140</td>\n",
              "      <td>7.257399</td>\n",
              "      <td>3.477507</td>\n",
              "      <td>3.041844</td>\n",
              "      <td>2.470981</td>\n",
              "      <td>2.744415</td>\n",
              "      <td>2.763764</td>\n",
              "      <td>7.848633</td>\n",
              "      <td>3.853900</td>\n",
              "      <td>3.185840</td>\n",
              "      <td>2.910977</td>\n",
              "      <td>4.839607</td>\n",
              "      <td>3.116006</td>\n",
              "      <td>4.099547</td>\n",
              "      <td>3.029919</td>\n",
              "      <td>2.766441</td>\n",
              "      <td>3.871248</td>\n",
              "      <td>3.033338</td>\n",
              "      <td>2.531280</td>\n",
              "      <td>4.986124</td>\n",
              "      <td>2.992148</td>\n",
              "      <td>3.111383</td>\n",
              "      <td>8.468564</td>\n",
              "      <td>3.142641</td>\n",
              "      <td>2.857956</td>\n",
              "      <td>2.832840</td>\n",
              "      <td>9.900550</td>\n",
              "      <td>3.243563</td>\n",
              "      <td>7.622261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>7.153127</td>\n",
              "      <td>2.834285</td>\n",
              "      <td>10.788218</td>\n",
              "      <td>4.100493</td>\n",
              "      <td>3.330279</td>\n",
              "      <td>3.063284</td>\n",
              "      <td>8.191465</td>\n",
              "      <td>5.329834</td>\n",
              "      <td>5.877487</td>\n",
              "      <td>4.215433</td>\n",
              "      <td>8.179745</td>\n",
              "      <td>3.642221</td>\n",
              "      <td>3.772388</td>\n",
              "      <td>3.829010</td>\n",
              "      <td>2.974629</td>\n",
              "      <td>8.492699</td>\n",
              "      <td>4.311844</td>\n",
              "      <td>3.281952</td>\n",
              "      <td>4.967268</td>\n",
              "      <td>6.539451</td>\n",
              "      <td>9.611164</td>\n",
              "      <td>3.330025</td>\n",
              "      <td>3.576292</td>\n",
              "      <td>2.818373</td>\n",
              "      <td>2.721674</td>\n",
              "      <td>9.964246</td>\n",
              "      <td>3.965856</td>\n",
              "      <td>4.967207</td>\n",
              "      <td>3.266466</td>\n",
              "      <td>9.057700</td>\n",
              "      <td>3.923060</td>\n",
              "      <td>2.924887</td>\n",
              "      <td>4.646153</td>\n",
              "      <td>3.633279</td>\n",
              "      <td>4.682117</td>\n",
              "      <td>3.067121</td>\n",
              "      <td>5.155566</td>\n",
              "      <td>6.074918</td>\n",
              "      <td>6.444457</td>\n",
              "      <td>8.024425</td>\n",
              "      <td>...</td>\n",
              "      <td>3.273818</td>\n",
              "      <td>6.886046</td>\n",
              "      <td>3.098539</td>\n",
              "      <td>3.004521</td>\n",
              "      <td>2.998243</td>\n",
              "      <td>5.495573</td>\n",
              "      <td>2.961595</td>\n",
              "      <td>5.136811</td>\n",
              "      <td>3.074840</td>\n",
              "      <td>3.239312</td>\n",
              "      <td>4.405299</td>\n",
              "      <td>3.560002</td>\n",
              "      <td>6.473561</td>\n",
              "      <td>3.565383</td>\n",
              "      <td>3.198007</td>\n",
              "      <td>2.824467</td>\n",
              "      <td>2.690283</td>\n",
              "      <td>3.047576</td>\n",
              "      <td>8.762100</td>\n",
              "      <td>10.811478</td>\n",
              "      <td>3.435318</td>\n",
              "      <td>3.407199</td>\n",
              "      <td>3.764979</td>\n",
              "      <td>3.210291</td>\n",
              "      <td>4.095968</td>\n",
              "      <td>3.053006</td>\n",
              "      <td>3.074055</td>\n",
              "      <td>3.768554</td>\n",
              "      <td>3.745116</td>\n",
              "      <td>2.734454</td>\n",
              "      <td>4.362137</td>\n",
              "      <td>2.964605</td>\n",
              "      <td>3.300715</td>\n",
              "      <td>8.386096</td>\n",
              "      <td>2.927523</td>\n",
              "      <td>3.033662</td>\n",
              "      <td>2.817057</td>\n",
              "      <td>9.071943</td>\n",
              "      <td>3.324517</td>\n",
              "      <td>7.290293</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1018 rows × 17736 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05eaa1f2-3a51-4e54-aae1-c516e37bbf89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05eaa1f2-3a51-4e54-aae1-c516e37bbf89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05eaa1f2-3a51-4e54-aae1-c516e37bbf89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ENSG00000000003  ENSG00000000005  ...  ENSG00000266433  ENSG00000266753\n",
              "0            7.632023         2.964585  ...         3.073724         7.284733\n",
              "1            7.548671         2.777716  ...         3.000182         8.504804\n",
              "2            8.712338         2.643508  ...         2.916274         7.059092\n",
              "3            7.797142         2.817923  ...         3.256500         7.318125\n",
              "4            7.729268         2.957739  ...         3.396126         7.726867\n",
              "...               ...              ...  ...              ...              ...\n",
              "1013         8.441628         2.639276  ...         3.435411        10.392042\n",
              "1014         8.422922         2.879890  ...         3.317945         6.203929\n",
              "1015         8.089255         2.521169  ...         3.174515         7.119213\n",
              "1016         3.112333         2.870468  ...         3.243563         7.622261\n",
              "1017         7.153127         2.834285  ...         3.324517         7.290293\n",
              "\n",
              "[1018 rows x 17736 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T84qD2ye3mGT"
      },
      "source": [
        "df = df.astype({\"COSMIC_ID\": int})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.iloc[:, :1]"
      ],
      "metadata": {
        "id": "DELia46z-uqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del df1[\"COSMIC_ID\"]\n",
        "\n",
        "columns1 = df.columns"
      ],
      "metadata": {
        "id": "9AgxG6Zv3blD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qqvrzTQD3mJg",
        "outputId": "65fb6cbc-3ebe-412d-c607-7f732bd6b8a1"
      },
      "source": [
        "drug_data = pd.read_csv('/content/drive/MyDrive/Thesis2_Dec2021/data_genes/Drug Responce_100_gdsc_sdf.csv', encoding= 'unicode_escape')\n",
        "drug_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-062825b7-0f10-4bd5-b289-a741dde48165\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>749710</td>\n",
              "      <td>HCC1143</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.343315</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>749711</td>\n",
              "      <td>HCC1187</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.736985</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>749712</td>\n",
              "      <td>HCC1395</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-2.309078</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>749713</td>\n",
              "      <td>HCC1599</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-3.106684</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65398</th>\n",
              "      <td>1290798</td>\n",
              "      <td>EFM-192A</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>3.576583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65399</th>\n",
              "      <td>1290905</td>\n",
              "      <td>HCC1428</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>1.402466</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65400</th>\n",
              "      <td>1290922</td>\n",
              "      <td>HDQ-P1</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>2.762460</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65401</th>\n",
              "      <td>1298157</td>\n",
              "      <td>JIMT-1</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>3.442930</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65402</th>\n",
              "      <td>1303900</td>\n",
              "      <td>HCC1500</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>2.767916</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65403 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-062825b7-0f10-4bd5-b289-a741dde48165')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-062825b7-0f10-4bd5-b289-a741dde48165 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-062825b7-0f10-4bd5-b289-a741dde48165');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       COSMIC_ID CELL_LINE_NAME  ... Unnamed: 6  Unnamed: 7\n",
              "0         749709        HCC1954  ...        NaN         NaN\n",
              "1         749710        HCC1143  ...        NaN         NaN\n",
              "2         749711        HCC1187  ...        NaN         NaN\n",
              "3         749712        HCC1395  ...        NaN         NaN\n",
              "4         749713        HCC1599  ...        NaN         NaN\n",
              "...          ...            ...  ...        ...         ...\n",
              "65398    1290798       EFM-192A  ...        NaN         NaN\n",
              "65399    1290905        HCC1428  ...        NaN         NaN\n",
              "65400    1290922         HDQ-P1  ...        NaN         NaN\n",
              "65401    1298157         JIMT-1  ...        NaN         NaN\n",
              "65402    1303900        HCC1500  ...        NaN         NaN\n",
              "\n",
              "[65403 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDGATAx73mQR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e701aa89-564b-4ec0-c83a-18a170eaab0c"
      },
      "source": [
        "del drug_data['Unnamed: 4']\n",
        "del drug_data['Unnamed: 5']\n",
        "del drug_data['Unnamed: 6']\n",
        "del drug_data['Unnamed: 7']\n",
        "# del drug_data['Unnamed: 8']\n",
        "# del drug_data['Unnamed: 9']\n",
        "# del drug_data['Unnamed: 10']\n",
        "# del drug_data['Unnamed: 11']\n",
        "# del drug_data['Unnamed: 12']\n",
        "drug_data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1ee59c5a-6184-49f2-b87b-5834aaf5b2dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>749710</td>\n",
              "      <td>HCC1143</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.343315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>749711</td>\n",
              "      <td>HCC1187</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.736985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>749712</td>\n",
              "      <td>HCC1395</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-2.309078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>749713</td>\n",
              "      <td>HCC1599</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-3.106684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65398</th>\n",
              "      <td>1290798</td>\n",
              "      <td>EFM-192A</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>3.576583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65399</th>\n",
              "      <td>1290905</td>\n",
              "      <td>HCC1428</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>1.402466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65400</th>\n",
              "      <td>1290922</td>\n",
              "      <td>HDQ-P1</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>2.762460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65401</th>\n",
              "      <td>1298157</td>\n",
              "      <td>JIMT-1</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>3.442930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65402</th>\n",
              "      <td>1303900</td>\n",
              "      <td>HCC1500</td>\n",
              "      <td>JQ1</td>\n",
              "      <td>2.767916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65403 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ee59c5a-6184-49f2-b87b-5834aaf5b2dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ee59c5a-6184-49f2-b87b-5834aaf5b2dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ee59c5a-6184-49f2-b87b-5834aaf5b2dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       COSMIC_ID CELL_LINE_NAME     DRUG_NAME   LN_IC50\n",
              "0         749709        HCC1954  Camptothecin -0.251083\n",
              "1         749710        HCC1143  Camptothecin  1.343315\n",
              "2         749711        HCC1187  Camptothecin  1.736985\n",
              "3         749712        HCC1395  Camptothecin -2.309078\n",
              "4         749713        HCC1599  Camptothecin -3.106684\n",
              "...          ...            ...           ...       ...\n",
              "65398    1290798       EFM-192A           JQ1  3.576583\n",
              "65399    1290905        HCC1428           JQ1  1.402466\n",
              "65400    1290922         HDQ-P1           JQ1  2.762460\n",
              "65401    1298157         JIMT-1           JQ1  3.442930\n",
              "65402    1303900        HCC1500           JQ1  2.767916\n",
              "\n",
              "[65403 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGvJk-ZV3_fC"
      },
      "source": [
        "### **Normalization (Min Max Scaler)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N713H8ij3-0P",
        "outputId": "925de787-c643-4897-c6fe-40a3d5b7403e"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "x= df.iloc[:, 1:].values\n",
        "#x= df.iloc[:, :].values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "expdatanorm = pd.DataFrame(x_scaled)\n",
        "print ('The shape of variance matrix =' , expdatanorm.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of variance matrix = (1018, 17736)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "expdatanorm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "6Zh1SJOn8XUE",
        "outputId": "49eee73b-9311-4179-ed97-1627336ea7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7959946b-f9f6-4186-b9a2-61d77c63aff7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>17696</th>\n",
              "      <th>17697</th>\n",
              "      <th>17698</th>\n",
              "      <th>17699</th>\n",
              "      <th>17700</th>\n",
              "      <th>17701</th>\n",
              "      <th>17702</th>\n",
              "      <th>17703</th>\n",
              "      <th>17704</th>\n",
              "      <th>17705</th>\n",
              "      <th>17706</th>\n",
              "      <th>17707</th>\n",
              "      <th>17708</th>\n",
              "      <th>17709</th>\n",
              "      <th>17710</th>\n",
              "      <th>17711</th>\n",
              "      <th>17712</th>\n",
              "      <th>17713</th>\n",
              "      <th>17714</th>\n",
              "      <th>17715</th>\n",
              "      <th>17716</th>\n",
              "      <th>17717</th>\n",
              "      <th>17718</th>\n",
              "      <th>17719</th>\n",
              "      <th>17720</th>\n",
              "      <th>17721</th>\n",
              "      <th>17722</th>\n",
              "      <th>17723</th>\n",
              "      <th>17724</th>\n",
              "      <th>17725</th>\n",
              "      <th>17726</th>\n",
              "      <th>17727</th>\n",
              "      <th>17728</th>\n",
              "      <th>17729</th>\n",
              "      <th>17730</th>\n",
              "      <th>17731</th>\n",
              "      <th>17732</th>\n",
              "      <th>17733</th>\n",
              "      <th>17734</th>\n",
              "      <th>17735</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.090174</td>\n",
              "      <td>0.831734</td>\n",
              "      <td>0.134854</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.056670</td>\n",
              "      <td>0.092200</td>\n",
              "      <td>0.711781</td>\n",
              "      <td>0.295762</td>\n",
              "      <td>0.340987</td>\n",
              "      <td>0.278234</td>\n",
              "      <td>0.742342</td>\n",
              "      <td>0.599873</td>\n",
              "      <td>0.310306</td>\n",
              "      <td>0.147415</td>\n",
              "      <td>0.031824</td>\n",
              "      <td>0.418007</td>\n",
              "      <td>0.172443</td>\n",
              "      <td>0.319434</td>\n",
              "      <td>0.680111</td>\n",
              "      <td>0.526486</td>\n",
              "      <td>0.679726</td>\n",
              "      <td>0.125355</td>\n",
              "      <td>0.051405</td>\n",
              "      <td>0.186721</td>\n",
              "      <td>0.031059</td>\n",
              "      <td>0.190874</td>\n",
              "      <td>0.342158</td>\n",
              "      <td>0.230392</td>\n",
              "      <td>0.035336</td>\n",
              "      <td>0.820529</td>\n",
              "      <td>0.471317</td>\n",
              "      <td>0.172845</td>\n",
              "      <td>0.151907</td>\n",
              "      <td>0.260020</td>\n",
              "      <td>0.199171</td>\n",
              "      <td>0.066666</td>\n",
              "      <td>0.361543</td>\n",
              "      <td>0.977863</td>\n",
              "      <td>0.429066</td>\n",
              "      <td>0.756991</td>\n",
              "      <td>...</td>\n",
              "      <td>0.172654</td>\n",
              "      <td>0.320180</td>\n",
              "      <td>0.066718</td>\n",
              "      <td>0.132262</td>\n",
              "      <td>0.133767</td>\n",
              "      <td>0.307158</td>\n",
              "      <td>0.231446</td>\n",
              "      <td>0.019054</td>\n",
              "      <td>0.282120</td>\n",
              "      <td>0.148932</td>\n",
              "      <td>0.259837</td>\n",
              "      <td>0.092130</td>\n",
              "      <td>0.032295</td>\n",
              "      <td>0.217113</td>\n",
              "      <td>0.043037</td>\n",
              "      <td>0.057655</td>\n",
              "      <td>0.072909</td>\n",
              "      <td>0.617143</td>\n",
              "      <td>0.491339</td>\n",
              "      <td>0.060244</td>\n",
              "      <td>0.083015</td>\n",
              "      <td>0.139713</td>\n",
              "      <td>0.221998</td>\n",
              "      <td>0.132657</td>\n",
              "      <td>0.669727</td>\n",
              "      <td>0.168623</td>\n",
              "      <td>0.326715</td>\n",
              "      <td>0.502761</td>\n",
              "      <td>0.135343</td>\n",
              "      <td>0.038248</td>\n",
              "      <td>0.759824</td>\n",
              "      <td>0.244857</td>\n",
              "      <td>0.086937</td>\n",
              "      <td>0.270578</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.061037</td>\n",
              "      <td>0.294185</td>\n",
              "      <td>0.662015</td>\n",
              "      <td>0.187001</td>\n",
              "      <td>0.398991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.054091</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.260056</td>\n",
              "      <td>0.293690</td>\n",
              "      <td>0.035300</td>\n",
              "      <td>0.570020</td>\n",
              "      <td>0.498266</td>\n",
              "      <td>0.374794</td>\n",
              "      <td>0.739398</td>\n",
              "      <td>0.338531</td>\n",
              "      <td>0.413151</td>\n",
              "      <td>0.502340</td>\n",
              "      <td>0.607386</td>\n",
              "      <td>0.110605</td>\n",
              "      <td>0.043824</td>\n",
              "      <td>0.421579</td>\n",
              "      <td>0.216578</td>\n",
              "      <td>0.376647</td>\n",
              "      <td>0.683961</td>\n",
              "      <td>0.578262</td>\n",
              "      <td>0.681248</td>\n",
              "      <td>0.055207</td>\n",
              "      <td>0.035425</td>\n",
              "      <td>0.022377</td>\n",
              "      <td>0.067788</td>\n",
              "      <td>0.305928</td>\n",
              "      <td>0.245438</td>\n",
              "      <td>0.336185</td>\n",
              "      <td>0.041887</td>\n",
              "      <td>0.698167</td>\n",
              "      <td>0.069602</td>\n",
              "      <td>0.097481</td>\n",
              "      <td>0.213374</td>\n",
              "      <td>0.439000</td>\n",
              "      <td>0.216370</td>\n",
              "      <td>0.046950</td>\n",
              "      <td>0.233082</td>\n",
              "      <td>0.050551</td>\n",
              "      <td>0.613009</td>\n",
              "      <td>0.784067</td>\n",
              "      <td>...</td>\n",
              "      <td>0.536404</td>\n",
              "      <td>0.026991</td>\n",
              "      <td>0.034909</td>\n",
              "      <td>0.241586</td>\n",
              "      <td>0.184873</td>\n",
              "      <td>0.440619</td>\n",
              "      <td>0.293674</td>\n",
              "      <td>0.064394</td>\n",
              "      <td>0.261089</td>\n",
              "      <td>0.271386</td>\n",
              "      <td>0.560891</td>\n",
              "      <td>0.080544</td>\n",
              "      <td>0.647544</td>\n",
              "      <td>0.254231</td>\n",
              "      <td>0.054425</td>\n",
              "      <td>0.055732</td>\n",
              "      <td>0.087818</td>\n",
              "      <td>0.440152</td>\n",
              "      <td>0.760993</td>\n",
              "      <td>0.040269</td>\n",
              "      <td>0.098719</td>\n",
              "      <td>0.046183</td>\n",
              "      <td>0.263360</td>\n",
              "      <td>0.201099</td>\n",
              "      <td>0.554002</td>\n",
              "      <td>0.134859</td>\n",
              "      <td>0.375896</td>\n",
              "      <td>0.215475</td>\n",
              "      <td>0.177461</td>\n",
              "      <td>0.062879</td>\n",
              "      <td>0.486777</td>\n",
              "      <td>0.464771</td>\n",
              "      <td>0.077337</td>\n",
              "      <td>0.507740</td>\n",
              "      <td>0.111780</td>\n",
              "      <td>0.051589</td>\n",
              "      <td>0.356246</td>\n",
              "      <td>0.454642</td>\n",
              "      <td>0.134000</td>\n",
              "      <td>0.590433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.028176</td>\n",
              "      <td>0.772948</td>\n",
              "      <td>0.229411</td>\n",
              "      <td>0.124901</td>\n",
              "      <td>0.046320</td>\n",
              "      <td>0.020954</td>\n",
              "      <td>0.709995</td>\n",
              "      <td>0.322153</td>\n",
              "      <td>0.287242</td>\n",
              "      <td>0.412678</td>\n",
              "      <td>0.393641</td>\n",
              "      <td>0.311474</td>\n",
              "      <td>0.321922</td>\n",
              "      <td>0.218414</td>\n",
              "      <td>0.016277</td>\n",
              "      <td>0.343545</td>\n",
              "      <td>0.206756</td>\n",
              "      <td>0.245505</td>\n",
              "      <td>0.672980</td>\n",
              "      <td>0.383428</td>\n",
              "      <td>0.739074</td>\n",
              "      <td>0.185688</td>\n",
              "      <td>0.036071</td>\n",
              "      <td>0.017455</td>\n",
              "      <td>0.100955</td>\n",
              "      <td>0.214566</td>\n",
              "      <td>0.154880</td>\n",
              "      <td>0.203514</td>\n",
              "      <td>0.020999</td>\n",
              "      <td>0.701153</td>\n",
              "      <td>0.044331</td>\n",
              "      <td>0.099277</td>\n",
              "      <td>0.015990</td>\n",
              "      <td>0.412989</td>\n",
              "      <td>0.159140</td>\n",
              "      <td>0.234605</td>\n",
              "      <td>0.370474</td>\n",
              "      <td>0.778290</td>\n",
              "      <td>0.393368</td>\n",
              "      <td>0.730091</td>\n",
              "      <td>...</td>\n",
              "      <td>0.165700</td>\n",
              "      <td>0.077543</td>\n",
              "      <td>0.050955</td>\n",
              "      <td>0.244059</td>\n",
              "      <td>0.122437</td>\n",
              "      <td>0.521862</td>\n",
              "      <td>0.262982</td>\n",
              "      <td>0.079300</td>\n",
              "      <td>0.474512</td>\n",
              "      <td>0.191074</td>\n",
              "      <td>0.254567</td>\n",
              "      <td>0.056056</td>\n",
              "      <td>0.721048</td>\n",
              "      <td>0.120380</td>\n",
              "      <td>0.012275</td>\n",
              "      <td>0.037707</td>\n",
              "      <td>0.052386</td>\n",
              "      <td>0.277275</td>\n",
              "      <td>0.696679</td>\n",
              "      <td>0.043741</td>\n",
              "      <td>0.037792</td>\n",
              "      <td>0.072692</td>\n",
              "      <td>0.220876</td>\n",
              "      <td>0.200668</td>\n",
              "      <td>0.401915</td>\n",
              "      <td>0.163329</td>\n",
              "      <td>0.437672</td>\n",
              "      <td>0.162127</td>\n",
              "      <td>0.210804</td>\n",
              "      <td>0.034210</td>\n",
              "      <td>0.082525</td>\n",
              "      <td>0.339761</td>\n",
              "      <td>0.052709</td>\n",
              "      <td>0.515632</td>\n",
              "      <td>0.074360</td>\n",
              "      <td>0.040184</td>\n",
              "      <td>0.315879</td>\n",
              "      <td>0.477919</td>\n",
              "      <td>0.073528</td>\n",
              "      <td>0.363586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.061855</td>\n",
              "      <td>0.773271</td>\n",
              "      <td>0.259174</td>\n",
              "      <td>0.234437</td>\n",
              "      <td>0.028955</td>\n",
              "      <td>0.501000</td>\n",
              "      <td>0.769090</td>\n",
              "      <td>0.348427</td>\n",
              "      <td>0.260334</td>\n",
              "      <td>0.194173</td>\n",
              "      <td>0.590428</td>\n",
              "      <td>0.182881</td>\n",
              "      <td>0.468570</td>\n",
              "      <td>0.167707</td>\n",
              "      <td>0.022746</td>\n",
              "      <td>0.196373</td>\n",
              "      <td>0.198716</td>\n",
              "      <td>0.092587</td>\n",
              "      <td>0.730317</td>\n",
              "      <td>0.312400</td>\n",
              "      <td>0.541029</td>\n",
              "      <td>0.042277</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.022821</td>\n",
              "      <td>0.129346</td>\n",
              "      <td>0.221094</td>\n",
              "      <td>0.351700</td>\n",
              "      <td>0.184301</td>\n",
              "      <td>0.034182</td>\n",
              "      <td>0.714869</td>\n",
              "      <td>0.084176</td>\n",
              "      <td>0.171028</td>\n",
              "      <td>0.596462</td>\n",
              "      <td>0.206212</td>\n",
              "      <td>0.186972</td>\n",
              "      <td>0.196681</td>\n",
              "      <td>0.499387</td>\n",
              "      <td>0.497512</td>\n",
              "      <td>0.258113</td>\n",
              "      <td>0.563841</td>\n",
              "      <td>...</td>\n",
              "      <td>0.140226</td>\n",
              "      <td>0.316679</td>\n",
              "      <td>0.166627</td>\n",
              "      <td>0.274978</td>\n",
              "      <td>0.151700</td>\n",
              "      <td>0.252854</td>\n",
              "      <td>0.376361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366580</td>\n",
              "      <td>0.126492</td>\n",
              "      <td>0.297160</td>\n",
              "      <td>0.059973</td>\n",
              "      <td>0.603815</td>\n",
              "      <td>0.467051</td>\n",
              "      <td>0.032428</td>\n",
              "      <td>0.042165</td>\n",
              "      <td>0.062093</td>\n",
              "      <td>0.381049</td>\n",
              "      <td>0.615017</td>\n",
              "      <td>0.031989</td>\n",
              "      <td>0.064793</td>\n",
              "      <td>0.054981</td>\n",
              "      <td>0.085451</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.336091</td>\n",
              "      <td>0.181669</td>\n",
              "      <td>0.320983</td>\n",
              "      <td>0.303929</td>\n",
              "      <td>0.035810</td>\n",
              "      <td>0.036751</td>\n",
              "      <td>0.084549</td>\n",
              "      <td>0.372276</td>\n",
              "      <td>0.037546</td>\n",
              "      <td>0.267656</td>\n",
              "      <td>0.400978</td>\n",
              "      <td>0.133843</td>\n",
              "      <td>0.267383</td>\n",
              "      <td>0.656043</td>\n",
              "      <td>0.318726</td>\n",
              "      <td>0.404231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.088852</td>\n",
              "      <td>0.836364</td>\n",
              "      <td>0.336107</td>\n",
              "      <td>0.330414</td>\n",
              "      <td>0.016621</td>\n",
              "      <td>0.070789</td>\n",
              "      <td>0.724211</td>\n",
              "      <td>0.355544</td>\n",
              "      <td>0.083657</td>\n",
              "      <td>0.126718</td>\n",
              "      <td>0.494024</td>\n",
              "      <td>0.489154</td>\n",
              "      <td>0.529315</td>\n",
              "      <td>0.038617</td>\n",
              "      <td>0.043574</td>\n",
              "      <td>0.515520</td>\n",
              "      <td>0.189364</td>\n",
              "      <td>0.397824</td>\n",
              "      <td>0.595536</td>\n",
              "      <td>0.196272</td>\n",
              "      <td>0.648330</td>\n",
              "      <td>0.201501</td>\n",
              "      <td>0.058255</td>\n",
              "      <td>0.040653</td>\n",
              "      <td>0.072281</td>\n",
              "      <td>0.213277</td>\n",
              "      <td>0.454418</td>\n",
              "      <td>0.382668</td>\n",
              "      <td>0.034089</td>\n",
              "      <td>0.912117</td>\n",
              "      <td>0.037130</td>\n",
              "      <td>0.085330</td>\n",
              "      <td>0.108092</td>\n",
              "      <td>0.111587</td>\n",
              "      <td>0.280351</td>\n",
              "      <td>0.265903</td>\n",
              "      <td>0.279810</td>\n",
              "      <td>0.574992</td>\n",
              "      <td>0.620433</td>\n",
              "      <td>0.622026</td>\n",
              "      <td>...</td>\n",
              "      <td>0.413198</td>\n",
              "      <td>0.113996</td>\n",
              "      <td>0.012176</td>\n",
              "      <td>0.121574</td>\n",
              "      <td>0.176264</td>\n",
              "      <td>0.552606</td>\n",
              "      <td>0.197809</td>\n",
              "      <td>0.027883</td>\n",
              "      <td>0.271277</td>\n",
              "      <td>0.261868</td>\n",
              "      <td>0.196197</td>\n",
              "      <td>0.060743</td>\n",
              "      <td>0.115823</td>\n",
              "      <td>0.128144</td>\n",
              "      <td>0.039210</td>\n",
              "      <td>0.037267</td>\n",
              "      <td>0.042149</td>\n",
              "      <td>0.240381</td>\n",
              "      <td>0.591982</td>\n",
              "      <td>0.066232</td>\n",
              "      <td>0.088704</td>\n",
              "      <td>0.081633</td>\n",
              "      <td>0.190575</td>\n",
              "      <td>0.252984</td>\n",
              "      <td>0.681710</td>\n",
              "      <td>0.149895</td>\n",
              "      <td>0.287542</td>\n",
              "      <td>0.233630</td>\n",
              "      <td>0.087411</td>\n",
              "      <td>0.009784</td>\n",
              "      <td>0.177255</td>\n",
              "      <td>0.180061</td>\n",
              "      <td>0.037319</td>\n",
              "      <td>0.586302</td>\n",
              "      <td>0.259986</td>\n",
              "      <td>0.073348</td>\n",
              "      <td>0.333650</td>\n",
              "      <td>0.651974</td>\n",
              "      <td>0.419353</td>\n",
              "      <td>0.468367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>0.027359</td>\n",
              "      <td>0.959507</td>\n",
              "      <td>0.359467</td>\n",
              "      <td>0.515710</td>\n",
              "      <td>0.044864</td>\n",
              "      <td>0.092744</td>\n",
              "      <td>0.710230</td>\n",
              "      <td>0.355844</td>\n",
              "      <td>0.248984</td>\n",
              "      <td>0.345024</td>\n",
              "      <td>0.694234</td>\n",
              "      <td>0.523141</td>\n",
              "      <td>0.163646</td>\n",
              "      <td>0.307159</td>\n",
              "      <td>0.044090</td>\n",
              "      <td>0.414590</td>\n",
              "      <td>0.106494</td>\n",
              "      <td>0.416769</td>\n",
              "      <td>0.638885</td>\n",
              "      <td>0.402110</td>\n",
              "      <td>0.523680</td>\n",
              "      <td>0.080156</td>\n",
              "      <td>0.052827</td>\n",
              "      <td>0.048459</td>\n",
              "      <td>0.111618</td>\n",
              "      <td>0.126456</td>\n",
              "      <td>0.312534</td>\n",
              "      <td>0.277837</td>\n",
              "      <td>0.037908</td>\n",
              "      <td>0.806088</td>\n",
              "      <td>0.096805</td>\n",
              "      <td>0.133687</td>\n",
              "      <td>0.066497</td>\n",
              "      <td>0.239089</td>\n",
              "      <td>0.199501</td>\n",
              "      <td>0.151576</td>\n",
              "      <td>0.280078</td>\n",
              "      <td>0.597179</td>\n",
              "      <td>0.553442</td>\n",
              "      <td>0.708737</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279965</td>\n",
              "      <td>0.495366</td>\n",
              "      <td>0.071721</td>\n",
              "      <td>0.220917</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>0.397822</td>\n",
              "      <td>0.318628</td>\n",
              "      <td>0.056417</td>\n",
              "      <td>0.499499</td>\n",
              "      <td>0.532195</td>\n",
              "      <td>0.254144</td>\n",
              "      <td>0.089226</td>\n",
              "      <td>0.081519</td>\n",
              "      <td>0.133549</td>\n",
              "      <td>0.131000</td>\n",
              "      <td>0.085147</td>\n",
              "      <td>0.038093</td>\n",
              "      <td>0.459311</td>\n",
              "      <td>0.587845</td>\n",
              "      <td>0.068397</td>\n",
              "      <td>0.101239</td>\n",
              "      <td>0.097643</td>\n",
              "      <td>0.260141</td>\n",
              "      <td>0.227539</td>\n",
              "      <td>0.541206</td>\n",
              "      <td>0.146204</td>\n",
              "      <td>0.405486</td>\n",
              "      <td>0.494672</td>\n",
              "      <td>0.158422</td>\n",
              "      <td>0.032849</td>\n",
              "      <td>0.445880</td>\n",
              "      <td>0.332203</td>\n",
              "      <td>0.112444</td>\n",
              "      <td>0.338273</td>\n",
              "      <td>0.235684</td>\n",
              "      <td>0.074313</td>\n",
              "      <td>0.235501</td>\n",
              "      <td>0.524071</td>\n",
              "      <td>0.447665</td>\n",
              "      <td>0.886561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>0.073820</td>\n",
              "      <td>0.852738</td>\n",
              "      <td>0.117018</td>\n",
              "      <td>0.468891</td>\n",
              "      <td>0.038269</td>\n",
              "      <td>0.064777</td>\n",
              "      <td>0.805546</td>\n",
              "      <td>0.220018</td>\n",
              "      <td>0.091385</td>\n",
              "      <td>0.214763</td>\n",
              "      <td>0.215043</td>\n",
              "      <td>0.524350</td>\n",
              "      <td>0.373020</td>\n",
              "      <td>0.295909</td>\n",
              "      <td>0.040198</td>\n",
              "      <td>0.490534</td>\n",
              "      <td>0.255476</td>\n",
              "      <td>0.248416</td>\n",
              "      <td>0.692417</td>\n",
              "      <td>0.769541</td>\n",
              "      <td>0.534635</td>\n",
              "      <td>0.180956</td>\n",
              "      <td>0.047423</td>\n",
              "      <td>0.028071</td>\n",
              "      <td>0.067124</td>\n",
              "      <td>0.085290</td>\n",
              "      <td>0.296303</td>\n",
              "      <td>0.290001</td>\n",
              "      <td>0.029303</td>\n",
              "      <td>0.827800</td>\n",
              "      <td>0.355242</td>\n",
              "      <td>0.215527</td>\n",
              "      <td>0.195924</td>\n",
              "      <td>0.279796</td>\n",
              "      <td>0.137408</td>\n",
              "      <td>0.078883</td>\n",
              "      <td>0.269550</td>\n",
              "      <td>0.034215</td>\n",
              "      <td>0.533017</td>\n",
              "      <td>0.559530</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275081</td>\n",
              "      <td>0.074618</td>\n",
              "      <td>0.037855</td>\n",
              "      <td>0.104034</td>\n",
              "      <td>0.103202</td>\n",
              "      <td>0.283133</td>\n",
              "      <td>0.115526</td>\n",
              "      <td>0.144306</td>\n",
              "      <td>0.352280</td>\n",
              "      <td>0.559440</td>\n",
              "      <td>0.373613</td>\n",
              "      <td>0.090806</td>\n",
              "      <td>0.094415</td>\n",
              "      <td>0.310192</td>\n",
              "      <td>0.069056</td>\n",
              "      <td>0.074242</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.284680</td>\n",
              "      <td>0.660530</td>\n",
              "      <td>0.075172</td>\n",
              "      <td>0.085748</td>\n",
              "      <td>0.040536</td>\n",
              "      <td>0.438609</td>\n",
              "      <td>0.382912</td>\n",
              "      <td>0.336809</td>\n",
              "      <td>0.123039</td>\n",
              "      <td>0.201447</td>\n",
              "      <td>0.475016</td>\n",
              "      <td>0.170436</td>\n",
              "      <td>0.008726</td>\n",
              "      <td>0.287065</td>\n",
              "      <td>0.275431</td>\n",
              "      <td>0.071945</td>\n",
              "      <td>0.650397</td>\n",
              "      <td>0.259976</td>\n",
              "      <td>0.076242</td>\n",
              "      <td>0.274247</td>\n",
              "      <td>0.821378</td>\n",
              "      <td>0.363008</td>\n",
              "      <td>0.229402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>0.004553</td>\n",
              "      <td>0.880430</td>\n",
              "      <td>0.364310</td>\n",
              "      <td>0.068647</td>\n",
              "      <td>0.045955</td>\n",
              "      <td>0.276464</td>\n",
              "      <td>0.694144</td>\n",
              "      <td>0.352019</td>\n",
              "      <td>0.269970</td>\n",
              "      <td>0.181171</td>\n",
              "      <td>0.576120</td>\n",
              "      <td>0.217004</td>\n",
              "      <td>0.574435</td>\n",
              "      <td>0.184465</td>\n",
              "      <td>0.073986</td>\n",
              "      <td>0.321139</td>\n",
              "      <td>0.091324</td>\n",
              "      <td>0.627098</td>\n",
              "      <td>0.423852</td>\n",
              "      <td>0.656984</td>\n",
              "      <td>0.409097</td>\n",
              "      <td>0.652559</td>\n",
              "      <td>0.061183</td>\n",
              "      <td>0.036018</td>\n",
              "      <td>0.103056</td>\n",
              "      <td>0.372518</td>\n",
              "      <td>0.327165</td>\n",
              "      <td>0.196041</td>\n",
              "      <td>0.011444</td>\n",
              "      <td>0.893187</td>\n",
              "      <td>0.085812</td>\n",
              "      <td>0.118146</td>\n",
              "      <td>0.578110</td>\n",
              "      <td>0.241989</td>\n",
              "      <td>0.345898</td>\n",
              "      <td>0.175183</td>\n",
              "      <td>0.551191</td>\n",
              "      <td>0.561866</td>\n",
              "      <td>0.437294</td>\n",
              "      <td>0.825547</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227347</td>\n",
              "      <td>0.208725</td>\n",
              "      <td>0.058879</td>\n",
              "      <td>0.329007</td>\n",
              "      <td>0.413728</td>\n",
              "      <td>0.508648</td>\n",
              "      <td>0.302141</td>\n",
              "      <td>0.156915</td>\n",
              "      <td>0.379266</td>\n",
              "      <td>0.601128</td>\n",
              "      <td>0.150778</td>\n",
              "      <td>0.065662</td>\n",
              "      <td>0.102571</td>\n",
              "      <td>0.456914</td>\n",
              "      <td>0.035104</td>\n",
              "      <td>0.037546</td>\n",
              "      <td>0.024604</td>\n",
              "      <td>0.775284</td>\n",
              "      <td>0.622757</td>\n",
              "      <td>0.141688</td>\n",
              "      <td>0.070532</td>\n",
              "      <td>0.211050</td>\n",
              "      <td>0.403960</td>\n",
              "      <td>0.163731</td>\n",
              "      <td>0.603548</td>\n",
              "      <td>0.137243</td>\n",
              "      <td>0.411822</td>\n",
              "      <td>0.700503</td>\n",
              "      <td>0.164547</td>\n",
              "      <td>0.034248</td>\n",
              "      <td>0.443456</td>\n",
              "      <td>0.232336</td>\n",
              "      <td>0.200182</td>\n",
              "      <td>0.446087</td>\n",
              "      <td>0.340376</td>\n",
              "      <td>0.067441</td>\n",
              "      <td>0.159287</td>\n",
              "      <td>0.358076</td>\n",
              "      <td>0.259640</td>\n",
              "      <td>0.373019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>0.072001</td>\n",
              "      <td>0.772143</td>\n",
              "      <td>0.315427</td>\n",
              "      <td>0.122715</td>\n",
              "      <td>0.019838</td>\n",
              "      <td>0.074347</td>\n",
              "      <td>0.383091</td>\n",
              "      <td>0.378234</td>\n",
              "      <td>0.380313</td>\n",
              "      <td>0.153446</td>\n",
              "      <td>0.634884</td>\n",
              "      <td>0.230125</td>\n",
              "      <td>0.663346</td>\n",
              "      <td>0.508455</td>\n",
              "      <td>0.034398</td>\n",
              "      <td>0.374662</td>\n",
              "      <td>0.232526</td>\n",
              "      <td>0.136101</td>\n",
              "      <td>0.814045</td>\n",
              "      <td>0.384851</td>\n",
              "      <td>0.561460</td>\n",
              "      <td>0.354532</td>\n",
              "      <td>0.465207</td>\n",
              "      <td>0.016535</td>\n",
              "      <td>0.309236</td>\n",
              "      <td>0.263656</td>\n",
              "      <td>0.141825</td>\n",
              "      <td>0.237645</td>\n",
              "      <td>0.572934</td>\n",
              "      <td>0.697386</td>\n",
              "      <td>0.626372</td>\n",
              "      <td>0.080712</td>\n",
              "      <td>0.664680</td>\n",
              "      <td>0.413097</td>\n",
              "      <td>0.246998</td>\n",
              "      <td>0.104478</td>\n",
              "      <td>0.256957</td>\n",
              "      <td>0.057628</td>\n",
              "      <td>0.185676</td>\n",
              "      <td>0.642192</td>\n",
              "      <td>...</td>\n",
              "      <td>0.191653</td>\n",
              "      <td>0.037337</td>\n",
              "      <td>0.092299</td>\n",
              "      <td>0.276874</td>\n",
              "      <td>0.219018</td>\n",
              "      <td>0.589439</td>\n",
              "      <td>0.150473</td>\n",
              "      <td>0.056181</td>\n",
              "      <td>0.309105</td>\n",
              "      <td>0.396257</td>\n",
              "      <td>0.209121</td>\n",
              "      <td>0.078095</td>\n",
              "      <td>0.683304</td>\n",
              "      <td>0.189459</td>\n",
              "      <td>0.044325</td>\n",
              "      <td>0.008102</td>\n",
              "      <td>0.058907</td>\n",
              "      <td>0.213952</td>\n",
              "      <td>0.626235</td>\n",
              "      <td>0.091539</td>\n",
              "      <td>0.110743</td>\n",
              "      <td>0.024473</td>\n",
              "      <td>0.542192</td>\n",
              "      <td>0.126217</td>\n",
              "      <td>0.352672</td>\n",
              "      <td>0.175157</td>\n",
              "      <td>0.193137</td>\n",
              "      <td>0.391886</td>\n",
              "      <td>0.044577</td>\n",
              "      <td>0.022681</td>\n",
              "      <td>0.425107</td>\n",
              "      <td>0.240812</td>\n",
              "      <td>0.087244</td>\n",
              "      <td>0.444588</td>\n",
              "      <td>0.164724</td>\n",
              "      <td>0.061712</td>\n",
              "      <td>0.152301</td>\n",
              "      <td>0.643873</td>\n",
              "      <td>0.309402</td>\n",
              "      <td>0.451953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>0.065014</td>\n",
              "      <td>0.879896</td>\n",
              "      <td>0.269363</td>\n",
              "      <td>0.192699</td>\n",
              "      <td>0.057363</td>\n",
              "      <td>0.035785</td>\n",
              "      <td>0.710024</td>\n",
              "      <td>0.308800</td>\n",
              "      <td>0.451043</td>\n",
              "      <td>0.516425</td>\n",
              "      <td>0.834278</td>\n",
              "      <td>0.235049</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.083583</td>\n",
              "      <td>0.025721</td>\n",
              "      <td>0.458845</td>\n",
              "      <td>0.310781</td>\n",
              "      <td>0.117603</td>\n",
              "      <td>0.221524</td>\n",
              "      <td>0.541814</td>\n",
              "      <td>0.695960</td>\n",
              "      <td>0.097568</td>\n",
              "      <td>0.077095</td>\n",
              "      <td>0.036823</td>\n",
              "      <td>0.048511</td>\n",
              "      <td>0.774323</td>\n",
              "      <td>0.112093</td>\n",
              "      <td>0.274524</td>\n",
              "      <td>0.067498</td>\n",
              "      <td>0.725596</td>\n",
              "      <td>0.161685</td>\n",
              "      <td>0.066904</td>\n",
              "      <td>0.226281</td>\n",
              "      <td>0.232928</td>\n",
              "      <td>0.379641</td>\n",
              "      <td>0.176544</td>\n",
              "      <td>0.312147</td>\n",
              "      <td>0.330700</td>\n",
              "      <td>0.602107</td>\n",
              "      <td>0.681850</td>\n",
              "      <td>...</td>\n",
              "      <td>0.201090</td>\n",
              "      <td>0.647809</td>\n",
              "      <td>0.070094</td>\n",
              "      <td>0.127168</td>\n",
              "      <td>0.112842</td>\n",
              "      <td>0.236906</td>\n",
              "      <td>0.247013</td>\n",
              "      <td>0.398347</td>\n",
              "      <td>0.342736</td>\n",
              "      <td>0.392180</td>\n",
              "      <td>0.408267</td>\n",
              "      <td>0.108048</td>\n",
              "      <td>0.561988</td>\n",
              "      <td>0.236142</td>\n",
              "      <td>0.061637</td>\n",
              "      <td>0.062930</td>\n",
              "      <td>0.045521</td>\n",
              "      <td>0.490115</td>\n",
              "      <td>0.767338</td>\n",
              "      <td>0.913164</td>\n",
              "      <td>0.155125</td>\n",
              "      <td>0.100233</td>\n",
              "      <td>0.304835</td>\n",
              "      <td>0.159595</td>\n",
              "      <td>0.351143</td>\n",
              "      <td>0.181313</td>\n",
              "      <td>0.430627</td>\n",
              "      <td>0.331241</td>\n",
              "      <td>0.215530</td>\n",
              "      <td>0.055069</td>\n",
              "      <td>0.309126</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>0.123343</td>\n",
              "      <td>0.420108</td>\n",
              "      <td>0.088810</td>\n",
              "      <td>0.083622</td>\n",
              "      <td>0.144783</td>\n",
              "      <td>0.469213</td>\n",
              "      <td>0.367745</td>\n",
              "      <td>0.399864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1018 rows × 17736 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7959946b-f9f6-4186-b9a2-61d77c63aff7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7959946b-f9f6-4186-b9a2-61d77c63aff7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7959946b-f9f6-4186-b9a2-61d77c63aff7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         0         1         2      ...     17733     17734     17735\n",
              "0     0.090174  0.831734  0.134854  ...  0.662015  0.187001  0.398991\n",
              "1     0.054091  1.000000  0.260056  ...  0.454642  0.134000  0.590433\n",
              "2     0.028176  0.772948  0.229411  ...  0.477919  0.073528  0.363586\n",
              "3     0.061855  0.773271  0.259174  ...  0.656043  0.318726  0.404231\n",
              "4     0.088852  0.836364  0.336107  ...  0.651974  0.419353  0.468367\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1013  0.027359  0.959507  0.359467  ...  0.524071  0.447665  0.886561\n",
              "1014  0.073820  0.852738  0.117018  ...  0.821378  0.363008  0.229402\n",
              "1015  0.004553  0.880430  0.364310  ...  0.358076  0.259640  0.373019\n",
              "1016  0.072001  0.772143  0.315427  ...  0.643873  0.309402  0.451953\n",
              "1017  0.065014  0.879896  0.269363  ...  0.469213  0.367745  0.399864\n",
              "\n",
              "[1018 rows x 17736 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "wgbexRUW3_EJ",
        "outputId": "22742db3-a8d9-46dc-a687-3d9b5f3548e5"
      },
      "source": [
        "x= df.iloc[:, 1:]\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0c99926c-553c-47c1-a499-6c74c49f981b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000460</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>ENSG00000001167</th>\n",
              "      <th>ENSG00000001460</th>\n",
              "      <th>ENSG00000001461</th>\n",
              "      <th>ENSG00000001497</th>\n",
              "      <th>ENSG00000001561</th>\n",
              "      <th>ENSG00000001617</th>\n",
              "      <th>ENSG00000001626</th>\n",
              "      <th>ENSG00000001629</th>\n",
              "      <th>ENSG00000001631</th>\n",
              "      <th>ENSG00000002016</th>\n",
              "      <th>ENSG00000002330</th>\n",
              "      <th>ENSG00000002549</th>\n",
              "      <th>ENSG00000002586</th>\n",
              "      <th>ENSG00000002587</th>\n",
              "      <th>ENSG00000002726</th>\n",
              "      <th>ENSG00000002745</th>\n",
              "      <th>ENSG00000002746</th>\n",
              "      <th>ENSG00000002822</th>\n",
              "      <th>ENSG00000002834</th>\n",
              "      <th>ENSG00000002919</th>\n",
              "      <th>ENSG00000002933</th>\n",
              "      <th>ENSG00000003056</th>\n",
              "      <th>ENSG00000003096</th>\n",
              "      <th>ENSG00000003137</th>\n",
              "      <th>ENSG00000003147</th>\n",
              "      <th>ENSG00000003249</th>\n",
              "      <th>ENSG00000003393</th>\n",
              "      <th>ENSG00000003400</th>\n",
              "      <th>ENSG00000003402</th>\n",
              "      <th>ENSG00000003436</th>\n",
              "      <th>ENSG00000003509</th>\n",
              "      <th>ENSG00000003756</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000260347</th>\n",
              "      <th>ENSG00000260359</th>\n",
              "      <th>ENSG00000260432</th>\n",
              "      <th>ENSG00000260461</th>\n",
              "      <th>ENSG00000260495</th>\n",
              "      <th>ENSG00000260539</th>\n",
              "      <th>ENSG00000260612</th>\n",
              "      <th>ENSG00000260880</th>\n",
              "      <th>ENSG00000261215</th>\n",
              "      <th>ENSG00000261253</th>\n",
              "      <th>ENSG00000261351</th>\n",
              "      <th>ENSG00000261434</th>\n",
              "      <th>ENSG00000261452</th>\n",
              "      <th>ENSG00000261649</th>\n",
              "      <th>ENSG00000261685</th>\n",
              "      <th>ENSG00000261701</th>\n",
              "      <th>ENSG00000261742</th>\n",
              "      <th>ENSG00000261803</th>\n",
              "      <th>ENSG00000261819</th>\n",
              "      <th>ENSG00000261857</th>\n",
              "      <th>ENSG00000261925</th>\n",
              "      <th>ENSG00000262152</th>\n",
              "      <th>ENSG00000262557</th>\n",
              "      <th>ENSG00000262628</th>\n",
              "      <th>ENSG00000263002</th>\n",
              "      <th>ENSG00000263417</th>\n",
              "      <th>ENSG00000263574</th>\n",
              "      <th>ENSG00000263843</th>\n",
              "      <th>ENSG00000264247</th>\n",
              "      <th>ENSG00000264424</th>\n",
              "      <th>ENSG00000264575</th>\n",
              "      <th>ENSG00000265060</th>\n",
              "      <th>ENSG00000265246</th>\n",
              "      <th>ENSG00000265298</th>\n",
              "      <th>ENSG00000265480</th>\n",
              "      <th>ENSG00000265929</th>\n",
              "      <th>ENSG00000266066</th>\n",
              "      <th>ENSG00000266282</th>\n",
              "      <th>ENSG00000266433</th>\n",
              "      <th>ENSG00000266753</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.964585</td>\n",
              "      <td>10.379553</td>\n",
              "      <td>3.614794</td>\n",
              "      <td>3.380681</td>\n",
              "      <td>3.324692</td>\n",
              "      <td>3.566350</td>\n",
              "      <td>8.204530</td>\n",
              "      <td>5.235118</td>\n",
              "      <td>5.369039</td>\n",
              "      <td>3.596993</td>\n",
              "      <td>7.641756</td>\n",
              "      <td>4.549065</td>\n",
              "      <td>4.488261</td>\n",
              "      <td>4.118309</td>\n",
              "      <td>3.024970</td>\n",
              "      <td>8.296444</td>\n",
              "      <td>3.646615</td>\n",
              "      <td>3.780467</td>\n",
              "      <td>7.458409</td>\n",
              "      <td>6.453926</td>\n",
              "      <td>9.460478</td>\n",
              "      <td>3.517445</td>\n",
              "      <td>3.350498</td>\n",
              "      <td>3.741032</td>\n",
              "      <td>2.661393</td>\n",
              "      <td>5.200431</td>\n",
              "      <td>4.931681</td>\n",
              "      <td>4.767457</td>\n",
              "      <td>2.975821</td>\n",
              "      <td>9.792014</td>\n",
              "      <td>6.213763</td>\n",
              "      <td>3.440152</td>\n",
              "      <td>4.075371</td>\n",
              "      <td>3.689651</td>\n",
              "      <td>3.947773</td>\n",
              "      <td>2.831262</td>\n",
              "      <td>5.463531</td>\n",
              "      <td>12.091616</td>\n",
              "      <td>5.804314</td>\n",
              "      <td>8.548148</td>\n",
              "      <td>...</td>\n",
              "      <td>3.183110</td>\n",
              "      <td>4.633899</td>\n",
              "      <td>3.077504</td>\n",
              "      <td>3.019080</td>\n",
              "      <td>3.081601</td>\n",
              "      <td>5.945066</td>\n",
              "      <td>2.939461</td>\n",
              "      <td>2.927571</td>\n",
              "      <td>2.991526</td>\n",
              "      <td>2.906636</td>\n",
              "      <td>3.901483</td>\n",
              "      <td>3.435723</td>\n",
              "      <td>3.051134</td>\n",
              "      <td>3.529562</td>\n",
              "      <td>3.030229</td>\n",
              "      <td>2.790461</td>\n",
              "      <td>2.801037</td>\n",
              "      <td>3.178122</td>\n",
              "      <td>6.975354</td>\n",
              "      <td>3.588889</td>\n",
              "      <td>3.029979</td>\n",
              "      <td>3.665788</td>\n",
              "      <td>3.389938</td>\n",
              "      <td>3.134197</td>\n",
              "      <td>4.841169</td>\n",
              "      <td>3.005416</td>\n",
              "      <td>2.939461</td>\n",
              "      <td>4.059000</td>\n",
              "      <td>3.411250</td>\n",
              "      <td>2.628932</td>\n",
              "      <td>6.786925</td>\n",
              "      <td>2.997054</td>\n",
              "      <td>3.109774</td>\n",
              "      <td>7.882377</td>\n",
              "      <td>3.331134</td>\n",
              "      <td>2.852537</td>\n",
              "      <td>3.130696</td>\n",
              "      <td>9.986616</td>\n",
              "      <td>3.073724</td>\n",
              "      <td>7.284733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.777716</td>\n",
              "      <td>11.807341</td>\n",
              "      <td>4.066887</td>\n",
              "      <td>3.732485</td>\n",
              "      <td>3.152404</td>\n",
              "      <td>7.827172</td>\n",
              "      <td>6.616972</td>\n",
              "      <td>5.809264</td>\n",
              "      <td>7.209653</td>\n",
              "      <td>3.753548</td>\n",
              "      <td>5.715404</td>\n",
              "      <td>4.306627</td>\n",
              "      <td>6.030564</td>\n",
              "      <td>3.951478</td>\n",
              "      <td>3.123943</td>\n",
              "      <td>8.313609</td>\n",
              "      <td>3.858846</td>\n",
              "      <td>3.921778</td>\n",
              "      <td>7.479327</td>\n",
              "      <td>6.742826</td>\n",
              "      <td>9.474606</td>\n",
              "      <td>3.044297</td>\n",
              "      <td>3.210050</td>\n",
              "      <td>2.729453</td>\n",
              "      <td>2.788262</td>\n",
              "      <td>6.139840</td>\n",
              "      <td>4.525647</td>\n",
              "      <td>5.246301</td>\n",
              "      <td>3.035024</td>\n",
              "      <td>8.845537</td>\n",
              "      <td>3.241823</td>\n",
              "      <td>3.073604</td>\n",
              "      <td>4.547098</td>\n",
              "      <td>4.062049</td>\n",
              "      <td>4.017758</td>\n",
              "      <td>2.788942</td>\n",
              "      <td>4.662621</td>\n",
              "      <td>3.470365</td>\n",
              "      <td>6.484788</td>\n",
              "      <td>8.736863</td>\n",
              "      <td>...</td>\n",
              "      <td>4.343442</td>\n",
              "      <td>2.618501</td>\n",
              "      <td>2.879343</td>\n",
              "      <td>3.331508</td>\n",
              "      <td>3.285192</td>\n",
              "      <td>6.798999</td>\n",
              "      <td>3.027941</td>\n",
              "      <td>3.191654</td>\n",
              "      <td>2.962621</td>\n",
              "      <td>3.074109</td>\n",
              "      <td>4.923347</td>\n",
              "      <td>3.345257</td>\n",
              "      <td>7.026350</td>\n",
              "      <td>3.599434</td>\n",
              "      <td>3.132953</td>\n",
              "      <td>2.778059</td>\n",
              "      <td>2.861326</td>\n",
              "      <td>2.996229</td>\n",
              "      <td>8.721021</td>\n",
              "      <td>3.419746</td>\n",
              "      <td>3.118254</td>\n",
              "      <td>3.053174</td>\n",
              "      <td>3.577202</td>\n",
              "      <td>3.327528</td>\n",
              "      <td>4.570476</td>\n",
              "      <td>2.878796</td>\n",
              "      <td>3.003163</td>\n",
              "      <td>3.572520</td>\n",
              "      <td>3.586613</td>\n",
              "      <td>2.783441</td>\n",
              "      <td>5.317911</td>\n",
              "      <td>3.263745</td>\n",
              "      <td>3.059424</td>\n",
              "      <td>8.681302</td>\n",
              "      <td>2.992611</td>\n",
              "      <td>2.776771</td>\n",
              "      <td>3.260982</td>\n",
              "      <td>9.002814</td>\n",
              "      <td>3.000182</td>\n",
              "      <td>8.504804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.643508</td>\n",
              "      <td>9.880733</td>\n",
              "      <td>3.956230</td>\n",
              "      <td>3.236620</td>\n",
              "      <td>3.241246</td>\n",
              "      <td>2.931034</td>\n",
              "      <td>8.191246</td>\n",
              "      <td>5.426841</td>\n",
              "      <td>5.120747</td>\n",
              "      <td>3.946064</td>\n",
              "      <td>5.601235</td>\n",
              "      <td>3.832190</td>\n",
              "      <td>4.548564</td>\n",
              "      <td>4.440084</td>\n",
              "      <td>2.896733</td>\n",
              "      <td>7.938611</td>\n",
              "      <td>3.811614</td>\n",
              "      <td>3.597864</td>\n",
              "      <td>7.419672</td>\n",
              "      <td>5.655691</td>\n",
              "      <td>10.011329</td>\n",
              "      <td>3.924394</td>\n",
              "      <td>3.215727</td>\n",
              "      <td>2.699162</td>\n",
              "      <td>2.902831</td>\n",
              "      <td>5.393870</td>\n",
              "      <td>4.145480</td>\n",
              "      <td>4.645800</td>\n",
              "      <td>2.846260</td>\n",
              "      <td>8.868636</td>\n",
              "      <td>3.054858</td>\n",
              "      <td>3.082341</td>\n",
              "      <td>3.032266</td>\n",
              "      <td>4.007929</td>\n",
              "      <td>3.784884</td>\n",
              "      <td>3.191751</td>\n",
              "      <td>5.519212</td>\n",
              "      <td>10.236172</td>\n",
              "      <td>5.672254</td>\n",
              "      <td>8.360662</td>\n",
              "      <td>...</td>\n",
              "      <td>3.160929</td>\n",
              "      <td>2.966000</td>\n",
              "      <td>2.979303</td>\n",
              "      <td>3.338575</td>\n",
              "      <td>3.036464</td>\n",
              "      <td>7.318819</td>\n",
              "      <td>2.984301</td>\n",
              "      <td>3.278479</td>\n",
              "      <td>3.255958</td>\n",
              "      <td>2.964270</td>\n",
              "      <td>3.883598</td>\n",
              "      <td>3.154062</td>\n",
              "      <td>7.501269</td>\n",
              "      <td>3.347474</td>\n",
              "      <td>2.752734</td>\n",
              "      <td>2.661848</td>\n",
              "      <td>2.718044</td>\n",
              "      <td>2.828840</td>\n",
              "      <td>8.304669</td>\n",
              "      <td>3.449147</td>\n",
              "      <td>2.775777</td>\n",
              "      <td>3.226808</td>\n",
              "      <td>3.384858</td>\n",
              "      <td>3.326309</td>\n",
              "      <td>4.214729</td>\n",
              "      <td>2.985562</td>\n",
              "      <td>3.083179</td>\n",
              "      <td>3.482183</td>\n",
              "      <td>3.725436</td>\n",
              "      <td>2.603604</td>\n",
              "      <td>3.143006</td>\n",
              "      <td>3.112145</td>\n",
              "      <td>2.930254</td>\n",
              "      <td>8.707886</td>\n",
              "      <td>2.886574</td>\n",
              "      <td>2.685307</td>\n",
              "      <td>3.176239</td>\n",
              "      <td>9.113243</td>\n",
              "      <td>2.916274</td>\n",
              "      <td>7.059092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.817923</td>\n",
              "      <td>9.883471</td>\n",
              "      <td>4.063701</td>\n",
              "      <td>3.558414</td>\n",
              "      <td>3.101247</td>\n",
              "      <td>7.211707</td>\n",
              "      <td>8.630643</td>\n",
              "      <td>5.617714</td>\n",
              "      <td>4.996434</td>\n",
              "      <td>3.378736</td>\n",
              "      <td>6.752791</td>\n",
              "      <td>3.512547</td>\n",
              "      <td>5.309896</td>\n",
              "      <td>4.210272</td>\n",
              "      <td>2.950093</td>\n",
              "      <td>7.231354</td>\n",
              "      <td>3.772951</td>\n",
              "      <td>3.220164</td>\n",
              "      <td>7.731137</td>\n",
              "      <td>5.259367</td>\n",
              "      <td>8.173147</td>\n",
              "      <td>2.957085</td>\n",
              "      <td>3.396187</td>\n",
              "      <td>2.732190</td>\n",
              "      <td>3.000899</td>\n",
              "      <td>5.447174</td>\n",
              "      <td>4.971736</td>\n",
              "      <td>4.558836</td>\n",
              "      <td>2.965398</td>\n",
              "      <td>8.974729</td>\n",
              "      <td>3.349643</td>\n",
              "      <td>3.431314</td>\n",
              "      <td>7.487131</td>\n",
              "      <td>3.577693</td>\n",
              "      <td>3.898134</td>\n",
              "      <td>3.110345</td>\n",
              "      <td>6.322941</td>\n",
              "      <td>7.625778</td>\n",
              "      <td>5.171895</td>\n",
              "      <td>7.201922</td>\n",
              "      <td>...</td>\n",
              "      <td>3.079667</td>\n",
              "      <td>4.609837</td>\n",
              "      <td>3.699916</td>\n",
              "      <td>3.426935</td>\n",
              "      <td>3.153041</td>\n",
              "      <td>5.597614</td>\n",
              "      <td>3.145512</td>\n",
              "      <td>2.816586</td>\n",
              "      <td>3.107612</td>\n",
              "      <td>2.875945</td>\n",
              "      <td>4.028170</td>\n",
              "      <td>3.184647</td>\n",
              "      <td>6.743810</td>\n",
              "      <td>4.000042</td>\n",
              "      <td>2.934522</td>\n",
              "      <td>2.690589</td>\n",
              "      <td>2.757298</td>\n",
              "      <td>2.935488</td>\n",
              "      <td>7.776016</td>\n",
              "      <td>3.349624</td>\n",
              "      <td>2.927550</td>\n",
              "      <td>3.110801</td>\n",
              "      <td>2.771725</td>\n",
              "      <td>2.921903</td>\n",
              "      <td>4.060761</td>\n",
              "      <td>3.054339</td>\n",
              "      <td>2.932036</td>\n",
              "      <td>3.722306</td>\n",
              "      <td>2.996834</td>\n",
              "      <td>2.619540</td>\n",
              "      <td>3.153896</td>\n",
              "      <td>3.151576</td>\n",
              "      <td>2.850726</td>\n",
              "      <td>7.872535</td>\n",
              "      <td>3.812119</td>\n",
              "      <td>3.436412</td>\n",
              "      <td>3.074432</td>\n",
              "      <td>9.958284</td>\n",
              "      <td>3.256500</td>\n",
              "      <td>7.318125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.957739</td>\n",
              "      <td>10.418840</td>\n",
              "      <td>4.341500</td>\n",
              "      <td>3.840373</td>\n",
              "      <td>3.001802</td>\n",
              "      <td>3.375422</td>\n",
              "      <td>8.296950</td>\n",
              "      <td>5.669418</td>\n",
              "      <td>4.180205</td>\n",
              "      <td>3.203597</td>\n",
              "      <td>6.188655</td>\n",
              "      <td>4.273850</td>\n",
              "      <td>5.625257</td>\n",
              "      <td>3.625219</td>\n",
              "      <td>3.121881</td>\n",
              "      <td>8.765057</td>\n",
              "      <td>3.727983</td>\n",
              "      <td>3.974085</td>\n",
              "      <td>6.998981</td>\n",
              "      <td>4.611395</td>\n",
              "      <td>9.169078</td>\n",
              "      <td>4.031050</td>\n",
              "      <td>3.410705</td>\n",
              "      <td>2.841949</td>\n",
              "      <td>2.803782</td>\n",
              "      <td>5.383349</td>\n",
              "      <td>5.402952</td>\n",
              "      <td>5.456692</td>\n",
              "      <td>2.964560</td>\n",
              "      <td>10.500454</td>\n",
              "      <td>3.001589</td>\n",
              "      <td>3.014507</td>\n",
              "      <td>3.739111</td>\n",
              "      <td>3.380808</td>\n",
              "      <td>4.278098</td>\n",
              "      <td>3.258932</td>\n",
              "      <td>4.953957</td>\n",
              "      <td>8.346107</td>\n",
              "      <td>6.512252</td>\n",
              "      <td>7.607464</td>\n",
              "      <td>...</td>\n",
              "      <td>3.950427</td>\n",
              "      <td>3.216579</td>\n",
              "      <td>2.737720</td>\n",
              "      <td>2.988535</td>\n",
              "      <td>3.250894</td>\n",
              "      <td>7.515529</td>\n",
              "      <td>2.891633</td>\n",
              "      <td>2.978996</td>\n",
              "      <td>2.976623</td>\n",
              "      <td>3.061091</td>\n",
              "      <td>3.685472</td>\n",
              "      <td>3.190658</td>\n",
              "      <td>3.590825</td>\n",
              "      <td>3.362089</td>\n",
              "      <td>2.995701</td>\n",
              "      <td>2.659010</td>\n",
              "      <td>2.676646</td>\n",
              "      <td>2.790924</td>\n",
              "      <td>7.626892</td>\n",
              "      <td>3.639602</td>\n",
              "      <td>3.061956</td>\n",
              "      <td>3.285372</td>\n",
              "      <td>3.247671</td>\n",
              "      <td>3.474086</td>\n",
              "      <td>4.869199</td>\n",
              "      <td>2.935180</td>\n",
              "      <td>2.888721</td>\n",
              "      <td>3.603264</td>\n",
              "      <td>3.211679</td>\n",
              "      <td>2.450375</td>\n",
              "      <td>3.652660</td>\n",
              "      <td>2.918475</td>\n",
              "      <td>2.849537</td>\n",
              "      <td>8.945953</td>\n",
              "      <td>3.412586</td>\n",
              "      <td>2.951270</td>\n",
              "      <td>3.213545</td>\n",
              "      <td>9.938978</td>\n",
              "      <td>3.396126</td>\n",
              "      <td>7.726867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>2.639276</td>\n",
              "      <td>11.463742</td>\n",
              "      <td>4.425849</td>\n",
              "      <td>4.384732</td>\n",
              "      <td>3.229511</td>\n",
              "      <td>3.571204</td>\n",
              "      <td>8.193000</td>\n",
              "      <td>5.671600</td>\n",
              "      <td>4.943996</td>\n",
              "      <td>3.770408</td>\n",
              "      <td>7.360238</td>\n",
              "      <td>4.358331</td>\n",
              "      <td>3.726872</td>\n",
              "      <td>4.842286</td>\n",
              "      <td>3.126138</td>\n",
              "      <td>8.280024</td>\n",
              "      <td>3.329482</td>\n",
              "      <td>4.020879</td>\n",
              "      <td>7.234464</td>\n",
              "      <td>5.759933</td>\n",
              "      <td>8.012117</td>\n",
              "      <td>3.212582</td>\n",
              "      <td>3.362995</td>\n",
              "      <td>2.889998</td>\n",
              "      <td>2.939662</td>\n",
              "      <td>4.674459</td>\n",
              "      <td>4.807316</td>\n",
              "      <td>4.982202</td>\n",
              "      <td>2.999066</td>\n",
              "      <td>9.680311</td>\n",
              "      <td>3.443071</td>\n",
              "      <td>3.249699</td>\n",
              "      <td>3.419884</td>\n",
              "      <td>3.646099</td>\n",
              "      <td>3.949115</td>\n",
              "      <td>3.013525</td>\n",
              "      <td>4.955624</td>\n",
              "      <td>8.552384</td>\n",
              "      <td>6.264426</td>\n",
              "      <td>8.211825</td>\n",
              "      <td>...</td>\n",
              "      <td>3.525425</td>\n",
              "      <td>5.838142</td>\n",
              "      <td>3.108675</td>\n",
              "      <td>3.272440</td>\n",
              "      <td>3.797733</td>\n",
              "      <td>6.525171</td>\n",
              "      <td>3.063422</td>\n",
              "      <td>3.145192</td>\n",
              "      <td>3.290301</td>\n",
              "      <td>3.430804</td>\n",
              "      <td>3.882161</td>\n",
              "      <td>3.413045</td>\n",
              "      <td>3.369182</td>\n",
              "      <td>3.372263</td>\n",
              "      <td>3.823720</td>\n",
              "      <td>2.967707</td>\n",
              "      <td>2.660243</td>\n",
              "      <td>3.015918</td>\n",
              "      <td>7.600110</td>\n",
              "      <td>3.657931</td>\n",
              "      <td>3.132416</td>\n",
              "      <td>3.390231</td>\n",
              "      <td>3.562632</td>\n",
              "      <td>3.402212</td>\n",
              "      <td>4.540545</td>\n",
              "      <td>2.921340</td>\n",
              "      <td>3.041490</td>\n",
              "      <td>4.045301</td>\n",
              "      <td>3.507341</td>\n",
              "      <td>2.595066</td>\n",
              "      <td>5.097882</td>\n",
              "      <td>3.102979</td>\n",
              "      <td>3.243552</td>\n",
              "      <td>8.110421</td>\n",
              "      <td>3.343723</td>\n",
              "      <td>2.959009</td>\n",
              "      <td>3.007502</td>\n",
              "      <td>9.332193</td>\n",
              "      <td>3.435411</td>\n",
              "      <td>10.392042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>2.879890</td>\n",
              "      <td>10.557777</td>\n",
              "      <td>3.550390</td>\n",
              "      <td>4.247189</td>\n",
              "      <td>3.176336</td>\n",
              "      <td>3.321811</td>\n",
              "      <td>8.901706</td>\n",
              "      <td>4.684851</td>\n",
              "      <td>4.215908</td>\n",
              "      <td>3.432197</td>\n",
              "      <td>4.556123</td>\n",
              "      <td>4.361337</td>\n",
              "      <td>4.813846</td>\n",
              "      <td>4.791299</td>\n",
              "      <td>3.094036</td>\n",
              "      <td>8.644983</td>\n",
              "      <td>4.045898</td>\n",
              "      <td>3.605055</td>\n",
              "      <td>7.525257</td>\n",
              "      <td>7.810126</td>\n",
              "      <td>8.113801</td>\n",
              "      <td>3.892474</td>\n",
              "      <td>3.315494</td>\n",
              "      <td>2.764505</td>\n",
              "      <td>2.785968</td>\n",
              "      <td>4.338340</td>\n",
              "      <td>4.739177</td>\n",
              "      <td>5.037259</td>\n",
              "      <td>2.921308</td>\n",
              "      <td>9.848256</td>\n",
              "      <td>5.355027</td>\n",
              "      <td>3.647747</td>\n",
              "      <td>4.413179</td>\n",
              "      <td>3.730797</td>\n",
              "      <td>3.696454</td>\n",
              "      <td>2.857487</td>\n",
              "      <td>4.889988</td>\n",
              "      <td>3.318492</td>\n",
              "      <td>6.188865</td>\n",
              "      <td>7.171880</td>\n",
              "      <td>...</td>\n",
              "      <td>3.509842</td>\n",
              "      <td>2.945893</td>\n",
              "      <td>2.897693</td>\n",
              "      <td>2.938409</td>\n",
              "      <td>2.959839</td>\n",
              "      <td>5.791348</td>\n",
              "      <td>2.774638</td>\n",
              "      <td>3.657118</td>\n",
              "      <td>3.087958</td>\n",
              "      <td>3.468064</td>\n",
              "      <td>4.287674</td>\n",
              "      <td>3.425382</td>\n",
              "      <td>3.452500</td>\n",
              "      <td>3.704773</td>\n",
              "      <td>3.264937</td>\n",
              "      <td>2.897396</td>\n",
              "      <td>2.763486</td>\n",
              "      <td>2.836450</td>\n",
              "      <td>8.070651</td>\n",
              "      <td>3.715302</td>\n",
              "      <td>3.045340</td>\n",
              "      <td>3.016188</td>\n",
              "      <td>4.370638</td>\n",
              "      <td>3.841095</td>\n",
              "      <td>4.062441</td>\n",
              "      <td>2.834466</td>\n",
              "      <td>2.777204</td>\n",
              "      <td>4.012017</td>\n",
              "      <td>3.557362</td>\n",
              "      <td>2.443743</td>\n",
              "      <td>4.243448</td>\n",
              "      <td>3.034131</td>\n",
              "      <td>3.031143</td>\n",
              "      <td>9.161868</td>\n",
              "      <td>3.412558</td>\n",
              "      <td>2.974475</td>\n",
              "      <td>3.088841</td>\n",
              "      <td>10.742651</td>\n",
              "      <td>3.317945</td>\n",
              "      <td>6.203929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>2.521169</td>\n",
              "      <td>10.792750</td>\n",
              "      <td>4.443337</td>\n",
              "      <td>3.071359</td>\n",
              "      <td>3.238305</td>\n",
              "      <td>5.209472</td>\n",
              "      <td>8.073389</td>\n",
              "      <td>5.643811</td>\n",
              "      <td>5.040952</td>\n",
              "      <td>3.344979</td>\n",
              "      <td>6.669064</td>\n",
              "      <td>3.597366</td>\n",
              "      <td>5.859500</td>\n",
              "      <td>4.286220</td>\n",
              "      <td>3.372714</td>\n",
              "      <td>7.830936</td>\n",
              "      <td>3.256537</td>\n",
              "      <td>4.540383</td>\n",
              "      <td>6.066356</td>\n",
              "      <td>7.182077</td>\n",
              "      <td>6.948601</td>\n",
              "      <td>7.073437</td>\n",
              "      <td>3.436440</td>\n",
              "      <td>2.813419</td>\n",
              "      <td>2.910087</td>\n",
              "      <td>6.683538</td>\n",
              "      <td>4.868739</td>\n",
              "      <td>4.611973</td>\n",
              "      <td>2.759914</td>\n",
              "      <td>10.354026</td>\n",
              "      <td>3.361741</td>\n",
              "      <td>3.174112</td>\n",
              "      <td>7.346287</td>\n",
              "      <td>3.652134</td>\n",
              "      <td>4.544815</td>\n",
              "      <td>3.064199</td>\n",
              "      <td>6.645925</td>\n",
              "      <td>8.224078</td>\n",
              "      <td>5.834752</td>\n",
              "      <td>9.025969</td>\n",
              "      <td>...</td>\n",
              "      <td>3.357575</td>\n",
              "      <td>3.867752</td>\n",
              "      <td>3.028672</td>\n",
              "      <td>3.581341</td>\n",
              "      <td>4.196880</td>\n",
              "      <td>7.234274</td>\n",
              "      <td>3.039980</td>\n",
              "      <td>3.730557</td>\n",
              "      <td>3.125049</td>\n",
              "      <td>3.525079</td>\n",
              "      <td>3.531308</td>\n",
              "      <td>3.229062</td>\n",
              "      <td>3.505198</td>\n",
              "      <td>3.980961</td>\n",
              "      <td>2.958662</td>\n",
              "      <td>2.660811</td>\n",
              "      <td>2.605696</td>\n",
              "      <td>3.340643</td>\n",
              "      <td>7.826121</td>\n",
              "      <td>4.278568</td>\n",
              "      <td>2.959811</td>\n",
              "      <td>4.133042</td>\n",
              "      <td>4.213764</td>\n",
              "      <td>3.221974</td>\n",
              "      <td>4.686370</td>\n",
              "      <td>2.887736</td>\n",
              "      <td>3.049697</td>\n",
              "      <td>4.393847</td>\n",
              "      <td>3.532841</td>\n",
              "      <td>2.603842</td>\n",
              "      <td>5.084844</td>\n",
              "      <td>2.981869</td>\n",
              "      <td>3.703721</td>\n",
              "      <td>8.473612</td>\n",
              "      <td>3.640390</td>\n",
              "      <td>2.903894</td>\n",
              "      <td>2.847505</td>\n",
              "      <td>8.544696</td>\n",
              "      <td>3.174515</td>\n",
              "      <td>7.119213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>2.870468</td>\n",
              "      <td>9.873902</td>\n",
              "      <td>4.266828</td>\n",
              "      <td>3.230197</td>\n",
              "      <td>3.027742</td>\n",
              "      <td>3.407148</td>\n",
              "      <td>5.760610</td>\n",
              "      <td>5.834256</td>\n",
              "      <td>5.550722</td>\n",
              "      <td>3.272994</td>\n",
              "      <td>7.012936</td>\n",
              "      <td>3.629980</td>\n",
              "      <td>6.321085</td>\n",
              "      <td>5.754581</td>\n",
              "      <td>3.046196</td>\n",
              "      <td>8.088148</td>\n",
              "      <td>3.935535</td>\n",
              "      <td>3.327640</td>\n",
              "      <td>8.185968</td>\n",
              "      <td>5.663629</td>\n",
              "      <td>8.362776</td>\n",
              "      <td>5.063248</td>\n",
              "      <td>6.987454</td>\n",
              "      <td>2.693494</td>\n",
              "      <td>3.622282</td>\n",
              "      <td>5.794690</td>\n",
              "      <td>4.090673</td>\n",
              "      <td>4.800284</td>\n",
              "      <td>7.833970</td>\n",
              "      <td>8.839499</td>\n",
              "      <td>7.360885</td>\n",
              "      <td>2.992044</td>\n",
              "      <td>8.010674</td>\n",
              "      <td>4.008153</td>\n",
              "      <td>4.142386</td>\n",
              "      <td>2.912428</td>\n",
              "      <td>4.811472</td>\n",
              "      <td>3.536157</td>\n",
              "      <td>4.903923</td>\n",
              "      <td>7.748020</td>\n",
              "      <td>...</td>\n",
              "      <td>3.243715</td>\n",
              "      <td>2.689623</td>\n",
              "      <td>3.236872</td>\n",
              "      <td>3.432355</td>\n",
              "      <td>3.421215</td>\n",
              "      <td>7.751206</td>\n",
              "      <td>2.824329</td>\n",
              "      <td>3.143819</td>\n",
              "      <td>3.028617</td>\n",
              "      <td>3.244888</td>\n",
              "      <td>3.729339</td>\n",
              "      <td>3.326140</td>\n",
              "      <td>7.257399</td>\n",
              "      <td>3.477507</td>\n",
              "      <td>3.041844</td>\n",
              "      <td>2.470981</td>\n",
              "      <td>2.744415</td>\n",
              "      <td>2.763764</td>\n",
              "      <td>7.848633</td>\n",
              "      <td>3.853900</td>\n",
              "      <td>3.185840</td>\n",
              "      <td>2.910977</td>\n",
              "      <td>4.839607</td>\n",
              "      <td>3.116006</td>\n",
              "      <td>4.099547</td>\n",
              "      <td>3.029919</td>\n",
              "      <td>2.766441</td>\n",
              "      <td>3.871248</td>\n",
              "      <td>3.033338</td>\n",
              "      <td>2.531280</td>\n",
              "      <td>4.986124</td>\n",
              "      <td>2.992148</td>\n",
              "      <td>3.111383</td>\n",
              "      <td>8.468564</td>\n",
              "      <td>3.142641</td>\n",
              "      <td>2.857956</td>\n",
              "      <td>2.832840</td>\n",
              "      <td>9.900550</td>\n",
              "      <td>3.243563</td>\n",
              "      <td>7.622261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>2.834285</td>\n",
              "      <td>10.788218</td>\n",
              "      <td>4.100493</td>\n",
              "      <td>3.435795</td>\n",
              "      <td>3.330279</td>\n",
              "      <td>3.063284</td>\n",
              "      <td>8.191465</td>\n",
              "      <td>5.329834</td>\n",
              "      <td>5.877487</td>\n",
              "      <td>4.215433</td>\n",
              "      <td>8.179745</td>\n",
              "      <td>3.642221</td>\n",
              "      <td>3.772388</td>\n",
              "      <td>3.829010</td>\n",
              "      <td>2.974629</td>\n",
              "      <td>8.492699</td>\n",
              "      <td>4.311844</td>\n",
              "      <td>3.281952</td>\n",
              "      <td>4.967268</td>\n",
              "      <td>6.539451</td>\n",
              "      <td>9.611164</td>\n",
              "      <td>3.330025</td>\n",
              "      <td>3.576292</td>\n",
              "      <td>2.818373</td>\n",
              "      <td>2.721674</td>\n",
              "      <td>9.964246</td>\n",
              "      <td>3.965856</td>\n",
              "      <td>4.967207</td>\n",
              "      <td>3.266466</td>\n",
              "      <td>9.057700</td>\n",
              "      <td>3.923060</td>\n",
              "      <td>2.924887</td>\n",
              "      <td>4.646153</td>\n",
              "      <td>3.633279</td>\n",
              "      <td>4.682117</td>\n",
              "      <td>3.067121</td>\n",
              "      <td>5.155566</td>\n",
              "      <td>6.074918</td>\n",
              "      <td>6.444457</td>\n",
              "      <td>8.024425</td>\n",
              "      <td>...</td>\n",
              "      <td>3.273818</td>\n",
              "      <td>6.886046</td>\n",
              "      <td>3.098539</td>\n",
              "      <td>3.004521</td>\n",
              "      <td>2.998243</td>\n",
              "      <td>5.495573</td>\n",
              "      <td>2.961595</td>\n",
              "      <td>5.136811</td>\n",
              "      <td>3.074840</td>\n",
              "      <td>3.239312</td>\n",
              "      <td>4.405299</td>\n",
              "      <td>3.560002</td>\n",
              "      <td>6.473561</td>\n",
              "      <td>3.565383</td>\n",
              "      <td>3.198007</td>\n",
              "      <td>2.824467</td>\n",
              "      <td>2.690283</td>\n",
              "      <td>3.047576</td>\n",
              "      <td>8.762100</td>\n",
              "      <td>10.811478</td>\n",
              "      <td>3.435318</td>\n",
              "      <td>3.407199</td>\n",
              "      <td>3.764979</td>\n",
              "      <td>3.210291</td>\n",
              "      <td>4.095968</td>\n",
              "      <td>3.053006</td>\n",
              "      <td>3.074055</td>\n",
              "      <td>3.768554</td>\n",
              "      <td>3.745116</td>\n",
              "      <td>2.734454</td>\n",
              "      <td>4.362137</td>\n",
              "      <td>2.964605</td>\n",
              "      <td>3.300715</td>\n",
              "      <td>8.386096</td>\n",
              "      <td>2.927523</td>\n",
              "      <td>3.033662</td>\n",
              "      <td>2.817057</td>\n",
              "      <td>9.071943</td>\n",
              "      <td>3.324517</td>\n",
              "      <td>7.290293</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1018 rows × 17736 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c99926c-553c-47c1-a499-6c74c49f981b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c99926c-553c-47c1-a499-6c74c49f981b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c99926c-553c-47c1-a499-6c74c49f981b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      ENSG00000000005  ENSG00000000419  ...  ENSG00000266433  ENSG00000266753\n",
              "0            2.964585        10.379553  ...         3.073724         7.284733\n",
              "1            2.777716        11.807341  ...         3.000182         8.504804\n",
              "2            2.643508         9.880733  ...         2.916274         7.059092\n",
              "3            2.817923         9.883471  ...         3.256500         7.318125\n",
              "4            2.957739        10.418840  ...         3.396126         7.726867\n",
              "...               ...              ...  ...              ...              ...\n",
              "1013         2.639276        11.463742  ...         3.435411        10.392042\n",
              "1014         2.879890        10.557777  ...         3.317945         6.203929\n",
              "1015         2.521169        10.792750  ...         3.174515         7.119213\n",
              "1016         2.870468         9.873902  ...         3.243563         7.622261\n",
              "1017         2.834285        10.788218  ...         3.324517         7.290293\n",
              "\n",
              "[1018 rows x 17736 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0mrQo9d47KL"
      },
      "source": [
        "expdatanorm['COSMIC_ID']=df[\"COSMIC_ID\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "K0j6CQ7m47TS",
        "outputId": "f507ab2e-982a-4e0c-c4bb-f2337f054434"
      },
      "source": [
        "#expdatanorm.columns = columns1\n",
        "expdatanorm = pd.concat([df2,expdatanorm],axis=1)\n",
        "\n",
        "expdatanorm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3278d06b-4090-42f0-b04f-ef90f4fea3da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>ENSG00000000003</th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>ENSG00000001167</th>\n",
              "      <th>ENSG00000001460</th>\n",
              "      <th>ENSG00000001461</th>\n",
              "      <th>ENSG00000001497</th>\n",
              "      <th>ENSG00000001561</th>\n",
              "      <th>ENSG00000001617</th>\n",
              "      <th>ENSG00000001626</th>\n",
              "      <th>ENSG00000001629</th>\n",
              "      <th>ENSG00000001631</th>\n",
              "      <th>ENSG00000002016</th>\n",
              "      <th>ENSG00000002330</th>\n",
              "      <th>ENSG00000002549</th>\n",
              "      <th>ENSG00000002586</th>\n",
              "      <th>ENSG00000002587</th>\n",
              "      <th>ENSG00000002726</th>\n",
              "      <th>ENSG00000002745</th>\n",
              "      <th>ENSG00000002746</th>\n",
              "      <th>ENSG00000002822</th>\n",
              "      <th>ENSG00000002834</th>\n",
              "      <th>ENSG00000002919</th>\n",
              "      <th>ENSG00000002933</th>\n",
              "      <th>ENSG00000003056</th>\n",
              "      <th>ENSG00000003096</th>\n",
              "      <th>ENSG00000003137</th>\n",
              "      <th>ENSG00000003147</th>\n",
              "      <th>ENSG00000003249</th>\n",
              "      <th>ENSG00000003393</th>\n",
              "      <th>ENSG00000003400</th>\n",
              "      <th>ENSG00000003402</th>\n",
              "      <th>ENSG00000003436</th>\n",
              "      <th>ENSG00000003509</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000260347</th>\n",
              "      <th>ENSG00000260359</th>\n",
              "      <th>ENSG00000260432</th>\n",
              "      <th>ENSG00000260461</th>\n",
              "      <th>ENSG00000260495</th>\n",
              "      <th>ENSG00000260539</th>\n",
              "      <th>ENSG00000260612</th>\n",
              "      <th>ENSG00000260880</th>\n",
              "      <th>ENSG00000261215</th>\n",
              "      <th>ENSG00000261253</th>\n",
              "      <th>ENSG00000261351</th>\n",
              "      <th>ENSG00000261434</th>\n",
              "      <th>ENSG00000261452</th>\n",
              "      <th>ENSG00000261649</th>\n",
              "      <th>ENSG00000261685</th>\n",
              "      <th>ENSG00000261701</th>\n",
              "      <th>ENSG00000261742</th>\n",
              "      <th>ENSG00000261803</th>\n",
              "      <th>ENSG00000261819</th>\n",
              "      <th>ENSG00000261857</th>\n",
              "      <th>ENSG00000261925</th>\n",
              "      <th>ENSG00000262152</th>\n",
              "      <th>ENSG00000262557</th>\n",
              "      <th>ENSG00000262628</th>\n",
              "      <th>ENSG00000263002</th>\n",
              "      <th>ENSG00000263417</th>\n",
              "      <th>ENSG00000263574</th>\n",
              "      <th>ENSG00000263843</th>\n",
              "      <th>ENSG00000264247</th>\n",
              "      <th>ENSG00000264424</th>\n",
              "      <th>ENSG00000264575</th>\n",
              "      <th>ENSG00000265060</th>\n",
              "      <th>ENSG00000265246</th>\n",
              "      <th>ENSG00000265298</th>\n",
              "      <th>ENSG00000265480</th>\n",
              "      <th>ENSG00000265929</th>\n",
              "      <th>ENSG00000266066</th>\n",
              "      <th>ENSG00000266282</th>\n",
              "      <th>ENSG00000266433</th>\n",
              "      <th>ENSG00000266753</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>906826</td>\n",
              "      <td>0.090174</td>\n",
              "      <td>0.831734</td>\n",
              "      <td>0.134854</td>\n",
              "      <td>0.173938</td>\n",
              "      <td>0.056670</td>\n",
              "      <td>0.092200</td>\n",
              "      <td>0.711781</td>\n",
              "      <td>0.295762</td>\n",
              "      <td>0.340987</td>\n",
              "      <td>0.278234</td>\n",
              "      <td>0.742342</td>\n",
              "      <td>0.599873</td>\n",
              "      <td>0.310306</td>\n",
              "      <td>0.147415</td>\n",
              "      <td>0.031824</td>\n",
              "      <td>0.418007</td>\n",
              "      <td>0.172443</td>\n",
              "      <td>0.319434</td>\n",
              "      <td>0.680111</td>\n",
              "      <td>0.526486</td>\n",
              "      <td>0.679726</td>\n",
              "      <td>0.125355</td>\n",
              "      <td>0.051405</td>\n",
              "      <td>0.186721</td>\n",
              "      <td>0.031059</td>\n",
              "      <td>0.190874</td>\n",
              "      <td>0.342158</td>\n",
              "      <td>0.230392</td>\n",
              "      <td>0.035336</td>\n",
              "      <td>0.820529</td>\n",
              "      <td>0.471317</td>\n",
              "      <td>0.172845</td>\n",
              "      <td>0.151907</td>\n",
              "      <td>0.260020</td>\n",
              "      <td>0.199171</td>\n",
              "      <td>0.066666</td>\n",
              "      <td>0.361543</td>\n",
              "      <td>0.977863</td>\n",
              "      <td>0.429066</td>\n",
              "      <td>...</td>\n",
              "      <td>0.172654</td>\n",
              "      <td>0.320180</td>\n",
              "      <td>0.066718</td>\n",
              "      <td>0.132262</td>\n",
              "      <td>0.133767</td>\n",
              "      <td>0.307158</td>\n",
              "      <td>0.231446</td>\n",
              "      <td>0.019054</td>\n",
              "      <td>0.282120</td>\n",
              "      <td>0.148932</td>\n",
              "      <td>0.259837</td>\n",
              "      <td>0.092130</td>\n",
              "      <td>0.032295</td>\n",
              "      <td>0.217113</td>\n",
              "      <td>0.043037</td>\n",
              "      <td>0.057655</td>\n",
              "      <td>0.072909</td>\n",
              "      <td>0.617143</td>\n",
              "      <td>0.491339</td>\n",
              "      <td>0.060244</td>\n",
              "      <td>0.083015</td>\n",
              "      <td>0.139713</td>\n",
              "      <td>0.221998</td>\n",
              "      <td>0.132657</td>\n",
              "      <td>0.669727</td>\n",
              "      <td>0.168623</td>\n",
              "      <td>0.326715</td>\n",
              "      <td>0.502761</td>\n",
              "      <td>0.135343</td>\n",
              "      <td>0.038248</td>\n",
              "      <td>0.759824</td>\n",
              "      <td>0.244857</td>\n",
              "      <td>0.086937</td>\n",
              "      <td>0.270578</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.061037</td>\n",
              "      <td>0.294185</td>\n",
              "      <td>0.662015</td>\n",
              "      <td>0.187001</td>\n",
              "      <td>0.398991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>687983</td>\n",
              "      <td>0.054091</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.260056</td>\n",
              "      <td>0.293690</td>\n",
              "      <td>0.035300</td>\n",
              "      <td>0.570020</td>\n",
              "      <td>0.498266</td>\n",
              "      <td>0.374794</td>\n",
              "      <td>0.739398</td>\n",
              "      <td>0.338531</td>\n",
              "      <td>0.413151</td>\n",
              "      <td>0.502340</td>\n",
              "      <td>0.607386</td>\n",
              "      <td>0.110605</td>\n",
              "      <td>0.043824</td>\n",
              "      <td>0.421579</td>\n",
              "      <td>0.216578</td>\n",
              "      <td>0.376647</td>\n",
              "      <td>0.683961</td>\n",
              "      <td>0.578262</td>\n",
              "      <td>0.681248</td>\n",
              "      <td>0.055207</td>\n",
              "      <td>0.035425</td>\n",
              "      <td>0.022377</td>\n",
              "      <td>0.067788</td>\n",
              "      <td>0.305928</td>\n",
              "      <td>0.245438</td>\n",
              "      <td>0.336185</td>\n",
              "      <td>0.041887</td>\n",
              "      <td>0.698167</td>\n",
              "      <td>0.069602</td>\n",
              "      <td>0.097481</td>\n",
              "      <td>0.213374</td>\n",
              "      <td>0.439000</td>\n",
              "      <td>0.216370</td>\n",
              "      <td>0.046950</td>\n",
              "      <td>0.233082</td>\n",
              "      <td>0.050551</td>\n",
              "      <td>0.613009</td>\n",
              "      <td>...</td>\n",
              "      <td>0.536404</td>\n",
              "      <td>0.026991</td>\n",
              "      <td>0.034909</td>\n",
              "      <td>0.241586</td>\n",
              "      <td>0.184873</td>\n",
              "      <td>0.440619</td>\n",
              "      <td>0.293674</td>\n",
              "      <td>0.064394</td>\n",
              "      <td>0.261089</td>\n",
              "      <td>0.271386</td>\n",
              "      <td>0.560891</td>\n",
              "      <td>0.080544</td>\n",
              "      <td>0.647544</td>\n",
              "      <td>0.254231</td>\n",
              "      <td>0.054425</td>\n",
              "      <td>0.055732</td>\n",
              "      <td>0.087818</td>\n",
              "      <td>0.440152</td>\n",
              "      <td>0.760993</td>\n",
              "      <td>0.040269</td>\n",
              "      <td>0.098719</td>\n",
              "      <td>0.046183</td>\n",
              "      <td>0.263360</td>\n",
              "      <td>0.201099</td>\n",
              "      <td>0.554002</td>\n",
              "      <td>0.134859</td>\n",
              "      <td>0.375896</td>\n",
              "      <td>0.215475</td>\n",
              "      <td>0.177461</td>\n",
              "      <td>0.062879</td>\n",
              "      <td>0.486777</td>\n",
              "      <td>0.464771</td>\n",
              "      <td>0.077337</td>\n",
              "      <td>0.507740</td>\n",
              "      <td>0.111780</td>\n",
              "      <td>0.051589</td>\n",
              "      <td>0.356246</td>\n",
              "      <td>0.454642</td>\n",
              "      <td>0.134000</td>\n",
              "      <td>0.590433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>910927</td>\n",
              "      <td>0.028176</td>\n",
              "      <td>0.772948</td>\n",
              "      <td>0.229411</td>\n",
              "      <td>0.124901</td>\n",
              "      <td>0.046320</td>\n",
              "      <td>0.020954</td>\n",
              "      <td>0.709995</td>\n",
              "      <td>0.322153</td>\n",
              "      <td>0.287242</td>\n",
              "      <td>0.412678</td>\n",
              "      <td>0.393641</td>\n",
              "      <td>0.311474</td>\n",
              "      <td>0.321922</td>\n",
              "      <td>0.218414</td>\n",
              "      <td>0.016277</td>\n",
              "      <td>0.343545</td>\n",
              "      <td>0.206756</td>\n",
              "      <td>0.245505</td>\n",
              "      <td>0.672980</td>\n",
              "      <td>0.383428</td>\n",
              "      <td>0.739074</td>\n",
              "      <td>0.185688</td>\n",
              "      <td>0.036071</td>\n",
              "      <td>0.017455</td>\n",
              "      <td>0.100955</td>\n",
              "      <td>0.214566</td>\n",
              "      <td>0.154880</td>\n",
              "      <td>0.203514</td>\n",
              "      <td>0.020999</td>\n",
              "      <td>0.701153</td>\n",
              "      <td>0.044331</td>\n",
              "      <td>0.099277</td>\n",
              "      <td>0.015990</td>\n",
              "      <td>0.412989</td>\n",
              "      <td>0.159140</td>\n",
              "      <td>0.234605</td>\n",
              "      <td>0.370474</td>\n",
              "      <td>0.778290</td>\n",
              "      <td>0.393368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.165700</td>\n",
              "      <td>0.077543</td>\n",
              "      <td>0.050955</td>\n",
              "      <td>0.244059</td>\n",
              "      <td>0.122437</td>\n",
              "      <td>0.521862</td>\n",
              "      <td>0.262982</td>\n",
              "      <td>0.079300</td>\n",
              "      <td>0.474512</td>\n",
              "      <td>0.191074</td>\n",
              "      <td>0.254567</td>\n",
              "      <td>0.056056</td>\n",
              "      <td>0.721048</td>\n",
              "      <td>0.120380</td>\n",
              "      <td>0.012275</td>\n",
              "      <td>0.037707</td>\n",
              "      <td>0.052386</td>\n",
              "      <td>0.277275</td>\n",
              "      <td>0.696679</td>\n",
              "      <td>0.043741</td>\n",
              "      <td>0.037792</td>\n",
              "      <td>0.072692</td>\n",
              "      <td>0.220876</td>\n",
              "      <td>0.200668</td>\n",
              "      <td>0.401915</td>\n",
              "      <td>0.163329</td>\n",
              "      <td>0.437672</td>\n",
              "      <td>0.162127</td>\n",
              "      <td>0.210804</td>\n",
              "      <td>0.034210</td>\n",
              "      <td>0.082525</td>\n",
              "      <td>0.339761</td>\n",
              "      <td>0.052709</td>\n",
              "      <td>0.515632</td>\n",
              "      <td>0.074360</td>\n",
              "      <td>0.040184</td>\n",
              "      <td>0.315879</td>\n",
              "      <td>0.477919</td>\n",
              "      <td>0.073528</td>\n",
              "      <td>0.363586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1240138</td>\n",
              "      <td>0.061855</td>\n",
              "      <td>0.773271</td>\n",
              "      <td>0.259174</td>\n",
              "      <td>0.234437</td>\n",
              "      <td>0.028955</td>\n",
              "      <td>0.501000</td>\n",
              "      <td>0.769090</td>\n",
              "      <td>0.348427</td>\n",
              "      <td>0.260334</td>\n",
              "      <td>0.194173</td>\n",
              "      <td>0.590428</td>\n",
              "      <td>0.182881</td>\n",
              "      <td>0.468570</td>\n",
              "      <td>0.167707</td>\n",
              "      <td>0.022746</td>\n",
              "      <td>0.196373</td>\n",
              "      <td>0.198716</td>\n",
              "      <td>0.092587</td>\n",
              "      <td>0.730317</td>\n",
              "      <td>0.312400</td>\n",
              "      <td>0.541029</td>\n",
              "      <td>0.042277</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.022821</td>\n",
              "      <td>0.129346</td>\n",
              "      <td>0.221094</td>\n",
              "      <td>0.351700</td>\n",
              "      <td>0.184301</td>\n",
              "      <td>0.034182</td>\n",
              "      <td>0.714869</td>\n",
              "      <td>0.084176</td>\n",
              "      <td>0.171028</td>\n",
              "      <td>0.596462</td>\n",
              "      <td>0.206212</td>\n",
              "      <td>0.186972</td>\n",
              "      <td>0.196681</td>\n",
              "      <td>0.499387</td>\n",
              "      <td>0.497512</td>\n",
              "      <td>0.258113</td>\n",
              "      <td>...</td>\n",
              "      <td>0.140226</td>\n",
              "      <td>0.316679</td>\n",
              "      <td>0.166627</td>\n",
              "      <td>0.274978</td>\n",
              "      <td>0.151700</td>\n",
              "      <td>0.252854</td>\n",
              "      <td>0.376361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366580</td>\n",
              "      <td>0.126492</td>\n",
              "      <td>0.297160</td>\n",
              "      <td>0.059973</td>\n",
              "      <td>0.603815</td>\n",
              "      <td>0.467051</td>\n",
              "      <td>0.032428</td>\n",
              "      <td>0.042165</td>\n",
              "      <td>0.062093</td>\n",
              "      <td>0.381049</td>\n",
              "      <td>0.615017</td>\n",
              "      <td>0.031989</td>\n",
              "      <td>0.064793</td>\n",
              "      <td>0.054981</td>\n",
              "      <td>0.085451</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>0.336091</td>\n",
              "      <td>0.181669</td>\n",
              "      <td>0.320983</td>\n",
              "      <td>0.303929</td>\n",
              "      <td>0.035810</td>\n",
              "      <td>0.036751</td>\n",
              "      <td>0.084549</td>\n",
              "      <td>0.372276</td>\n",
              "      <td>0.037546</td>\n",
              "      <td>0.267656</td>\n",
              "      <td>0.400978</td>\n",
              "      <td>0.133843</td>\n",
              "      <td>0.267383</td>\n",
              "      <td>0.656043</td>\n",
              "      <td>0.318726</td>\n",
              "      <td>0.404231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1240139</td>\n",
              "      <td>0.088852</td>\n",
              "      <td>0.836364</td>\n",
              "      <td>0.336107</td>\n",
              "      <td>0.330414</td>\n",
              "      <td>0.016621</td>\n",
              "      <td>0.070789</td>\n",
              "      <td>0.724211</td>\n",
              "      <td>0.355544</td>\n",
              "      <td>0.083657</td>\n",
              "      <td>0.126718</td>\n",
              "      <td>0.494024</td>\n",
              "      <td>0.489154</td>\n",
              "      <td>0.529315</td>\n",
              "      <td>0.038617</td>\n",
              "      <td>0.043574</td>\n",
              "      <td>0.515520</td>\n",
              "      <td>0.189364</td>\n",
              "      <td>0.397824</td>\n",
              "      <td>0.595536</td>\n",
              "      <td>0.196272</td>\n",
              "      <td>0.648330</td>\n",
              "      <td>0.201501</td>\n",
              "      <td>0.058255</td>\n",
              "      <td>0.040653</td>\n",
              "      <td>0.072281</td>\n",
              "      <td>0.213277</td>\n",
              "      <td>0.454418</td>\n",
              "      <td>0.382668</td>\n",
              "      <td>0.034089</td>\n",
              "      <td>0.912117</td>\n",
              "      <td>0.037130</td>\n",
              "      <td>0.085330</td>\n",
              "      <td>0.108092</td>\n",
              "      <td>0.111587</td>\n",
              "      <td>0.280351</td>\n",
              "      <td>0.265903</td>\n",
              "      <td>0.279810</td>\n",
              "      <td>0.574992</td>\n",
              "      <td>0.620433</td>\n",
              "      <td>...</td>\n",
              "      <td>0.413198</td>\n",
              "      <td>0.113996</td>\n",
              "      <td>0.012176</td>\n",
              "      <td>0.121574</td>\n",
              "      <td>0.176264</td>\n",
              "      <td>0.552606</td>\n",
              "      <td>0.197809</td>\n",
              "      <td>0.027883</td>\n",
              "      <td>0.271277</td>\n",
              "      <td>0.261868</td>\n",
              "      <td>0.196197</td>\n",
              "      <td>0.060743</td>\n",
              "      <td>0.115823</td>\n",
              "      <td>0.128144</td>\n",
              "      <td>0.039210</td>\n",
              "      <td>0.037267</td>\n",
              "      <td>0.042149</td>\n",
              "      <td>0.240381</td>\n",
              "      <td>0.591982</td>\n",
              "      <td>0.066232</td>\n",
              "      <td>0.088704</td>\n",
              "      <td>0.081633</td>\n",
              "      <td>0.190575</td>\n",
              "      <td>0.252984</td>\n",
              "      <td>0.681710</td>\n",
              "      <td>0.149895</td>\n",
              "      <td>0.287542</td>\n",
              "      <td>0.233630</td>\n",
              "      <td>0.087411</td>\n",
              "      <td>0.009784</td>\n",
              "      <td>0.177255</td>\n",
              "      <td>0.180061</td>\n",
              "      <td>0.037319</td>\n",
              "      <td>0.586302</td>\n",
              "      <td>0.259986</td>\n",
              "      <td>0.073348</td>\n",
              "      <td>0.333650</td>\n",
              "      <td>0.651974</td>\n",
              "      <td>0.419353</td>\n",
              "      <td>0.468367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>1298157</td>\n",
              "      <td>0.027359</td>\n",
              "      <td>0.959507</td>\n",
              "      <td>0.359467</td>\n",
              "      <td>0.515710</td>\n",
              "      <td>0.044864</td>\n",
              "      <td>0.092744</td>\n",
              "      <td>0.710230</td>\n",
              "      <td>0.355844</td>\n",
              "      <td>0.248984</td>\n",
              "      <td>0.345024</td>\n",
              "      <td>0.694234</td>\n",
              "      <td>0.523141</td>\n",
              "      <td>0.163646</td>\n",
              "      <td>0.307159</td>\n",
              "      <td>0.044090</td>\n",
              "      <td>0.414590</td>\n",
              "      <td>0.106494</td>\n",
              "      <td>0.416769</td>\n",
              "      <td>0.638885</td>\n",
              "      <td>0.402110</td>\n",
              "      <td>0.523680</td>\n",
              "      <td>0.080156</td>\n",
              "      <td>0.052827</td>\n",
              "      <td>0.048459</td>\n",
              "      <td>0.111618</td>\n",
              "      <td>0.126456</td>\n",
              "      <td>0.312534</td>\n",
              "      <td>0.277837</td>\n",
              "      <td>0.037908</td>\n",
              "      <td>0.806088</td>\n",
              "      <td>0.096805</td>\n",
              "      <td>0.133687</td>\n",
              "      <td>0.066497</td>\n",
              "      <td>0.239089</td>\n",
              "      <td>0.199501</td>\n",
              "      <td>0.151576</td>\n",
              "      <td>0.280078</td>\n",
              "      <td>0.597179</td>\n",
              "      <td>0.553442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279965</td>\n",
              "      <td>0.495366</td>\n",
              "      <td>0.071721</td>\n",
              "      <td>0.220917</td>\n",
              "      <td>0.313533</td>\n",
              "      <td>0.397822</td>\n",
              "      <td>0.318628</td>\n",
              "      <td>0.056417</td>\n",
              "      <td>0.499499</td>\n",
              "      <td>0.532195</td>\n",
              "      <td>0.254144</td>\n",
              "      <td>0.089226</td>\n",
              "      <td>0.081519</td>\n",
              "      <td>0.133549</td>\n",
              "      <td>0.131000</td>\n",
              "      <td>0.085147</td>\n",
              "      <td>0.038093</td>\n",
              "      <td>0.459311</td>\n",
              "      <td>0.587845</td>\n",
              "      <td>0.068397</td>\n",
              "      <td>0.101239</td>\n",
              "      <td>0.097643</td>\n",
              "      <td>0.260141</td>\n",
              "      <td>0.227539</td>\n",
              "      <td>0.541206</td>\n",
              "      <td>0.146204</td>\n",
              "      <td>0.405486</td>\n",
              "      <td>0.494672</td>\n",
              "      <td>0.158422</td>\n",
              "      <td>0.032849</td>\n",
              "      <td>0.445880</td>\n",
              "      <td>0.332203</td>\n",
              "      <td>0.112444</td>\n",
              "      <td>0.338273</td>\n",
              "      <td>0.235684</td>\n",
              "      <td>0.074313</td>\n",
              "      <td>0.235501</td>\n",
              "      <td>0.524071</td>\n",
              "      <td>0.447665</td>\n",
              "      <td>0.886561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>1480372</td>\n",
              "      <td>0.073820</td>\n",
              "      <td>0.852738</td>\n",
              "      <td>0.117018</td>\n",
              "      <td>0.468891</td>\n",
              "      <td>0.038269</td>\n",
              "      <td>0.064777</td>\n",
              "      <td>0.805546</td>\n",
              "      <td>0.220018</td>\n",
              "      <td>0.091385</td>\n",
              "      <td>0.214763</td>\n",
              "      <td>0.215043</td>\n",
              "      <td>0.524350</td>\n",
              "      <td>0.373020</td>\n",
              "      <td>0.295909</td>\n",
              "      <td>0.040198</td>\n",
              "      <td>0.490534</td>\n",
              "      <td>0.255476</td>\n",
              "      <td>0.248416</td>\n",
              "      <td>0.692417</td>\n",
              "      <td>0.769541</td>\n",
              "      <td>0.534635</td>\n",
              "      <td>0.180956</td>\n",
              "      <td>0.047423</td>\n",
              "      <td>0.028071</td>\n",
              "      <td>0.067124</td>\n",
              "      <td>0.085290</td>\n",
              "      <td>0.296303</td>\n",
              "      <td>0.290001</td>\n",
              "      <td>0.029303</td>\n",
              "      <td>0.827800</td>\n",
              "      <td>0.355242</td>\n",
              "      <td>0.215527</td>\n",
              "      <td>0.195924</td>\n",
              "      <td>0.279796</td>\n",
              "      <td>0.137408</td>\n",
              "      <td>0.078883</td>\n",
              "      <td>0.269550</td>\n",
              "      <td>0.034215</td>\n",
              "      <td>0.533017</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275081</td>\n",
              "      <td>0.074618</td>\n",
              "      <td>0.037855</td>\n",
              "      <td>0.104034</td>\n",
              "      <td>0.103202</td>\n",
              "      <td>0.283133</td>\n",
              "      <td>0.115526</td>\n",
              "      <td>0.144306</td>\n",
              "      <td>0.352280</td>\n",
              "      <td>0.559440</td>\n",
              "      <td>0.373613</td>\n",
              "      <td>0.090806</td>\n",
              "      <td>0.094415</td>\n",
              "      <td>0.310192</td>\n",
              "      <td>0.069056</td>\n",
              "      <td>0.074242</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.284680</td>\n",
              "      <td>0.660530</td>\n",
              "      <td>0.075172</td>\n",
              "      <td>0.085748</td>\n",
              "      <td>0.040536</td>\n",
              "      <td>0.438609</td>\n",
              "      <td>0.382912</td>\n",
              "      <td>0.336809</td>\n",
              "      <td>0.123039</td>\n",
              "      <td>0.201447</td>\n",
              "      <td>0.475016</td>\n",
              "      <td>0.170436</td>\n",
              "      <td>0.008726</td>\n",
              "      <td>0.287065</td>\n",
              "      <td>0.275431</td>\n",
              "      <td>0.071945</td>\n",
              "      <td>0.650397</td>\n",
              "      <td>0.259976</td>\n",
              "      <td>0.076242</td>\n",
              "      <td>0.274247</td>\n",
              "      <td>0.821378</td>\n",
              "      <td>0.363008</td>\n",
              "      <td>0.229402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>1298533</td>\n",
              "      <td>0.004553</td>\n",
              "      <td>0.880430</td>\n",
              "      <td>0.364310</td>\n",
              "      <td>0.068647</td>\n",
              "      <td>0.045955</td>\n",
              "      <td>0.276464</td>\n",
              "      <td>0.694144</td>\n",
              "      <td>0.352019</td>\n",
              "      <td>0.269970</td>\n",
              "      <td>0.181171</td>\n",
              "      <td>0.576120</td>\n",
              "      <td>0.217004</td>\n",
              "      <td>0.574435</td>\n",
              "      <td>0.184465</td>\n",
              "      <td>0.073986</td>\n",
              "      <td>0.321139</td>\n",
              "      <td>0.091324</td>\n",
              "      <td>0.627098</td>\n",
              "      <td>0.423852</td>\n",
              "      <td>0.656984</td>\n",
              "      <td>0.409097</td>\n",
              "      <td>0.652559</td>\n",
              "      <td>0.061183</td>\n",
              "      <td>0.036018</td>\n",
              "      <td>0.103056</td>\n",
              "      <td>0.372518</td>\n",
              "      <td>0.327165</td>\n",
              "      <td>0.196041</td>\n",
              "      <td>0.011444</td>\n",
              "      <td>0.893187</td>\n",
              "      <td>0.085812</td>\n",
              "      <td>0.118146</td>\n",
              "      <td>0.578110</td>\n",
              "      <td>0.241989</td>\n",
              "      <td>0.345898</td>\n",
              "      <td>0.175183</td>\n",
              "      <td>0.551191</td>\n",
              "      <td>0.561866</td>\n",
              "      <td>0.437294</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227347</td>\n",
              "      <td>0.208725</td>\n",
              "      <td>0.058879</td>\n",
              "      <td>0.329007</td>\n",
              "      <td>0.413728</td>\n",
              "      <td>0.508648</td>\n",
              "      <td>0.302141</td>\n",
              "      <td>0.156915</td>\n",
              "      <td>0.379266</td>\n",
              "      <td>0.601128</td>\n",
              "      <td>0.150778</td>\n",
              "      <td>0.065662</td>\n",
              "      <td>0.102571</td>\n",
              "      <td>0.456914</td>\n",
              "      <td>0.035104</td>\n",
              "      <td>0.037546</td>\n",
              "      <td>0.024604</td>\n",
              "      <td>0.775284</td>\n",
              "      <td>0.622757</td>\n",
              "      <td>0.141688</td>\n",
              "      <td>0.070532</td>\n",
              "      <td>0.211050</td>\n",
              "      <td>0.403960</td>\n",
              "      <td>0.163731</td>\n",
              "      <td>0.603548</td>\n",
              "      <td>0.137243</td>\n",
              "      <td>0.411822</td>\n",
              "      <td>0.700503</td>\n",
              "      <td>0.164547</td>\n",
              "      <td>0.034248</td>\n",
              "      <td>0.443456</td>\n",
              "      <td>0.232336</td>\n",
              "      <td>0.200182</td>\n",
              "      <td>0.446087</td>\n",
              "      <td>0.340376</td>\n",
              "      <td>0.067441</td>\n",
              "      <td>0.159287</td>\n",
              "      <td>0.358076</td>\n",
              "      <td>0.259640</td>\n",
              "      <td>0.373019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>930299</td>\n",
              "      <td>0.072001</td>\n",
              "      <td>0.772143</td>\n",
              "      <td>0.315427</td>\n",
              "      <td>0.122715</td>\n",
              "      <td>0.019838</td>\n",
              "      <td>0.074347</td>\n",
              "      <td>0.383091</td>\n",
              "      <td>0.378234</td>\n",
              "      <td>0.380313</td>\n",
              "      <td>0.153446</td>\n",
              "      <td>0.634884</td>\n",
              "      <td>0.230125</td>\n",
              "      <td>0.663346</td>\n",
              "      <td>0.508455</td>\n",
              "      <td>0.034398</td>\n",
              "      <td>0.374662</td>\n",
              "      <td>0.232526</td>\n",
              "      <td>0.136101</td>\n",
              "      <td>0.814045</td>\n",
              "      <td>0.384851</td>\n",
              "      <td>0.561460</td>\n",
              "      <td>0.354532</td>\n",
              "      <td>0.465207</td>\n",
              "      <td>0.016535</td>\n",
              "      <td>0.309236</td>\n",
              "      <td>0.263656</td>\n",
              "      <td>0.141825</td>\n",
              "      <td>0.237645</td>\n",
              "      <td>0.572934</td>\n",
              "      <td>0.697386</td>\n",
              "      <td>0.626372</td>\n",
              "      <td>0.080712</td>\n",
              "      <td>0.664680</td>\n",
              "      <td>0.413097</td>\n",
              "      <td>0.246998</td>\n",
              "      <td>0.104478</td>\n",
              "      <td>0.256957</td>\n",
              "      <td>0.057628</td>\n",
              "      <td>0.185676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.191653</td>\n",
              "      <td>0.037337</td>\n",
              "      <td>0.092299</td>\n",
              "      <td>0.276874</td>\n",
              "      <td>0.219018</td>\n",
              "      <td>0.589439</td>\n",
              "      <td>0.150473</td>\n",
              "      <td>0.056181</td>\n",
              "      <td>0.309105</td>\n",
              "      <td>0.396257</td>\n",
              "      <td>0.209121</td>\n",
              "      <td>0.078095</td>\n",
              "      <td>0.683304</td>\n",
              "      <td>0.189459</td>\n",
              "      <td>0.044325</td>\n",
              "      <td>0.008102</td>\n",
              "      <td>0.058907</td>\n",
              "      <td>0.213952</td>\n",
              "      <td>0.626235</td>\n",
              "      <td>0.091539</td>\n",
              "      <td>0.110743</td>\n",
              "      <td>0.024473</td>\n",
              "      <td>0.542192</td>\n",
              "      <td>0.126217</td>\n",
              "      <td>0.352672</td>\n",
              "      <td>0.175157</td>\n",
              "      <td>0.193137</td>\n",
              "      <td>0.391886</td>\n",
              "      <td>0.044577</td>\n",
              "      <td>0.022681</td>\n",
              "      <td>0.425107</td>\n",
              "      <td>0.240812</td>\n",
              "      <td>0.087244</td>\n",
              "      <td>0.444588</td>\n",
              "      <td>0.164724</td>\n",
              "      <td>0.061712</td>\n",
              "      <td>0.152301</td>\n",
              "      <td>0.643873</td>\n",
              "      <td>0.309402</td>\n",
              "      <td>0.451953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>905954</td>\n",
              "      <td>0.065014</td>\n",
              "      <td>0.879896</td>\n",
              "      <td>0.269363</td>\n",
              "      <td>0.192699</td>\n",
              "      <td>0.057363</td>\n",
              "      <td>0.035785</td>\n",
              "      <td>0.710024</td>\n",
              "      <td>0.308800</td>\n",
              "      <td>0.451043</td>\n",
              "      <td>0.516425</td>\n",
              "      <td>0.834278</td>\n",
              "      <td>0.235049</td>\n",
              "      <td>0.172414</td>\n",
              "      <td>0.083583</td>\n",
              "      <td>0.025721</td>\n",
              "      <td>0.458845</td>\n",
              "      <td>0.310781</td>\n",
              "      <td>0.117603</td>\n",
              "      <td>0.221524</td>\n",
              "      <td>0.541814</td>\n",
              "      <td>0.695960</td>\n",
              "      <td>0.097568</td>\n",
              "      <td>0.077095</td>\n",
              "      <td>0.036823</td>\n",
              "      <td>0.048511</td>\n",
              "      <td>0.774323</td>\n",
              "      <td>0.112093</td>\n",
              "      <td>0.274524</td>\n",
              "      <td>0.067498</td>\n",
              "      <td>0.725596</td>\n",
              "      <td>0.161685</td>\n",
              "      <td>0.066904</td>\n",
              "      <td>0.226281</td>\n",
              "      <td>0.232928</td>\n",
              "      <td>0.379641</td>\n",
              "      <td>0.176544</td>\n",
              "      <td>0.312147</td>\n",
              "      <td>0.330700</td>\n",
              "      <td>0.602107</td>\n",
              "      <td>...</td>\n",
              "      <td>0.201090</td>\n",
              "      <td>0.647809</td>\n",
              "      <td>0.070094</td>\n",
              "      <td>0.127168</td>\n",
              "      <td>0.112842</td>\n",
              "      <td>0.236906</td>\n",
              "      <td>0.247013</td>\n",
              "      <td>0.398347</td>\n",
              "      <td>0.342736</td>\n",
              "      <td>0.392180</td>\n",
              "      <td>0.408267</td>\n",
              "      <td>0.108048</td>\n",
              "      <td>0.561988</td>\n",
              "      <td>0.236142</td>\n",
              "      <td>0.061637</td>\n",
              "      <td>0.062930</td>\n",
              "      <td>0.045521</td>\n",
              "      <td>0.490115</td>\n",
              "      <td>0.767338</td>\n",
              "      <td>0.913164</td>\n",
              "      <td>0.155125</td>\n",
              "      <td>0.100233</td>\n",
              "      <td>0.304835</td>\n",
              "      <td>0.159595</td>\n",
              "      <td>0.351143</td>\n",
              "      <td>0.181313</td>\n",
              "      <td>0.430627</td>\n",
              "      <td>0.331241</td>\n",
              "      <td>0.215530</td>\n",
              "      <td>0.055069</td>\n",
              "      <td>0.309126</td>\n",
              "      <td>0.218100</td>\n",
              "      <td>0.123343</td>\n",
              "      <td>0.420108</td>\n",
              "      <td>0.088810</td>\n",
              "      <td>0.083622</td>\n",
              "      <td>0.144783</td>\n",
              "      <td>0.469213</td>\n",
              "      <td>0.367745</td>\n",
              "      <td>0.399864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1018 rows × 17737 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3278d06b-4090-42f0-b04f-ef90f4fea3da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3278d06b-4090-42f0-b04f-ef90f4fea3da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3278d06b-4090-42f0-b04f-ef90f4fea3da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      COSMIC_ID  ENSG00000000003  ...  ENSG00000266433  ENSG00000266753\n",
              "0        906826         0.090174  ...         0.187001         0.398991\n",
              "1        687983         0.054091  ...         0.134000         0.590433\n",
              "2        910927         0.028176  ...         0.073528         0.363586\n",
              "3       1240138         0.061855  ...         0.318726         0.404231\n",
              "4       1240139         0.088852  ...         0.419353         0.468367\n",
              "...         ...              ...  ...              ...              ...\n",
              "1013    1298157         0.027359  ...         0.447665         0.886561\n",
              "1014    1480372         0.073820  ...         0.363008         0.229402\n",
              "1015    1298533         0.004553  ...         0.259640         0.373019\n",
              "1016     930299         0.072001  ...         0.309402         0.451953\n",
              "1017     905954         0.065014  ...         0.367745         0.399864\n",
              "\n",
              "[1018 rows x 17737 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/topmer.csv"
      ],
      "metadata": {
        "id": "TIr671WdK1dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN0jxaxI5Ct8"
      },
      "source": [
        "**Merge Normalized Gene data with drug responses ic50**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#topmer = pd.merge(drug_data,expdatanorm,on=\"COSMIC_ID\") \n",
        "topmer.to_csv(\"topmer.csv\")"
      ],
      "metadata": {
        "id": "voK59WL-9uGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "topmer = pd.read_csv(\"/content/topmer.csv\")"
      ],
      "metadata": {
        "id": "0xVwrfmXQjC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topmer = topmer.astype({\"COSMIC_ID\": int})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "qvoPQu8I97Pr",
        "outputId": "2d4f2c7d-5e4a-40f3-b942-9a0294a4c4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-35464e4b5ba9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"COSMIC_ID\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'topmer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "GXhB99Cv5Mhr",
        "outputId": "5098d599-70f4-4e90-f018-d3d45f5885d1"
      },
      "source": [
        "import pandas as pd\n",
        "topmer = pd.merge(drug_data,expdatanorm,on=\"COSMIC_ID\") \n",
        "topmer                                                #merge top 100 with normalized gene"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-724aa2a7-d805-475b-8acb-a2726187bf00\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "      <th>ENSG00000000003</th>\n",
              "      <th>ENSG00000000005</th>\n",
              "      <th>ENSG00000000419</th>\n",
              "      <th>ENSG00000000457</th>\n",
              "      <th>ENSG00000000938</th>\n",
              "      <th>ENSG00000000971</th>\n",
              "      <th>ENSG00000001036</th>\n",
              "      <th>ENSG00000001084</th>\n",
              "      <th>ENSG00000001167</th>\n",
              "      <th>ENSG00000001460</th>\n",
              "      <th>ENSG00000001461</th>\n",
              "      <th>ENSG00000001497</th>\n",
              "      <th>ENSG00000001561</th>\n",
              "      <th>ENSG00000001617</th>\n",
              "      <th>ENSG00000001626</th>\n",
              "      <th>ENSG00000001629</th>\n",
              "      <th>ENSG00000001631</th>\n",
              "      <th>ENSG00000002016</th>\n",
              "      <th>ENSG00000002330</th>\n",
              "      <th>ENSG00000002549</th>\n",
              "      <th>ENSG00000002586</th>\n",
              "      <th>ENSG00000002587</th>\n",
              "      <th>ENSG00000002726</th>\n",
              "      <th>ENSG00000002745</th>\n",
              "      <th>ENSG00000002746</th>\n",
              "      <th>ENSG00000002822</th>\n",
              "      <th>ENSG00000002834</th>\n",
              "      <th>ENSG00000002919</th>\n",
              "      <th>ENSG00000002933</th>\n",
              "      <th>ENSG00000003056</th>\n",
              "      <th>ENSG00000003096</th>\n",
              "      <th>ENSG00000003137</th>\n",
              "      <th>ENSG00000003147</th>\n",
              "      <th>ENSG00000003249</th>\n",
              "      <th>ENSG00000003393</th>\n",
              "      <th>ENSG00000003400</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000260347</th>\n",
              "      <th>ENSG00000260359</th>\n",
              "      <th>ENSG00000260432</th>\n",
              "      <th>ENSG00000260461</th>\n",
              "      <th>ENSG00000260495</th>\n",
              "      <th>ENSG00000260539</th>\n",
              "      <th>ENSG00000260612</th>\n",
              "      <th>ENSG00000260880</th>\n",
              "      <th>ENSG00000261215</th>\n",
              "      <th>ENSG00000261253</th>\n",
              "      <th>ENSG00000261351</th>\n",
              "      <th>ENSG00000261434</th>\n",
              "      <th>ENSG00000261452</th>\n",
              "      <th>ENSG00000261649</th>\n",
              "      <th>ENSG00000261685</th>\n",
              "      <th>ENSG00000261701</th>\n",
              "      <th>ENSG00000261742</th>\n",
              "      <th>ENSG00000261803</th>\n",
              "      <th>ENSG00000261819</th>\n",
              "      <th>ENSG00000261857</th>\n",
              "      <th>ENSG00000261925</th>\n",
              "      <th>ENSG00000262152</th>\n",
              "      <th>ENSG00000262557</th>\n",
              "      <th>ENSG00000262628</th>\n",
              "      <th>ENSG00000263002</th>\n",
              "      <th>ENSG00000263417</th>\n",
              "      <th>ENSG00000263574</th>\n",
              "      <th>ENSG00000263843</th>\n",
              "      <th>ENSG00000264247</th>\n",
              "      <th>ENSG00000264424</th>\n",
              "      <th>ENSG00000264575</th>\n",
              "      <th>ENSG00000265060</th>\n",
              "      <th>ENSG00000265246</th>\n",
              "      <th>ENSG00000265298</th>\n",
              "      <th>ENSG00000265480</th>\n",
              "      <th>ENSG00000265929</th>\n",
              "      <th>ENSG00000266066</th>\n",
              "      <th>ENSG00000266282</th>\n",
              "      <th>ENSG00000266433</th>\n",
              "      <th>ENSG00000266753</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "      <td>0.019699</td>\n",
              "      <td>0.831315</td>\n",
              "      <td>0.567871</td>\n",
              "      <td>0.475756</td>\n",
              "      <td>0.027848</td>\n",
              "      <td>0.384212</td>\n",
              "      <td>0.624164</td>\n",
              "      <td>0.852666</td>\n",
              "      <td>0.363793</td>\n",
              "      <td>0.191799</td>\n",
              "      <td>0.488027</td>\n",
              "      <td>0.396985</td>\n",
              "      <td>0.328996</td>\n",
              "      <td>0.446040</td>\n",
              "      <td>0.049895</td>\n",
              "      <td>0.428243</td>\n",
              "      <td>0.202829</td>\n",
              "      <td>0.231802</td>\n",
              "      <td>0.602156</td>\n",
              "      <td>0.649847</td>\n",
              "      <td>0.636162</td>\n",
              "      <td>0.128855</td>\n",
              "      <td>0.049585</td>\n",
              "      <td>0.043707</td>\n",
              "      <td>0.097299</td>\n",
              "      <td>0.248719</td>\n",
              "      <td>0.271042</td>\n",
              "      <td>0.279466</td>\n",
              "      <td>0.031348</td>\n",
              "      <td>0.820286</td>\n",
              "      <td>0.119649</td>\n",
              "      <td>0.242203</td>\n",
              "      <td>0.482941</td>\n",
              "      <td>0.437873</td>\n",
              "      <td>0.071037</td>\n",
              "      <td>0.248580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.08407</td>\n",
              "      <td>0.054874</td>\n",
              "      <td>0.232744</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.317984</td>\n",
              "      <td>0.078905</td>\n",
              "      <td>0.039098</td>\n",
              "      <td>0.252363</td>\n",
              "      <td>0.441084</td>\n",
              "      <td>0.428964</td>\n",
              "      <td>0.072481</td>\n",
              "      <td>0.081641</td>\n",
              "      <td>0.445432</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>0.064681</td>\n",
              "      <td>0.105559</td>\n",
              "      <td>0.208741</td>\n",
              "      <td>0.670001</td>\n",
              "      <td>0.061132</td>\n",
              "      <td>0.057705</td>\n",
              "      <td>0.101136</td>\n",
              "      <td>0.397858</td>\n",
              "      <td>0.165876</td>\n",
              "      <td>0.595242</td>\n",
              "      <td>0.197744</td>\n",
              "      <td>0.545309</td>\n",
              "      <td>0.548242</td>\n",
              "      <td>0.104354</td>\n",
              "      <td>0.038808</td>\n",
              "      <td>0.150977</td>\n",
              "      <td>0.258820</td>\n",
              "      <td>0.076482</td>\n",
              "      <td>0.254100</td>\n",
              "      <td>0.232049</td>\n",
              "      <td>0.083111</td>\n",
              "      <td>0.168700</td>\n",
              "      <td>0.407965</td>\n",
              "      <td>0.301499</td>\n",
              "      <td>0.493309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Cisplatin</td>\n",
              "      <td>5.005908</td>\n",
              "      <td>0.019699</td>\n",
              "      <td>0.831315</td>\n",
              "      <td>0.567871</td>\n",
              "      <td>0.475756</td>\n",
              "      <td>0.027848</td>\n",
              "      <td>0.384212</td>\n",
              "      <td>0.624164</td>\n",
              "      <td>0.852666</td>\n",
              "      <td>0.363793</td>\n",
              "      <td>0.191799</td>\n",
              "      <td>0.488027</td>\n",
              "      <td>0.396985</td>\n",
              "      <td>0.328996</td>\n",
              "      <td>0.446040</td>\n",
              "      <td>0.049895</td>\n",
              "      <td>0.428243</td>\n",
              "      <td>0.202829</td>\n",
              "      <td>0.231802</td>\n",
              "      <td>0.602156</td>\n",
              "      <td>0.649847</td>\n",
              "      <td>0.636162</td>\n",
              "      <td>0.128855</td>\n",
              "      <td>0.049585</td>\n",
              "      <td>0.043707</td>\n",
              "      <td>0.097299</td>\n",
              "      <td>0.248719</td>\n",
              "      <td>0.271042</td>\n",
              "      <td>0.279466</td>\n",
              "      <td>0.031348</td>\n",
              "      <td>0.820286</td>\n",
              "      <td>0.119649</td>\n",
              "      <td>0.242203</td>\n",
              "      <td>0.482941</td>\n",
              "      <td>0.437873</td>\n",
              "      <td>0.071037</td>\n",
              "      <td>0.248580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.08407</td>\n",
              "      <td>0.054874</td>\n",
              "      <td>0.232744</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.317984</td>\n",
              "      <td>0.078905</td>\n",
              "      <td>0.039098</td>\n",
              "      <td>0.252363</td>\n",
              "      <td>0.441084</td>\n",
              "      <td>0.428964</td>\n",
              "      <td>0.072481</td>\n",
              "      <td>0.081641</td>\n",
              "      <td>0.445432</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>0.064681</td>\n",
              "      <td>0.105559</td>\n",
              "      <td>0.208741</td>\n",
              "      <td>0.670001</td>\n",
              "      <td>0.061132</td>\n",
              "      <td>0.057705</td>\n",
              "      <td>0.101136</td>\n",
              "      <td>0.397858</td>\n",
              "      <td>0.165876</td>\n",
              "      <td>0.595242</td>\n",
              "      <td>0.197744</td>\n",
              "      <td>0.545309</td>\n",
              "      <td>0.548242</td>\n",
              "      <td>0.104354</td>\n",
              "      <td>0.038808</td>\n",
              "      <td>0.150977</td>\n",
              "      <td>0.258820</td>\n",
              "      <td>0.076482</td>\n",
              "      <td>0.254100</td>\n",
              "      <td>0.232049</td>\n",
              "      <td>0.083111</td>\n",
              "      <td>0.168700</td>\n",
              "      <td>0.407965</td>\n",
              "      <td>0.301499</td>\n",
              "      <td>0.493309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Cytarabine</td>\n",
              "      <td>3.947056</td>\n",
              "      <td>0.019699</td>\n",
              "      <td>0.831315</td>\n",
              "      <td>0.567871</td>\n",
              "      <td>0.475756</td>\n",
              "      <td>0.027848</td>\n",
              "      <td>0.384212</td>\n",
              "      <td>0.624164</td>\n",
              "      <td>0.852666</td>\n",
              "      <td>0.363793</td>\n",
              "      <td>0.191799</td>\n",
              "      <td>0.488027</td>\n",
              "      <td>0.396985</td>\n",
              "      <td>0.328996</td>\n",
              "      <td>0.446040</td>\n",
              "      <td>0.049895</td>\n",
              "      <td>0.428243</td>\n",
              "      <td>0.202829</td>\n",
              "      <td>0.231802</td>\n",
              "      <td>0.602156</td>\n",
              "      <td>0.649847</td>\n",
              "      <td>0.636162</td>\n",
              "      <td>0.128855</td>\n",
              "      <td>0.049585</td>\n",
              "      <td>0.043707</td>\n",
              "      <td>0.097299</td>\n",
              "      <td>0.248719</td>\n",
              "      <td>0.271042</td>\n",
              "      <td>0.279466</td>\n",
              "      <td>0.031348</td>\n",
              "      <td>0.820286</td>\n",
              "      <td>0.119649</td>\n",
              "      <td>0.242203</td>\n",
              "      <td>0.482941</td>\n",
              "      <td>0.437873</td>\n",
              "      <td>0.071037</td>\n",
              "      <td>0.248580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.08407</td>\n",
              "      <td>0.054874</td>\n",
              "      <td>0.232744</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.317984</td>\n",
              "      <td>0.078905</td>\n",
              "      <td>0.039098</td>\n",
              "      <td>0.252363</td>\n",
              "      <td>0.441084</td>\n",
              "      <td>0.428964</td>\n",
              "      <td>0.072481</td>\n",
              "      <td>0.081641</td>\n",
              "      <td>0.445432</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>0.064681</td>\n",
              "      <td>0.105559</td>\n",
              "      <td>0.208741</td>\n",
              "      <td>0.670001</td>\n",
              "      <td>0.061132</td>\n",
              "      <td>0.057705</td>\n",
              "      <td>0.101136</td>\n",
              "      <td>0.397858</td>\n",
              "      <td>0.165876</td>\n",
              "      <td>0.595242</td>\n",
              "      <td>0.197744</td>\n",
              "      <td>0.545309</td>\n",
              "      <td>0.548242</td>\n",
              "      <td>0.104354</td>\n",
              "      <td>0.038808</td>\n",
              "      <td>0.150977</td>\n",
              "      <td>0.258820</td>\n",
              "      <td>0.076482</td>\n",
              "      <td>0.254100</td>\n",
              "      <td>0.232049</td>\n",
              "      <td>0.083111</td>\n",
              "      <td>0.168700</td>\n",
              "      <td>0.407965</td>\n",
              "      <td>0.301499</td>\n",
              "      <td>0.493309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Docetaxel</td>\n",
              "      <td>-4.177968</td>\n",
              "      <td>0.019699</td>\n",
              "      <td>0.831315</td>\n",
              "      <td>0.567871</td>\n",
              "      <td>0.475756</td>\n",
              "      <td>0.027848</td>\n",
              "      <td>0.384212</td>\n",
              "      <td>0.624164</td>\n",
              "      <td>0.852666</td>\n",
              "      <td>0.363793</td>\n",
              "      <td>0.191799</td>\n",
              "      <td>0.488027</td>\n",
              "      <td>0.396985</td>\n",
              "      <td>0.328996</td>\n",
              "      <td>0.446040</td>\n",
              "      <td>0.049895</td>\n",
              "      <td>0.428243</td>\n",
              "      <td>0.202829</td>\n",
              "      <td>0.231802</td>\n",
              "      <td>0.602156</td>\n",
              "      <td>0.649847</td>\n",
              "      <td>0.636162</td>\n",
              "      <td>0.128855</td>\n",
              "      <td>0.049585</td>\n",
              "      <td>0.043707</td>\n",
              "      <td>0.097299</td>\n",
              "      <td>0.248719</td>\n",
              "      <td>0.271042</td>\n",
              "      <td>0.279466</td>\n",
              "      <td>0.031348</td>\n",
              "      <td>0.820286</td>\n",
              "      <td>0.119649</td>\n",
              "      <td>0.242203</td>\n",
              "      <td>0.482941</td>\n",
              "      <td>0.437873</td>\n",
              "      <td>0.071037</td>\n",
              "      <td>0.248580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.08407</td>\n",
              "      <td>0.054874</td>\n",
              "      <td>0.232744</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.317984</td>\n",
              "      <td>0.078905</td>\n",
              "      <td>0.039098</td>\n",
              "      <td>0.252363</td>\n",
              "      <td>0.441084</td>\n",
              "      <td>0.428964</td>\n",
              "      <td>0.072481</td>\n",
              "      <td>0.081641</td>\n",
              "      <td>0.445432</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>0.064681</td>\n",
              "      <td>0.105559</td>\n",
              "      <td>0.208741</td>\n",
              "      <td>0.670001</td>\n",
              "      <td>0.061132</td>\n",
              "      <td>0.057705</td>\n",
              "      <td>0.101136</td>\n",
              "      <td>0.397858</td>\n",
              "      <td>0.165876</td>\n",
              "      <td>0.595242</td>\n",
              "      <td>0.197744</td>\n",
              "      <td>0.545309</td>\n",
              "      <td>0.548242</td>\n",
              "      <td>0.104354</td>\n",
              "      <td>0.038808</td>\n",
              "      <td>0.150977</td>\n",
              "      <td>0.258820</td>\n",
              "      <td>0.076482</td>\n",
              "      <td>0.254100</td>\n",
              "      <td>0.232049</td>\n",
              "      <td>0.083111</td>\n",
              "      <td>0.168700</td>\n",
              "      <td>0.407965</td>\n",
              "      <td>0.301499</td>\n",
              "      <td>0.493309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Gefitinib</td>\n",
              "      <td>3.375500</td>\n",
              "      <td>0.019699</td>\n",
              "      <td>0.831315</td>\n",
              "      <td>0.567871</td>\n",
              "      <td>0.475756</td>\n",
              "      <td>0.027848</td>\n",
              "      <td>0.384212</td>\n",
              "      <td>0.624164</td>\n",
              "      <td>0.852666</td>\n",
              "      <td>0.363793</td>\n",
              "      <td>0.191799</td>\n",
              "      <td>0.488027</td>\n",
              "      <td>0.396985</td>\n",
              "      <td>0.328996</td>\n",
              "      <td>0.446040</td>\n",
              "      <td>0.049895</td>\n",
              "      <td>0.428243</td>\n",
              "      <td>0.202829</td>\n",
              "      <td>0.231802</td>\n",
              "      <td>0.602156</td>\n",
              "      <td>0.649847</td>\n",
              "      <td>0.636162</td>\n",
              "      <td>0.128855</td>\n",
              "      <td>0.049585</td>\n",
              "      <td>0.043707</td>\n",
              "      <td>0.097299</td>\n",
              "      <td>0.248719</td>\n",
              "      <td>0.271042</td>\n",
              "      <td>0.279466</td>\n",
              "      <td>0.031348</td>\n",
              "      <td>0.820286</td>\n",
              "      <td>0.119649</td>\n",
              "      <td>0.242203</td>\n",
              "      <td>0.482941</td>\n",
              "      <td>0.437873</td>\n",
              "      <td>0.071037</td>\n",
              "      <td>0.248580</td>\n",
              "      <td>...</td>\n",
              "      <td>0.138067</td>\n",
              "      <td>0.08407</td>\n",
              "      <td>0.054874</td>\n",
              "      <td>0.232744</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.317984</td>\n",
              "      <td>0.078905</td>\n",
              "      <td>0.039098</td>\n",
              "      <td>0.252363</td>\n",
              "      <td>0.441084</td>\n",
              "      <td>0.428964</td>\n",
              "      <td>0.072481</td>\n",
              "      <td>0.081641</td>\n",
              "      <td>0.445432</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>0.064681</td>\n",
              "      <td>0.105559</td>\n",
              "      <td>0.208741</td>\n",
              "      <td>0.670001</td>\n",
              "      <td>0.061132</td>\n",
              "      <td>0.057705</td>\n",
              "      <td>0.101136</td>\n",
              "      <td>0.397858</td>\n",
              "      <td>0.165876</td>\n",
              "      <td>0.595242</td>\n",
              "      <td>0.197744</td>\n",
              "      <td>0.545309</td>\n",
              "      <td>0.548242</td>\n",
              "      <td>0.104354</td>\n",
              "      <td>0.038808</td>\n",
              "      <td>0.150977</td>\n",
              "      <td>0.258820</td>\n",
              "      <td>0.076482</td>\n",
              "      <td>0.254100</td>\n",
              "      <td>0.232049</td>\n",
              "      <td>0.083111</td>\n",
              "      <td>0.168700</td>\n",
              "      <td>0.407965</td>\n",
              "      <td>0.301499</td>\n",
              "      <td>0.493309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65371</th>\n",
              "      <td>1290906</td>\n",
              "      <td>HCC202</td>\n",
              "      <td>Cisplatin</td>\n",
              "      <td>4.475262</td>\n",
              "      <td>0.041497</td>\n",
              "      <td>0.880358</td>\n",
              "      <td>0.730852</td>\n",
              "      <td>0.461278</td>\n",
              "      <td>0.050192</td>\n",
              "      <td>0.062370</td>\n",
              "      <td>0.559155</td>\n",
              "      <td>0.456826</td>\n",
              "      <td>0.368459</td>\n",
              "      <td>0.224732</td>\n",
              "      <td>0.624502</td>\n",
              "      <td>0.202448</td>\n",
              "      <td>0.149122</td>\n",
              "      <td>0.334727</td>\n",
              "      <td>0.068340</td>\n",
              "      <td>0.487373</td>\n",
              "      <td>0.260884</td>\n",
              "      <td>0.122962</td>\n",
              "      <td>0.756259</td>\n",
              "      <td>0.514228</td>\n",
              "      <td>0.254563</td>\n",
              "      <td>0.071592</td>\n",
              "      <td>0.053819</td>\n",
              "      <td>0.062682</td>\n",
              "      <td>0.060508</td>\n",
              "      <td>0.213489</td>\n",
              "      <td>0.368660</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.051487</td>\n",
              "      <td>0.743721</td>\n",
              "      <td>0.124871</td>\n",
              "      <td>0.083921</td>\n",
              "      <td>0.784277</td>\n",
              "      <td>0.769609</td>\n",
              "      <td>0.058796</td>\n",
              "      <td>0.095589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323937</td>\n",
              "      <td>0.06000</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>0.266620</td>\n",
              "      <td>0.170533</td>\n",
              "      <td>0.344163</td>\n",
              "      <td>0.692386</td>\n",
              "      <td>0.102438</td>\n",
              "      <td>0.632741</td>\n",
              "      <td>0.682688</td>\n",
              "      <td>0.659832</td>\n",
              "      <td>0.149524</td>\n",
              "      <td>0.656898</td>\n",
              "      <td>0.493294</td>\n",
              "      <td>0.106320</td>\n",
              "      <td>0.063693</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.545246</td>\n",
              "      <td>0.107496</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.913301</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.338106</td>\n",
              "      <td>0.542378</td>\n",
              "      <td>0.165978</td>\n",
              "      <td>0.491791</td>\n",
              "      <td>0.661079</td>\n",
              "      <td>0.088773</td>\n",
              "      <td>0.041247</td>\n",
              "      <td>0.221327</td>\n",
              "      <td>0.435706</td>\n",
              "      <td>0.336945</td>\n",
              "      <td>0.665038</td>\n",
              "      <td>0.310326</td>\n",
              "      <td>0.108076</td>\n",
              "      <td>0.323573</td>\n",
              "      <td>0.660989</td>\n",
              "      <td>0.594872</td>\n",
              "      <td>0.658088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65372</th>\n",
              "      <td>1290906</td>\n",
              "      <td>HCC202</td>\n",
              "      <td>Docetaxel</td>\n",
              "      <td>-2.044859</td>\n",
              "      <td>0.041497</td>\n",
              "      <td>0.880358</td>\n",
              "      <td>0.730852</td>\n",
              "      <td>0.461278</td>\n",
              "      <td>0.050192</td>\n",
              "      <td>0.062370</td>\n",
              "      <td>0.559155</td>\n",
              "      <td>0.456826</td>\n",
              "      <td>0.368459</td>\n",
              "      <td>0.224732</td>\n",
              "      <td>0.624502</td>\n",
              "      <td>0.202448</td>\n",
              "      <td>0.149122</td>\n",
              "      <td>0.334727</td>\n",
              "      <td>0.068340</td>\n",
              "      <td>0.487373</td>\n",
              "      <td>0.260884</td>\n",
              "      <td>0.122962</td>\n",
              "      <td>0.756259</td>\n",
              "      <td>0.514228</td>\n",
              "      <td>0.254563</td>\n",
              "      <td>0.071592</td>\n",
              "      <td>0.053819</td>\n",
              "      <td>0.062682</td>\n",
              "      <td>0.060508</td>\n",
              "      <td>0.213489</td>\n",
              "      <td>0.368660</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.051487</td>\n",
              "      <td>0.743721</td>\n",
              "      <td>0.124871</td>\n",
              "      <td>0.083921</td>\n",
              "      <td>0.784277</td>\n",
              "      <td>0.769609</td>\n",
              "      <td>0.058796</td>\n",
              "      <td>0.095589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323937</td>\n",
              "      <td>0.06000</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>0.266620</td>\n",
              "      <td>0.170533</td>\n",
              "      <td>0.344163</td>\n",
              "      <td>0.692386</td>\n",
              "      <td>0.102438</td>\n",
              "      <td>0.632741</td>\n",
              "      <td>0.682688</td>\n",
              "      <td>0.659832</td>\n",
              "      <td>0.149524</td>\n",
              "      <td>0.656898</td>\n",
              "      <td>0.493294</td>\n",
              "      <td>0.106320</td>\n",
              "      <td>0.063693</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.545246</td>\n",
              "      <td>0.107496</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.913301</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.338106</td>\n",
              "      <td>0.542378</td>\n",
              "      <td>0.165978</td>\n",
              "      <td>0.491791</td>\n",
              "      <td>0.661079</td>\n",
              "      <td>0.088773</td>\n",
              "      <td>0.041247</td>\n",
              "      <td>0.221327</td>\n",
              "      <td>0.435706</td>\n",
              "      <td>0.336945</td>\n",
              "      <td>0.665038</td>\n",
              "      <td>0.310326</td>\n",
              "      <td>0.108076</td>\n",
              "      <td>0.323573</td>\n",
              "      <td>0.660989</td>\n",
              "      <td>0.594872</td>\n",
              "      <td>0.658088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65373</th>\n",
              "      <td>1290906</td>\n",
              "      <td>HCC202</td>\n",
              "      <td>Axitinib</td>\n",
              "      <td>2.675535</td>\n",
              "      <td>0.041497</td>\n",
              "      <td>0.880358</td>\n",
              "      <td>0.730852</td>\n",
              "      <td>0.461278</td>\n",
              "      <td>0.050192</td>\n",
              "      <td>0.062370</td>\n",
              "      <td>0.559155</td>\n",
              "      <td>0.456826</td>\n",
              "      <td>0.368459</td>\n",
              "      <td>0.224732</td>\n",
              "      <td>0.624502</td>\n",
              "      <td>0.202448</td>\n",
              "      <td>0.149122</td>\n",
              "      <td>0.334727</td>\n",
              "      <td>0.068340</td>\n",
              "      <td>0.487373</td>\n",
              "      <td>0.260884</td>\n",
              "      <td>0.122962</td>\n",
              "      <td>0.756259</td>\n",
              "      <td>0.514228</td>\n",
              "      <td>0.254563</td>\n",
              "      <td>0.071592</td>\n",
              "      <td>0.053819</td>\n",
              "      <td>0.062682</td>\n",
              "      <td>0.060508</td>\n",
              "      <td>0.213489</td>\n",
              "      <td>0.368660</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.051487</td>\n",
              "      <td>0.743721</td>\n",
              "      <td>0.124871</td>\n",
              "      <td>0.083921</td>\n",
              "      <td>0.784277</td>\n",
              "      <td>0.769609</td>\n",
              "      <td>0.058796</td>\n",
              "      <td>0.095589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323937</td>\n",
              "      <td>0.06000</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>0.266620</td>\n",
              "      <td>0.170533</td>\n",
              "      <td>0.344163</td>\n",
              "      <td>0.692386</td>\n",
              "      <td>0.102438</td>\n",
              "      <td>0.632741</td>\n",
              "      <td>0.682688</td>\n",
              "      <td>0.659832</td>\n",
              "      <td>0.149524</td>\n",
              "      <td>0.656898</td>\n",
              "      <td>0.493294</td>\n",
              "      <td>0.106320</td>\n",
              "      <td>0.063693</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.545246</td>\n",
              "      <td>0.107496</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.913301</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.338106</td>\n",
              "      <td>0.542378</td>\n",
              "      <td>0.165978</td>\n",
              "      <td>0.491791</td>\n",
              "      <td>0.661079</td>\n",
              "      <td>0.088773</td>\n",
              "      <td>0.041247</td>\n",
              "      <td>0.221327</td>\n",
              "      <td>0.435706</td>\n",
              "      <td>0.336945</td>\n",
              "      <td>0.665038</td>\n",
              "      <td>0.310326</td>\n",
              "      <td>0.108076</td>\n",
              "      <td>0.323573</td>\n",
              "      <td>0.660989</td>\n",
              "      <td>0.594872</td>\n",
              "      <td>0.658088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65374</th>\n",
              "      <td>1290906</td>\n",
              "      <td>HCC202</td>\n",
              "      <td>AZD7762</td>\n",
              "      <td>-0.039388</td>\n",
              "      <td>0.041497</td>\n",
              "      <td>0.880358</td>\n",
              "      <td>0.730852</td>\n",
              "      <td>0.461278</td>\n",
              "      <td>0.050192</td>\n",
              "      <td>0.062370</td>\n",
              "      <td>0.559155</td>\n",
              "      <td>0.456826</td>\n",
              "      <td>0.368459</td>\n",
              "      <td>0.224732</td>\n",
              "      <td>0.624502</td>\n",
              "      <td>0.202448</td>\n",
              "      <td>0.149122</td>\n",
              "      <td>0.334727</td>\n",
              "      <td>0.068340</td>\n",
              "      <td>0.487373</td>\n",
              "      <td>0.260884</td>\n",
              "      <td>0.122962</td>\n",
              "      <td>0.756259</td>\n",
              "      <td>0.514228</td>\n",
              "      <td>0.254563</td>\n",
              "      <td>0.071592</td>\n",
              "      <td>0.053819</td>\n",
              "      <td>0.062682</td>\n",
              "      <td>0.060508</td>\n",
              "      <td>0.213489</td>\n",
              "      <td>0.368660</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.051487</td>\n",
              "      <td>0.743721</td>\n",
              "      <td>0.124871</td>\n",
              "      <td>0.083921</td>\n",
              "      <td>0.784277</td>\n",
              "      <td>0.769609</td>\n",
              "      <td>0.058796</td>\n",
              "      <td>0.095589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323937</td>\n",
              "      <td>0.06000</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>0.266620</td>\n",
              "      <td>0.170533</td>\n",
              "      <td>0.344163</td>\n",
              "      <td>0.692386</td>\n",
              "      <td>0.102438</td>\n",
              "      <td>0.632741</td>\n",
              "      <td>0.682688</td>\n",
              "      <td>0.659832</td>\n",
              "      <td>0.149524</td>\n",
              "      <td>0.656898</td>\n",
              "      <td>0.493294</td>\n",
              "      <td>0.106320</td>\n",
              "      <td>0.063693</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.545246</td>\n",
              "      <td>0.107496</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.913301</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.338106</td>\n",
              "      <td>0.542378</td>\n",
              "      <td>0.165978</td>\n",
              "      <td>0.491791</td>\n",
              "      <td>0.661079</td>\n",
              "      <td>0.088773</td>\n",
              "      <td>0.041247</td>\n",
              "      <td>0.221327</td>\n",
              "      <td>0.435706</td>\n",
              "      <td>0.336945</td>\n",
              "      <td>0.665038</td>\n",
              "      <td>0.310326</td>\n",
              "      <td>0.108076</td>\n",
              "      <td>0.323573</td>\n",
              "      <td>0.660989</td>\n",
              "      <td>0.594872</td>\n",
              "      <td>0.658088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65375</th>\n",
              "      <td>1290906</td>\n",
              "      <td>HCC202</td>\n",
              "      <td>5-Fluorouracil</td>\n",
              "      <td>5.998151</td>\n",
              "      <td>0.041497</td>\n",
              "      <td>0.880358</td>\n",
              "      <td>0.730852</td>\n",
              "      <td>0.461278</td>\n",
              "      <td>0.050192</td>\n",
              "      <td>0.062370</td>\n",
              "      <td>0.559155</td>\n",
              "      <td>0.456826</td>\n",
              "      <td>0.368459</td>\n",
              "      <td>0.224732</td>\n",
              "      <td>0.624502</td>\n",
              "      <td>0.202448</td>\n",
              "      <td>0.149122</td>\n",
              "      <td>0.334727</td>\n",
              "      <td>0.068340</td>\n",
              "      <td>0.487373</td>\n",
              "      <td>0.260884</td>\n",
              "      <td>0.122962</td>\n",
              "      <td>0.756259</td>\n",
              "      <td>0.514228</td>\n",
              "      <td>0.254563</td>\n",
              "      <td>0.071592</td>\n",
              "      <td>0.053819</td>\n",
              "      <td>0.062682</td>\n",
              "      <td>0.060508</td>\n",
              "      <td>0.213489</td>\n",
              "      <td>0.368660</td>\n",
              "      <td>0.225440</td>\n",
              "      <td>0.051487</td>\n",
              "      <td>0.743721</td>\n",
              "      <td>0.124871</td>\n",
              "      <td>0.083921</td>\n",
              "      <td>0.784277</td>\n",
              "      <td>0.769609</td>\n",
              "      <td>0.058796</td>\n",
              "      <td>0.095589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323937</td>\n",
              "      <td>0.06000</td>\n",
              "      <td>0.048538</td>\n",
              "      <td>0.266620</td>\n",
              "      <td>0.170533</td>\n",
              "      <td>0.344163</td>\n",
              "      <td>0.692386</td>\n",
              "      <td>0.102438</td>\n",
              "      <td>0.632741</td>\n",
              "      <td>0.682688</td>\n",
              "      <td>0.659832</td>\n",
              "      <td>0.149524</td>\n",
              "      <td>0.656898</td>\n",
              "      <td>0.493294</td>\n",
              "      <td>0.106320</td>\n",
              "      <td>0.063693</td>\n",
              "      <td>0.056735</td>\n",
              "      <td>0.388101</td>\n",
              "      <td>0.545246</td>\n",
              "      <td>0.107496</td>\n",
              "      <td>0.074707</td>\n",
              "      <td>0.913301</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.338106</td>\n",
              "      <td>0.542378</td>\n",
              "      <td>0.165978</td>\n",
              "      <td>0.491791</td>\n",
              "      <td>0.661079</td>\n",
              "      <td>0.088773</td>\n",
              "      <td>0.041247</td>\n",
              "      <td>0.221327</td>\n",
              "      <td>0.435706</td>\n",
              "      <td>0.336945</td>\n",
              "      <td>0.665038</td>\n",
              "      <td>0.310326</td>\n",
              "      <td>0.108076</td>\n",
              "      <td>0.323573</td>\n",
              "      <td>0.660989</td>\n",
              "      <td>0.594872</td>\n",
              "      <td>0.658088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65376 rows × 17740 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-724aa2a7-d805-475b-8acb-a2726187bf00')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-724aa2a7-d805-475b-8acb-a2726187bf00 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-724aa2a7-d805-475b-8acb-a2726187bf00');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       COSMIC_ID CELL_LINE_NAME  ... ENSG00000266433  ENSG00000266753\n",
              "0         749709        HCC1954  ...        0.301499         0.493309\n",
              "1         749709        HCC1954  ...        0.301499         0.493309\n",
              "2         749709        HCC1954  ...        0.301499         0.493309\n",
              "3         749709        HCC1954  ...        0.301499         0.493309\n",
              "4         749709        HCC1954  ...        0.301499         0.493309\n",
              "...          ...            ...  ...             ...              ...\n",
              "65371    1290906         HCC202  ...        0.594872         0.658088\n",
              "65372    1290906         HCC202  ...        0.594872         0.658088\n",
              "65373    1290906         HCC202  ...        0.594872         0.658088\n",
              "65374    1290906         HCC202  ...        0.594872         0.658088\n",
              "65375    1290906         HCC202  ...        0.594872         0.658088\n",
              "\n",
              "[65376 rows x 17740 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR8Oe8tQ5bMe"
      },
      "source": [
        "a = topmer.iloc[:,4:]\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-uMJqWv9EGP"
      },
      "source": [
        "#subset_merged_data = topmer.iloc[:1800:,:]\n",
        "subset_merged_data.to_csv(\"Allset_merged_drugs.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = subset_merged_data.iloc[:, :4]\n",
        "df7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "URQ37FxvXT83",
        "outputId": "25a63581-448e-4ff7-f1b0-f61425d13eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8ec8bf0a-f2e7-4b38-9de7-8c55426f7b31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Cisplatin</td>\n",
              "      <td>5.005908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Cytarabine</td>\n",
              "      <td>3.947056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Docetaxel</td>\n",
              "      <td>-4.177968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Gefitinib</td>\n",
              "      <td>3.375500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>PD0325901</td>\n",
              "      <td>-0.470223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>5-Fluorouracil</td>\n",
              "      <td>5.199278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>Dasatinib</td>\n",
              "      <td>2.799078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>Paclitaxel</td>\n",
              "      <td>-3.705395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>Crizotinib</td>\n",
              "      <td>4.480879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ec8bf0a-f2e7-4b38-9de7-8c55426f7b31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ec8bf0a-f2e7-4b38-9de7-8c55426f7b31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ec8bf0a-f2e7-4b38-9de7-8c55426f7b31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      COSMIC_ID CELL_LINE_NAME       DRUG_NAME   LN_IC50\n",
              "0        749709        HCC1954    Camptothecin -0.251083\n",
              "1        749709        HCC1954       Cisplatin  5.005908\n",
              "2        749709        HCC1954      Cytarabine  3.947056\n",
              "3        749709        HCC1954       Docetaxel -4.177968\n",
              "4        749709        HCC1954       Gefitinib  3.375500\n",
              "...         ...            ...             ...       ...\n",
              "1795     906801          BT-20       PD0325901 -0.470223\n",
              "1796     906801          BT-20  5-Fluorouracil  5.199278\n",
              "1797     906801          BT-20       Dasatinib  2.799078\n",
              "1798     906801          BT-20      Paclitaxel -3.705395\n",
              "1799     906801          BT-20      Crizotinib  4.480879\n",
              "\n",
              "[1800 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLeTlKsy5nam"
      },
      "source": [
        "## **Pearson Correlation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euSq0kE65bQy"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "# define feature selection\n",
        "X= subset_merged_data.iloc[:, 4:].values\n",
        "y = subset_merged_data['LN_IC50'] \n",
        "# fs = SelectKBest(score_func=f_regression, k=500)\n",
        "# # apply feature selection\n",
        "# X_selected = pd.DataFrame(fs.fit_transform(X, y.ravel()))\n",
        "# X_selected\n",
        "\n",
        "selector = SelectKBest(score_func=f_regression, k=500)\n",
        "selector.fit(X , y)\n",
        "\n",
        "#Get columns to keep and create new dataframe with those only\n",
        "\n",
        "cols = selector.get_support(indices=True)\n",
        "features_df_new = subset_merged_data.iloc[:,cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df_new = pd.concat([df7,features_df_new],axis=1)"
      ],
      "metadata": {
        "id": "LJXNmSccXIgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df_new.to_csv(features_df_new_gdsc.csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "9g3zn6KmYAAw",
        "outputId": "eec53c5f-24f2-45ae-c987-efc3a27867b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-aeaaa1fc-f55a-4a7f-b44f-b96250274b44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "      <th>ENSG00000004142</th>\n",
              "      <th>ENSG00000005381</th>\n",
              "      <th>ENSG00000005471</th>\n",
              "      <th>ENSG00000006025</th>\n",
              "      <th>ENSG00000006377</th>\n",
              "      <th>ENSG00000010030</th>\n",
              "      <th>ENSG00000011376</th>\n",
              "      <th>ENSG00000011405</th>\n",
              "      <th>ENSG00000013297</th>\n",
              "      <th>ENSG00000013523</th>\n",
              "      <th>ENSG00000019186</th>\n",
              "      <th>ENSG00000022840</th>\n",
              "      <th>ENSG00000029534</th>\n",
              "      <th>ENSG00000030066</th>\n",
              "      <th>ENSG00000033800</th>\n",
              "      <th>ENSG00000042980</th>\n",
              "      <th>ENSG00000049167</th>\n",
              "      <th>ENSG00000053702</th>\n",
              "      <th>ENSG00000055147</th>\n",
              "      <th>ENSG00000056736</th>\n",
              "      <th>ENSG00000063177</th>\n",
              "      <th>ENSG00000064666</th>\n",
              "      <th>ENSG00000064961</th>\n",
              "      <th>ENSG00000065361</th>\n",
              "      <th>ENSG00000065371</th>\n",
              "      <th>ENSG00000066117</th>\n",
              "      <th>ENSG00000066279</th>\n",
              "      <th>ENSG00000067365</th>\n",
              "      <th>ENSG00000068796</th>\n",
              "      <th>ENSG00000068912</th>\n",
              "      <th>ENSG00000068976</th>\n",
              "      <th>ENSG00000070081</th>\n",
              "      <th>ENSG00000070371</th>\n",
              "      <th>ENSG00000070778</th>\n",
              "      <th>ENSG00000073578</th>\n",
              "      <th>ENSG00000073861</th>\n",
              "      <th>...</th>\n",
              "      <th>ENSG00000204209</th>\n",
              "      <th>ENSG00000204385</th>\n",
              "      <th>ENSG00000204420</th>\n",
              "      <th>ENSG00000204475</th>\n",
              "      <th>ENSG00000204511</th>\n",
              "      <th>ENSG00000205356</th>\n",
              "      <th>ENSG00000205363</th>\n",
              "      <th>ENSG00000205436</th>\n",
              "      <th>ENSG00000206474</th>\n",
              "      <th>ENSG00000206535</th>\n",
              "      <th>ENSG00000206560</th>\n",
              "      <th>ENSG00000206561</th>\n",
              "      <th>ENSG00000212719</th>\n",
              "      <th>ENSG00000212864</th>\n",
              "      <th>ENSG00000212938</th>\n",
              "      <th>ENSG00000213139</th>\n",
              "      <th>ENSG00000213606</th>\n",
              "      <th>ENSG00000213719</th>\n",
              "      <th>ENSG00000213722</th>\n",
              "      <th>ENSG00000213901</th>\n",
              "      <th>ENSG00000213923</th>\n",
              "      <th>ENSG00000214941</th>\n",
              "      <th>ENSG00000215424</th>\n",
              "      <th>ENSG00000223547</th>\n",
              "      <th>ENSG00000223611</th>\n",
              "      <th>ENSG00000225683</th>\n",
              "      <th>ENSG00000227392</th>\n",
              "      <th>ENSG00000229048</th>\n",
              "      <th>ENSG00000229807</th>\n",
              "      <th>ENSG00000230666</th>\n",
              "      <th>ENSG00000231782</th>\n",
              "      <th>ENSG00000232818</th>\n",
              "      <th>ENSG00000236311</th>\n",
              "      <th>ENSG00000238227</th>\n",
              "      <th>ENSG00000250896</th>\n",
              "      <th>ENSG00000256049</th>\n",
              "      <th>ENSG00000256235</th>\n",
              "      <th>ENSG00000256574</th>\n",
              "      <th>ENSG00000260495</th>\n",
              "      <th>ENSG00000261253</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.43274</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>0.067721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662582</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.103467</td>\n",
              "      <td>0.097839</td>\n",
              "      <td>0.568894</td>\n",
              "      <td>0.223390</td>\n",
              "      <td>0.292548</td>\n",
              "      <td>0.257969</td>\n",
              "      <td>0.124111</td>\n",
              "      <td>0.227795</td>\n",
              "      <td>0.338594</td>\n",
              "      <td>0.109063</td>\n",
              "      <td>0.111718</td>\n",
              "      <td>0.218616</td>\n",
              "      <td>0.690613</td>\n",
              "      <td>0.213996</td>\n",
              "      <td>0.747667</td>\n",
              "      <td>0.828934</td>\n",
              "      <td>0.466306</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.319073</td>\n",
              "      <td>0.189691</td>\n",
              "      <td>0.447551</td>\n",
              "      <td>0.310012</td>\n",
              "      <td>0.505841</td>\n",
              "      <td>0.251947</td>\n",
              "      <td>0.334275</td>\n",
              "      <td>0.227658</td>\n",
              "      <td>0.041494</td>\n",
              "      <td>0.277148</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.123355</td>\n",
              "      <td>0.193090</td>\n",
              "      <td>0.609574</td>\n",
              "      <td>0.263522</td>\n",
              "      <td>0.242677</td>\n",
              "      <td>0.153469</td>\n",
              "      <td>0.054529</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.441084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Cisplatin</td>\n",
              "      <td>5.005908</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.43274</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>0.067721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662582</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.103467</td>\n",
              "      <td>0.097839</td>\n",
              "      <td>0.568894</td>\n",
              "      <td>0.223390</td>\n",
              "      <td>0.292548</td>\n",
              "      <td>0.257969</td>\n",
              "      <td>0.124111</td>\n",
              "      <td>0.227795</td>\n",
              "      <td>0.338594</td>\n",
              "      <td>0.109063</td>\n",
              "      <td>0.111718</td>\n",
              "      <td>0.218616</td>\n",
              "      <td>0.690613</td>\n",
              "      <td>0.213996</td>\n",
              "      <td>0.747667</td>\n",
              "      <td>0.828934</td>\n",
              "      <td>0.466306</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.319073</td>\n",
              "      <td>0.189691</td>\n",
              "      <td>0.447551</td>\n",
              "      <td>0.310012</td>\n",
              "      <td>0.505841</td>\n",
              "      <td>0.251947</td>\n",
              "      <td>0.334275</td>\n",
              "      <td>0.227658</td>\n",
              "      <td>0.041494</td>\n",
              "      <td>0.277148</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.123355</td>\n",
              "      <td>0.193090</td>\n",
              "      <td>0.609574</td>\n",
              "      <td>0.263522</td>\n",
              "      <td>0.242677</td>\n",
              "      <td>0.153469</td>\n",
              "      <td>0.054529</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.441084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Cytarabine</td>\n",
              "      <td>3.947056</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.43274</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>0.067721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662582</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.103467</td>\n",
              "      <td>0.097839</td>\n",
              "      <td>0.568894</td>\n",
              "      <td>0.223390</td>\n",
              "      <td>0.292548</td>\n",
              "      <td>0.257969</td>\n",
              "      <td>0.124111</td>\n",
              "      <td>0.227795</td>\n",
              "      <td>0.338594</td>\n",
              "      <td>0.109063</td>\n",
              "      <td>0.111718</td>\n",
              "      <td>0.218616</td>\n",
              "      <td>0.690613</td>\n",
              "      <td>0.213996</td>\n",
              "      <td>0.747667</td>\n",
              "      <td>0.828934</td>\n",
              "      <td>0.466306</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.319073</td>\n",
              "      <td>0.189691</td>\n",
              "      <td>0.447551</td>\n",
              "      <td>0.310012</td>\n",
              "      <td>0.505841</td>\n",
              "      <td>0.251947</td>\n",
              "      <td>0.334275</td>\n",
              "      <td>0.227658</td>\n",
              "      <td>0.041494</td>\n",
              "      <td>0.277148</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.123355</td>\n",
              "      <td>0.193090</td>\n",
              "      <td>0.609574</td>\n",
              "      <td>0.263522</td>\n",
              "      <td>0.242677</td>\n",
              "      <td>0.153469</td>\n",
              "      <td>0.054529</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.441084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Docetaxel</td>\n",
              "      <td>-4.177968</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.43274</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>0.067721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662582</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.103467</td>\n",
              "      <td>0.097839</td>\n",
              "      <td>0.568894</td>\n",
              "      <td>0.223390</td>\n",
              "      <td>0.292548</td>\n",
              "      <td>0.257969</td>\n",
              "      <td>0.124111</td>\n",
              "      <td>0.227795</td>\n",
              "      <td>0.338594</td>\n",
              "      <td>0.109063</td>\n",
              "      <td>0.111718</td>\n",
              "      <td>0.218616</td>\n",
              "      <td>0.690613</td>\n",
              "      <td>0.213996</td>\n",
              "      <td>0.747667</td>\n",
              "      <td>0.828934</td>\n",
              "      <td>0.466306</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.319073</td>\n",
              "      <td>0.189691</td>\n",
              "      <td>0.447551</td>\n",
              "      <td>0.310012</td>\n",
              "      <td>0.505841</td>\n",
              "      <td>0.251947</td>\n",
              "      <td>0.334275</td>\n",
              "      <td>0.227658</td>\n",
              "      <td>0.041494</td>\n",
              "      <td>0.277148</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.123355</td>\n",
              "      <td>0.193090</td>\n",
              "      <td>0.609574</td>\n",
              "      <td>0.263522</td>\n",
              "      <td>0.242677</td>\n",
              "      <td>0.153469</td>\n",
              "      <td>0.054529</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.441084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Gefitinib</td>\n",
              "      <td>3.375500</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.43274</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>0.067721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.662582</td>\n",
              "      <td>0.050810</td>\n",
              "      <td>0.103467</td>\n",
              "      <td>0.097839</td>\n",
              "      <td>0.568894</td>\n",
              "      <td>0.223390</td>\n",
              "      <td>0.292548</td>\n",
              "      <td>0.257969</td>\n",
              "      <td>0.124111</td>\n",
              "      <td>0.227795</td>\n",
              "      <td>0.338594</td>\n",
              "      <td>0.109063</td>\n",
              "      <td>0.111718</td>\n",
              "      <td>0.218616</td>\n",
              "      <td>0.690613</td>\n",
              "      <td>0.213996</td>\n",
              "      <td>0.747667</td>\n",
              "      <td>0.828934</td>\n",
              "      <td>0.466306</td>\n",
              "      <td>0.098664</td>\n",
              "      <td>0.319073</td>\n",
              "      <td>0.189691</td>\n",
              "      <td>0.447551</td>\n",
              "      <td>0.310012</td>\n",
              "      <td>0.505841</td>\n",
              "      <td>0.251947</td>\n",
              "      <td>0.334275</td>\n",
              "      <td>0.227658</td>\n",
              "      <td>0.041494</td>\n",
              "      <td>0.277148</td>\n",
              "      <td>0.354678</td>\n",
              "      <td>0.123355</td>\n",
              "      <td>0.193090</td>\n",
              "      <td>0.609574</td>\n",
              "      <td>0.263522</td>\n",
              "      <td>0.242677</td>\n",
              "      <td>0.153469</td>\n",
              "      <td>0.054529</td>\n",
              "      <td>0.166561</td>\n",
              "      <td>0.441084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1795</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>PD0325901</td>\n",
              "      <td>-0.470223</td>\n",
              "      <td>0.397875</td>\n",
              "      <td>0.013915</td>\n",
              "      <td>0.050466</td>\n",
              "      <td>0.493019</td>\n",
              "      <td>0.046419</td>\n",
              "      <td>0.062844</td>\n",
              "      <td>0.378964</td>\n",
              "      <td>0.692236</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.173730</td>\n",
              "      <td>0.032470</td>\n",
              "      <td>0.567040</td>\n",
              "      <td>0.012926</td>\n",
              "      <td>0.21258</td>\n",
              "      <td>0.594424</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>0.196155</td>\n",
              "      <td>0.374442</td>\n",
              "      <td>0.378674</td>\n",
              "      <td>0.357132</td>\n",
              "      <td>0.397257</td>\n",
              "      <td>0.644091</td>\n",
              "      <td>0.529124</td>\n",
              "      <td>0.254181</td>\n",
              "      <td>0.125075</td>\n",
              "      <td>0.280669</td>\n",
              "      <td>0.781699</td>\n",
              "      <td>0.370860</td>\n",
              "      <td>0.206417</td>\n",
              "      <td>0.644126</td>\n",
              "      <td>0.102011</td>\n",
              "      <td>0.545783</td>\n",
              "      <td>0.025132</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>0.727856</td>\n",
              "      <td>0.034383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.679629</td>\n",
              "      <td>0.060601</td>\n",
              "      <td>0.057282</td>\n",
              "      <td>0.075115</td>\n",
              "      <td>0.505099</td>\n",
              "      <td>0.390989</td>\n",
              "      <td>0.138086</td>\n",
              "      <td>0.236278</td>\n",
              "      <td>0.239858</td>\n",
              "      <td>0.481617</td>\n",
              "      <td>0.381721</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>0.233433</td>\n",
              "      <td>0.342548</td>\n",
              "      <td>0.461299</td>\n",
              "      <td>0.153224</td>\n",
              "      <td>0.856842</td>\n",
              "      <td>0.890650</td>\n",
              "      <td>0.691409</td>\n",
              "      <td>0.079076</td>\n",
              "      <td>0.450541</td>\n",
              "      <td>0.355889</td>\n",
              "      <td>0.351024</td>\n",
              "      <td>0.329734</td>\n",
              "      <td>0.355194</td>\n",
              "      <td>0.308457</td>\n",
              "      <td>0.372952</td>\n",
              "      <td>0.343370</td>\n",
              "      <td>0.025339</td>\n",
              "      <td>0.309042</td>\n",
              "      <td>0.225833</td>\n",
              "      <td>0.076005</td>\n",
              "      <td>0.154339</td>\n",
              "      <td>0.677788</td>\n",
              "      <td>0.376908</td>\n",
              "      <td>0.203004</td>\n",
              "      <td>0.158899</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>0.363343</td>\n",
              "      <td>0.302894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>5-Fluorouracil</td>\n",
              "      <td>5.199278</td>\n",
              "      <td>0.397875</td>\n",
              "      <td>0.013915</td>\n",
              "      <td>0.050466</td>\n",
              "      <td>0.493019</td>\n",
              "      <td>0.046419</td>\n",
              "      <td>0.062844</td>\n",
              "      <td>0.378964</td>\n",
              "      <td>0.692236</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.173730</td>\n",
              "      <td>0.032470</td>\n",
              "      <td>0.567040</td>\n",
              "      <td>0.012926</td>\n",
              "      <td>0.21258</td>\n",
              "      <td>0.594424</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>0.196155</td>\n",
              "      <td>0.374442</td>\n",
              "      <td>0.378674</td>\n",
              "      <td>0.357132</td>\n",
              "      <td>0.397257</td>\n",
              "      <td>0.644091</td>\n",
              "      <td>0.529124</td>\n",
              "      <td>0.254181</td>\n",
              "      <td>0.125075</td>\n",
              "      <td>0.280669</td>\n",
              "      <td>0.781699</td>\n",
              "      <td>0.370860</td>\n",
              "      <td>0.206417</td>\n",
              "      <td>0.644126</td>\n",
              "      <td>0.102011</td>\n",
              "      <td>0.545783</td>\n",
              "      <td>0.025132</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>0.727856</td>\n",
              "      <td>0.034383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.679629</td>\n",
              "      <td>0.060601</td>\n",
              "      <td>0.057282</td>\n",
              "      <td>0.075115</td>\n",
              "      <td>0.505099</td>\n",
              "      <td>0.390989</td>\n",
              "      <td>0.138086</td>\n",
              "      <td>0.236278</td>\n",
              "      <td>0.239858</td>\n",
              "      <td>0.481617</td>\n",
              "      <td>0.381721</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>0.233433</td>\n",
              "      <td>0.342548</td>\n",
              "      <td>0.461299</td>\n",
              "      <td>0.153224</td>\n",
              "      <td>0.856842</td>\n",
              "      <td>0.890650</td>\n",
              "      <td>0.691409</td>\n",
              "      <td>0.079076</td>\n",
              "      <td>0.450541</td>\n",
              "      <td>0.355889</td>\n",
              "      <td>0.351024</td>\n",
              "      <td>0.329734</td>\n",
              "      <td>0.355194</td>\n",
              "      <td>0.308457</td>\n",
              "      <td>0.372952</td>\n",
              "      <td>0.343370</td>\n",
              "      <td>0.025339</td>\n",
              "      <td>0.309042</td>\n",
              "      <td>0.225833</td>\n",
              "      <td>0.076005</td>\n",
              "      <td>0.154339</td>\n",
              "      <td>0.677788</td>\n",
              "      <td>0.376908</td>\n",
              "      <td>0.203004</td>\n",
              "      <td>0.158899</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>0.363343</td>\n",
              "      <td>0.302894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>Dasatinib</td>\n",
              "      <td>2.799078</td>\n",
              "      <td>0.397875</td>\n",
              "      <td>0.013915</td>\n",
              "      <td>0.050466</td>\n",
              "      <td>0.493019</td>\n",
              "      <td>0.046419</td>\n",
              "      <td>0.062844</td>\n",
              "      <td>0.378964</td>\n",
              "      <td>0.692236</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.173730</td>\n",
              "      <td>0.032470</td>\n",
              "      <td>0.567040</td>\n",
              "      <td>0.012926</td>\n",
              "      <td>0.21258</td>\n",
              "      <td>0.594424</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>0.196155</td>\n",
              "      <td>0.374442</td>\n",
              "      <td>0.378674</td>\n",
              "      <td>0.357132</td>\n",
              "      <td>0.397257</td>\n",
              "      <td>0.644091</td>\n",
              "      <td>0.529124</td>\n",
              "      <td>0.254181</td>\n",
              "      <td>0.125075</td>\n",
              "      <td>0.280669</td>\n",
              "      <td>0.781699</td>\n",
              "      <td>0.370860</td>\n",
              "      <td>0.206417</td>\n",
              "      <td>0.644126</td>\n",
              "      <td>0.102011</td>\n",
              "      <td>0.545783</td>\n",
              "      <td>0.025132</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>0.727856</td>\n",
              "      <td>0.034383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.679629</td>\n",
              "      <td>0.060601</td>\n",
              "      <td>0.057282</td>\n",
              "      <td>0.075115</td>\n",
              "      <td>0.505099</td>\n",
              "      <td>0.390989</td>\n",
              "      <td>0.138086</td>\n",
              "      <td>0.236278</td>\n",
              "      <td>0.239858</td>\n",
              "      <td>0.481617</td>\n",
              "      <td>0.381721</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>0.233433</td>\n",
              "      <td>0.342548</td>\n",
              "      <td>0.461299</td>\n",
              "      <td>0.153224</td>\n",
              "      <td>0.856842</td>\n",
              "      <td>0.890650</td>\n",
              "      <td>0.691409</td>\n",
              "      <td>0.079076</td>\n",
              "      <td>0.450541</td>\n",
              "      <td>0.355889</td>\n",
              "      <td>0.351024</td>\n",
              "      <td>0.329734</td>\n",
              "      <td>0.355194</td>\n",
              "      <td>0.308457</td>\n",
              "      <td>0.372952</td>\n",
              "      <td>0.343370</td>\n",
              "      <td>0.025339</td>\n",
              "      <td>0.309042</td>\n",
              "      <td>0.225833</td>\n",
              "      <td>0.076005</td>\n",
              "      <td>0.154339</td>\n",
              "      <td>0.677788</td>\n",
              "      <td>0.376908</td>\n",
              "      <td>0.203004</td>\n",
              "      <td>0.158899</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>0.363343</td>\n",
              "      <td>0.302894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1798</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>Paclitaxel</td>\n",
              "      <td>-3.705395</td>\n",
              "      <td>0.397875</td>\n",
              "      <td>0.013915</td>\n",
              "      <td>0.050466</td>\n",
              "      <td>0.493019</td>\n",
              "      <td>0.046419</td>\n",
              "      <td>0.062844</td>\n",
              "      <td>0.378964</td>\n",
              "      <td>0.692236</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.173730</td>\n",
              "      <td>0.032470</td>\n",
              "      <td>0.567040</td>\n",
              "      <td>0.012926</td>\n",
              "      <td>0.21258</td>\n",
              "      <td>0.594424</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>0.196155</td>\n",
              "      <td>0.374442</td>\n",
              "      <td>0.378674</td>\n",
              "      <td>0.357132</td>\n",
              "      <td>0.397257</td>\n",
              "      <td>0.644091</td>\n",
              "      <td>0.529124</td>\n",
              "      <td>0.254181</td>\n",
              "      <td>0.125075</td>\n",
              "      <td>0.280669</td>\n",
              "      <td>0.781699</td>\n",
              "      <td>0.370860</td>\n",
              "      <td>0.206417</td>\n",
              "      <td>0.644126</td>\n",
              "      <td>0.102011</td>\n",
              "      <td>0.545783</td>\n",
              "      <td>0.025132</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>0.727856</td>\n",
              "      <td>0.034383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.679629</td>\n",
              "      <td>0.060601</td>\n",
              "      <td>0.057282</td>\n",
              "      <td>0.075115</td>\n",
              "      <td>0.505099</td>\n",
              "      <td>0.390989</td>\n",
              "      <td>0.138086</td>\n",
              "      <td>0.236278</td>\n",
              "      <td>0.239858</td>\n",
              "      <td>0.481617</td>\n",
              "      <td>0.381721</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>0.233433</td>\n",
              "      <td>0.342548</td>\n",
              "      <td>0.461299</td>\n",
              "      <td>0.153224</td>\n",
              "      <td>0.856842</td>\n",
              "      <td>0.890650</td>\n",
              "      <td>0.691409</td>\n",
              "      <td>0.079076</td>\n",
              "      <td>0.450541</td>\n",
              "      <td>0.355889</td>\n",
              "      <td>0.351024</td>\n",
              "      <td>0.329734</td>\n",
              "      <td>0.355194</td>\n",
              "      <td>0.308457</td>\n",
              "      <td>0.372952</td>\n",
              "      <td>0.343370</td>\n",
              "      <td>0.025339</td>\n",
              "      <td>0.309042</td>\n",
              "      <td>0.225833</td>\n",
              "      <td>0.076005</td>\n",
              "      <td>0.154339</td>\n",
              "      <td>0.677788</td>\n",
              "      <td>0.376908</td>\n",
              "      <td>0.203004</td>\n",
              "      <td>0.158899</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>0.363343</td>\n",
              "      <td>0.302894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1799</th>\n",
              "      <td>906801</td>\n",
              "      <td>BT-20</td>\n",
              "      <td>Crizotinib</td>\n",
              "      <td>4.480879</td>\n",
              "      <td>0.397875</td>\n",
              "      <td>0.013915</td>\n",
              "      <td>0.050466</td>\n",
              "      <td>0.493019</td>\n",
              "      <td>0.046419</td>\n",
              "      <td>0.062844</td>\n",
              "      <td>0.378964</td>\n",
              "      <td>0.692236</td>\n",
              "      <td>0.025285</td>\n",
              "      <td>0.173730</td>\n",
              "      <td>0.032470</td>\n",
              "      <td>0.567040</td>\n",
              "      <td>0.012926</td>\n",
              "      <td>0.21258</td>\n",
              "      <td>0.594424</td>\n",
              "      <td>0.044969</td>\n",
              "      <td>0.196155</td>\n",
              "      <td>0.374442</td>\n",
              "      <td>0.378674</td>\n",
              "      <td>0.357132</td>\n",
              "      <td>0.397257</td>\n",
              "      <td>0.644091</td>\n",
              "      <td>0.529124</td>\n",
              "      <td>0.254181</td>\n",
              "      <td>0.125075</td>\n",
              "      <td>0.280669</td>\n",
              "      <td>0.781699</td>\n",
              "      <td>0.370860</td>\n",
              "      <td>0.206417</td>\n",
              "      <td>0.644126</td>\n",
              "      <td>0.102011</td>\n",
              "      <td>0.545783</td>\n",
              "      <td>0.025132</td>\n",
              "      <td>0.147982</td>\n",
              "      <td>0.727856</td>\n",
              "      <td>0.034383</td>\n",
              "      <td>...</td>\n",
              "      <td>0.679629</td>\n",
              "      <td>0.060601</td>\n",
              "      <td>0.057282</td>\n",
              "      <td>0.075115</td>\n",
              "      <td>0.505099</td>\n",
              "      <td>0.390989</td>\n",
              "      <td>0.138086</td>\n",
              "      <td>0.236278</td>\n",
              "      <td>0.239858</td>\n",
              "      <td>0.481617</td>\n",
              "      <td>0.381721</td>\n",
              "      <td>0.104780</td>\n",
              "      <td>0.233433</td>\n",
              "      <td>0.342548</td>\n",
              "      <td>0.461299</td>\n",
              "      <td>0.153224</td>\n",
              "      <td>0.856842</td>\n",
              "      <td>0.890650</td>\n",
              "      <td>0.691409</td>\n",
              "      <td>0.079076</td>\n",
              "      <td>0.450541</td>\n",
              "      <td>0.355889</td>\n",
              "      <td>0.351024</td>\n",
              "      <td>0.329734</td>\n",
              "      <td>0.355194</td>\n",
              "      <td>0.308457</td>\n",
              "      <td>0.372952</td>\n",
              "      <td>0.343370</td>\n",
              "      <td>0.025339</td>\n",
              "      <td>0.309042</td>\n",
              "      <td>0.225833</td>\n",
              "      <td>0.076005</td>\n",
              "      <td>0.154339</td>\n",
              "      <td>0.677788</td>\n",
              "      <td>0.376908</td>\n",
              "      <td>0.203004</td>\n",
              "      <td>0.158899</td>\n",
              "      <td>0.026193</td>\n",
              "      <td>0.363343</td>\n",
              "      <td>0.302894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1800 rows × 504 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeaaa1fc-f55a-4a7f-b44f-b96250274b44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aeaaa1fc-f55a-4a7f-b44f-b96250274b44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aeaaa1fc-f55a-4a7f-b44f-b96250274b44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      COSMIC_ID CELL_LINE_NAME  ... ENSG00000260495  ENSG00000261253\n",
              "0        749709        HCC1954  ...        0.166561         0.441084\n",
              "1        749709        HCC1954  ...        0.166561         0.441084\n",
              "2        749709        HCC1954  ...        0.166561         0.441084\n",
              "3        749709        HCC1954  ...        0.166561         0.441084\n",
              "4        749709        HCC1954  ...        0.166561         0.441084\n",
              "...         ...            ...  ...             ...              ...\n",
              "1795     906801          BT-20  ...        0.363343         0.302894\n",
              "1796     906801          BT-20  ...        0.363343         0.302894\n",
              "1797     906801          BT-20  ...        0.363343         0.302894\n",
              "1798     906801          BT-20  ...        0.363343         0.302894\n",
              "1799     906801          BT-20  ...        0.363343         0.302894\n",
              "\n",
              "[1800 rows x 504 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_df_new.to_csv(\"/content/drive/MyDrive/Thesis2_Dec2021/features_df_new_gdsc.csv\")"
      ],
      "metadata": {
        "id": "s3F7uEaXYdnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drug_sdf1 = pd.read_csv('/content/drive/MyDrive/Thesis2_Dec2021/drug_data_sdf_100.csv')\n",
        "drug_sdf1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "KUJcx-DNYuHv",
        "outputId": "c82a56ec-6b45-4d3f-f870-785ad12a8f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-176b20be-72e3-4d8d-8ced-d12b663511a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Carmustine</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P22077</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KU-55933</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Afatinib</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doramapimod</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>GSK2578215A.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Telomerase Inhibitor IX</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>MIRA-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NVP-ADW742</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>AZD7762</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 257 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-176b20be-72e3-4d8d-8ced-d12b663511a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-176b20be-72e3-4d8d-8ced-d12b663511a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-176b20be-72e3-4d8d-8ced-d12b663511a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  DRUG_NAME  0  1  2  3  4  ...  250  251  252  253  254  255\n",
              "0                Carmustine  1  0  0  0  1  ...    0    0    0    0    0    0\n",
              "1                    P22077  0  1  0  0  0  ...    0    0    0    0    0    0\n",
              "2                  KU-55933  0  1  0  0  0  ...    0    0    1    0    0    0\n",
              "3                  Afatinib  0  1  0  0  0  ...    0    1    0    0    0    0\n",
              "4               Doramapimod  0  0  0  1  0  ...    0    0    0    0    0    1\n",
              "..                      ... .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...\n",
              "95            GSK2578215A.1  0  0  0  1  1  ...    1    0    0    0    0    1\n",
              "96  Telomerase Inhibitor IX  0  0  0  0  0  ...    0    0    0    0    0    0\n",
              "97                   MIRA-1  0  0  0  0  0  ...    0    0    0    0    0    0\n",
              "98               NVP-ADW742  0  0  0  0  1  ...    1    1    0    0    0    1\n",
              "99                  AZD7762  0  0  0  0  1  ...    0    1    1    0    0    0\n",
              "\n",
              "[100 rows x 257 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_data_sdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "k32r-qZbdVN3",
        "outputId": "d9a74563-0296-4dde-8f0d-442b8863d965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b7ded6fa-6204-4c9c-820c-919fc81edcdf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Carmustine</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>P22077</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KU-55933</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Afatinib</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Doramapimod</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GSK2578215A.1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Telomerase Inhibitor IX</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIRA-1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NVP-ADW742</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AZD7762</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 256 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7ded6fa-6204-4c9c-820c-919fc81edcdf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7ded6fa-6204-4c9c-820c-919fc81edcdf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7ded6fa-6204-4c9c-820c-919fc81edcdf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                         0    1    2    3    4    ...  251  252  253  254  255\n",
              "Carmustine                 1    0    0    0    1  ...    0    0    0    0    0\n",
              "P22077                     0    1    0    0    0  ...    0    0    0    0    0\n",
              "KU-55933                   0    1    0    0    0  ...    0    1    0    0    0\n",
              "Afatinib                   0    1    0    0    0  ...    1    0    0    0    0\n",
              "Doramapimod                0    0    0    1    0  ...    0    0    0    0    1\n",
              "...                      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "GSK2578215A.1              0    0    0    1    1  ...    0    0    0    0    1\n",
              "Telomerase Inhibitor IX    0    0    0    0    0  ...    0    0    0    0    0\n",
              "MIRA-1                     0    0    0    0    0  ...    0    0    0    0    0\n",
              "NVP-ADW742                 0    0    0    0    1  ...    1    0    0    0    1\n",
              "AZD7762                    0    0    0    0    1  ...    1    1    0    0    0\n",
              "\n",
              "[100 rows x 256 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auw5G_xo9I6q"
      },
      "source": [
        "#drug_merged=pd.merge(features_df_new, drug_sdf1, on=\"DRUG_NAME\")\n",
        "drug_merged.to_csv(\"/content/drive/MyDrive/Thesis2_Dec2021/drugmerged_final.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Thesis2_Dec2021/drugmerged_final.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "Gi6kZRd-eDi6",
        "outputId": "025ce8fb-01f8-4daf-e5c7-d7d2eac6d9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1da92c07-d220-4139-b9fb-62e2d7dba553\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "      <th>ENSG00000004142</th>\n",
              "      <th>ENSG00000005381</th>\n",
              "      <th>ENSG00000005471</th>\n",
              "      <th>ENSG00000006025</th>\n",
              "      <th>ENSG00000006377</th>\n",
              "      <th>ENSG00000010030</th>\n",
              "      <th>ENSG00000011376</th>\n",
              "      <th>ENSG00000011405</th>\n",
              "      <th>ENSG00000013297</th>\n",
              "      <th>ENSG00000013523</th>\n",
              "      <th>ENSG00000019186</th>\n",
              "      <th>ENSG00000022840</th>\n",
              "      <th>ENSG00000029534</th>\n",
              "      <th>ENSG00000030066</th>\n",
              "      <th>ENSG00000033800</th>\n",
              "      <th>ENSG00000042980</th>\n",
              "      <th>ENSG00000049167</th>\n",
              "      <th>ENSG00000053702</th>\n",
              "      <th>ENSG00000055147</th>\n",
              "      <th>ENSG00000056736</th>\n",
              "      <th>ENSG00000063177</th>\n",
              "      <th>ENSG00000064666</th>\n",
              "      <th>ENSG00000064961</th>\n",
              "      <th>ENSG00000065361</th>\n",
              "      <th>ENSG00000065371</th>\n",
              "      <th>ENSG00000066117</th>\n",
              "      <th>ENSG00000066279</th>\n",
              "      <th>ENSG00000067365</th>\n",
              "      <th>ENSG00000068796</th>\n",
              "      <th>ENSG00000068912</th>\n",
              "      <th>ENSG00000068976</th>\n",
              "      <th>ENSG00000070081</th>\n",
              "      <th>ENSG00000070371</th>\n",
              "      <th>ENSG00000070778</th>\n",
              "      <th>ENSG00000073578</th>\n",
              "      <th>...</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.432740</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>749710</td>\n",
              "      <td>HCC1143</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.343315</td>\n",
              "      <td>0.311230</td>\n",
              "      <td>0.025165</td>\n",
              "      <td>0.031411</td>\n",
              "      <td>0.458095</td>\n",
              "      <td>0.191393</td>\n",
              "      <td>0.372622</td>\n",
              "      <td>0.454148</td>\n",
              "      <td>0.711950</td>\n",
              "      <td>0.727950</td>\n",
              "      <td>0.269799</td>\n",
              "      <td>0.071288</td>\n",
              "      <td>0.371427</td>\n",
              "      <td>0.290302</td>\n",
              "      <td>0.577338</td>\n",
              "      <td>0.449637</td>\n",
              "      <td>0.064719</td>\n",
              "      <td>0.252867</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>0.347377</td>\n",
              "      <td>0.183097</td>\n",
              "      <td>0.646863</td>\n",
              "      <td>0.554294</td>\n",
              "      <td>0.454478</td>\n",
              "      <td>0.293674</td>\n",
              "      <td>0.124696</td>\n",
              "      <td>0.225172</td>\n",
              "      <td>0.819032</td>\n",
              "      <td>0.236604</td>\n",
              "      <td>0.445945</td>\n",
              "      <td>0.466896</td>\n",
              "      <td>0.094528</td>\n",
              "      <td>0.617589</td>\n",
              "      <td>0.070329</td>\n",
              "      <td>0.116111</td>\n",
              "      <td>0.877219</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>749711</td>\n",
              "      <td>HCC1187</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.736985</td>\n",
              "      <td>0.238954</td>\n",
              "      <td>0.051395</td>\n",
              "      <td>0.067070</td>\n",
              "      <td>0.456622</td>\n",
              "      <td>0.043694</td>\n",
              "      <td>0.919986</td>\n",
              "      <td>0.345631</td>\n",
              "      <td>0.640566</td>\n",
              "      <td>0.151405</td>\n",
              "      <td>0.244364</td>\n",
              "      <td>0.037784</td>\n",
              "      <td>0.407550</td>\n",
              "      <td>0.045708</td>\n",
              "      <td>0.638971</td>\n",
              "      <td>0.342508</td>\n",
              "      <td>0.061305</td>\n",
              "      <td>0.535583</td>\n",
              "      <td>0.377523</td>\n",
              "      <td>0.422462</td>\n",
              "      <td>0.523686</td>\n",
              "      <td>0.559227</td>\n",
              "      <td>0.094328</td>\n",
              "      <td>0.402929</td>\n",
              "      <td>0.400033</td>\n",
              "      <td>0.096194</td>\n",
              "      <td>0.303966</td>\n",
              "      <td>0.835617</td>\n",
              "      <td>0.322354</td>\n",
              "      <td>0.412906</td>\n",
              "      <td>0.171166</td>\n",
              "      <td>0.066090</td>\n",
              "      <td>0.485675</td>\n",
              "      <td>0.152859</td>\n",
              "      <td>0.155562</td>\n",
              "      <td>0.639032</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>749712</td>\n",
              "      <td>HCC1395</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-2.309078</td>\n",
              "      <td>0.324720</td>\n",
              "      <td>0.042300</td>\n",
              "      <td>0.067512</td>\n",
              "      <td>0.313101</td>\n",
              "      <td>0.397069</td>\n",
              "      <td>0.098445</td>\n",
              "      <td>0.552249</td>\n",
              "      <td>0.209121</td>\n",
              "      <td>0.075942</td>\n",
              "      <td>0.305536</td>\n",
              "      <td>0.041849</td>\n",
              "      <td>0.177567</td>\n",
              "      <td>0.113092</td>\n",
              "      <td>0.343055</td>\n",
              "      <td>0.491634</td>\n",
              "      <td>0.079983</td>\n",
              "      <td>0.301461</td>\n",
              "      <td>0.405244</td>\n",
              "      <td>0.518617</td>\n",
              "      <td>0.163528</td>\n",
              "      <td>0.402730</td>\n",
              "      <td>0.404349</td>\n",
              "      <td>0.520293</td>\n",
              "      <td>0.030230</td>\n",
              "      <td>0.639274</td>\n",
              "      <td>0.572510</td>\n",
              "      <td>0.855242</td>\n",
              "      <td>0.514551</td>\n",
              "      <td>0.364675</td>\n",
              "      <td>0.416497</td>\n",
              "      <td>0.142641</td>\n",
              "      <td>0.563301</td>\n",
              "      <td>0.098760</td>\n",
              "      <td>0.236006</td>\n",
              "      <td>0.625014</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>749713</td>\n",
              "      <td>HCC1599</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-3.106684</td>\n",
              "      <td>0.276038</td>\n",
              "      <td>0.017270</td>\n",
              "      <td>0.067748</td>\n",
              "      <td>0.218027</td>\n",
              "      <td>0.517101</td>\n",
              "      <td>0.085292</td>\n",
              "      <td>0.278903</td>\n",
              "      <td>0.358758</td>\n",
              "      <td>0.086211</td>\n",
              "      <td>0.126359</td>\n",
              "      <td>0.046438</td>\n",
              "      <td>0.208784</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.567615</td>\n",
              "      <td>0.512900</td>\n",
              "      <td>0.756006</td>\n",
              "      <td>0.273948</td>\n",
              "      <td>0.355545</td>\n",
              "      <td>0.392632</td>\n",
              "      <td>0.700247</td>\n",
              "      <td>0.383720</td>\n",
              "      <td>0.288251</td>\n",
              "      <td>0.460154</td>\n",
              "      <td>0.346931</td>\n",
              "      <td>0.592128</td>\n",
              "      <td>0.223071</td>\n",
              "      <td>0.941103</td>\n",
              "      <td>0.079103</td>\n",
              "      <td>0.422347</td>\n",
              "      <td>0.550132</td>\n",
              "      <td>0.139459</td>\n",
              "      <td>0.425594</td>\n",
              "      <td>0.136739</td>\n",
              "      <td>0.163232</td>\n",
              "      <td>0.493747</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1753</th>\n",
              "      <td>1753</td>\n",
              "      <td>905939</td>\n",
              "      <td>HT-29</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>-0.970947</td>\n",
              "      <td>0.313201</td>\n",
              "      <td>0.038280</td>\n",
              "      <td>0.063812</td>\n",
              "      <td>0.445275</td>\n",
              "      <td>0.046869</td>\n",
              "      <td>0.096091</td>\n",
              "      <td>0.313718</td>\n",
              "      <td>0.623458</td>\n",
              "      <td>0.048760</td>\n",
              "      <td>0.271831</td>\n",
              "      <td>0.086255</td>\n",
              "      <td>0.467896</td>\n",
              "      <td>0.032493</td>\n",
              "      <td>0.455519</td>\n",
              "      <td>0.624686</td>\n",
              "      <td>0.157443</td>\n",
              "      <td>0.406074</td>\n",
              "      <td>0.337643</td>\n",
              "      <td>0.402556</td>\n",
              "      <td>0.374226</td>\n",
              "      <td>0.646009</td>\n",
              "      <td>0.618591</td>\n",
              "      <td>0.358097</td>\n",
              "      <td>0.503028</td>\n",
              "      <td>0.122549</td>\n",
              "      <td>0.377686</td>\n",
              "      <td>0.625709</td>\n",
              "      <td>0.233503</td>\n",
              "      <td>0.326895</td>\n",
              "      <td>0.529073</td>\n",
              "      <td>0.105760</td>\n",
              "      <td>0.336436</td>\n",
              "      <td>0.031344</td>\n",
              "      <td>0.115808</td>\n",
              "      <td>0.735896</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>1754</td>\n",
              "      <td>905961</td>\n",
              "      <td>COLO-205</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>-3.416496</td>\n",
              "      <td>0.439068</td>\n",
              "      <td>0.035962</td>\n",
              "      <td>0.035725</td>\n",
              "      <td>0.489103</td>\n",
              "      <td>0.102220</td>\n",
              "      <td>0.175988</td>\n",
              "      <td>0.189343</td>\n",
              "      <td>0.466965</td>\n",
              "      <td>0.056732</td>\n",
              "      <td>0.300002</td>\n",
              "      <td>0.062686</td>\n",
              "      <td>0.542505</td>\n",
              "      <td>0.024669</td>\n",
              "      <td>0.499628</td>\n",
              "      <td>0.561652</td>\n",
              "      <td>0.058566</td>\n",
              "      <td>0.477390</td>\n",
              "      <td>0.352591</td>\n",
              "      <td>0.634896</td>\n",
              "      <td>0.397755</td>\n",
              "      <td>0.510152</td>\n",
              "      <td>0.491862</td>\n",
              "      <td>0.082707</td>\n",
              "      <td>0.479062</td>\n",
              "      <td>0.137466</td>\n",
              "      <td>0.283996</td>\n",
              "      <td>0.339465</td>\n",
              "      <td>0.372258</td>\n",
              "      <td>0.457552</td>\n",
              "      <td>0.685778</td>\n",
              "      <td>0.102094</td>\n",
              "      <td>0.668745</td>\n",
              "      <td>0.084991</td>\n",
              "      <td>0.111544</td>\n",
              "      <td>0.649986</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>1755</td>\n",
              "      <td>905962</td>\n",
              "      <td>SW620</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>0.797740</td>\n",
              "      <td>0.453850</td>\n",
              "      <td>0.041990</td>\n",
              "      <td>0.111984</td>\n",
              "      <td>0.748820</td>\n",
              "      <td>0.109232</td>\n",
              "      <td>0.118878</td>\n",
              "      <td>0.638330</td>\n",
              "      <td>0.337161</td>\n",
              "      <td>0.408148</td>\n",
              "      <td>0.478464</td>\n",
              "      <td>0.051985</td>\n",
              "      <td>0.368282</td>\n",
              "      <td>0.045878</td>\n",
              "      <td>0.609077</td>\n",
              "      <td>0.250035</td>\n",
              "      <td>0.104587</td>\n",
              "      <td>0.514765</td>\n",
              "      <td>0.574473</td>\n",
              "      <td>0.440861</td>\n",
              "      <td>0.627534</td>\n",
              "      <td>0.486819</td>\n",
              "      <td>0.504534</td>\n",
              "      <td>0.119803</td>\n",
              "      <td>0.212066</td>\n",
              "      <td>0.186372</td>\n",
              "      <td>0.544376</td>\n",
              "      <td>0.526725</td>\n",
              "      <td>0.539394</td>\n",
              "      <td>0.504472</td>\n",
              "      <td>0.430026</td>\n",
              "      <td>0.105518</td>\n",
              "      <td>0.505341</td>\n",
              "      <td>0.090485</td>\n",
              "      <td>0.198159</td>\n",
              "      <td>0.669806</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1756</th>\n",
              "      <td>1756</td>\n",
              "      <td>905971</td>\n",
              "      <td>HCC2998</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>2.452375</td>\n",
              "      <td>0.439910</td>\n",
              "      <td>0.029406</td>\n",
              "      <td>0.044036</td>\n",
              "      <td>0.423808</td>\n",
              "      <td>0.146303</td>\n",
              "      <td>0.153921</td>\n",
              "      <td>0.457220</td>\n",
              "      <td>0.498264</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.427243</td>\n",
              "      <td>0.033645</td>\n",
              "      <td>0.367547</td>\n",
              "      <td>0.026127</td>\n",
              "      <td>0.460748</td>\n",
              "      <td>0.338929</td>\n",
              "      <td>0.053081</td>\n",
              "      <td>0.453114</td>\n",
              "      <td>0.409218</td>\n",
              "      <td>0.438522</td>\n",
              "      <td>0.323406</td>\n",
              "      <td>0.544659</td>\n",
              "      <td>0.452354</td>\n",
              "      <td>0.356217</td>\n",
              "      <td>0.313258</td>\n",
              "      <td>0.102439</td>\n",
              "      <td>0.444342</td>\n",
              "      <td>0.744682</td>\n",
              "      <td>0.181319</td>\n",
              "      <td>0.547437</td>\n",
              "      <td>0.517223</td>\n",
              "      <td>0.213699</td>\n",
              "      <td>0.304372</td>\n",
              "      <td>0.092052</td>\n",
              "      <td>0.138254</td>\n",
              "      <td>0.560582</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1757</th>\n",
              "      <td>1757</td>\n",
              "      <td>905989</td>\n",
              "      <td>KM12</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>-2.725681</td>\n",
              "      <td>0.331874</td>\n",
              "      <td>0.025124</td>\n",
              "      <td>0.035678</td>\n",
              "      <td>0.520597</td>\n",
              "      <td>0.056487</td>\n",
              "      <td>0.193226</td>\n",
              "      <td>0.536482</td>\n",
              "      <td>0.480155</td>\n",
              "      <td>0.061966</td>\n",
              "      <td>0.377320</td>\n",
              "      <td>0.039614</td>\n",
              "      <td>0.518548</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.495043</td>\n",
              "      <td>0.386553</td>\n",
              "      <td>0.065246</td>\n",
              "      <td>0.567048</td>\n",
              "      <td>0.270060</td>\n",
              "      <td>0.387119</td>\n",
              "      <td>0.406812</td>\n",
              "      <td>0.532597</td>\n",
              "      <td>0.592743</td>\n",
              "      <td>0.406068</td>\n",
              "      <td>0.357241</td>\n",
              "      <td>0.151223</td>\n",
              "      <td>0.319128</td>\n",
              "      <td>0.779886</td>\n",
              "      <td>0.300751</td>\n",
              "      <td>0.429936</td>\n",
              "      <td>0.509255</td>\n",
              "      <td>0.133823</td>\n",
              "      <td>0.575487</td>\n",
              "      <td>0.071813</td>\n",
              "      <td>0.130061</td>\n",
              "      <td>0.396127</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1758 rows × 761 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1da92c07-d220-4139-b9fb-62e2d7dba553')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1da92c07-d220-4139-b9fb-62e2d7dba553 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1da92c07-d220-4139-b9fb-62e2d7dba553');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Unnamed: 0  COSMIC_ID CELL_LINE_NAME     DRUG_NAME  ...  252  253  254  255\n",
              "0              0     749709        HCC1954  Camptothecin  ...    0    0    0    0\n",
              "1              1     749710        HCC1143  Camptothecin  ...    0    0    0    0\n",
              "2              2     749711        HCC1187  Camptothecin  ...    0    0    0    0\n",
              "3              3     749712        HCC1395  Camptothecin  ...    0    0    0    0\n",
              "4              4     749713        HCC1599  Camptothecin  ...    0    0    0    0\n",
              "...          ...        ...            ...           ...  ...  ...  ...  ...  ...\n",
              "1753        1753     905939          HT-29    BMS-754807  ...    1    0    1    1\n",
              "1754        1754     905961       COLO-205    BMS-754807  ...    1    0    1    1\n",
              "1755        1755     905962          SW620    BMS-754807  ...    1    0    1    1\n",
              "1756        1756     905971        HCC2998    BMS-754807  ...    1    0    1    1\n",
              "1757        1757     905989           KM12    BMS-754807  ...    1    0    1    1\n",
              "\n",
              "[1758 rows x 761 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_merged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "mBGO4-aFuIlF",
        "outputId": "75a7664f-441e-42fa-c319-9c854312efae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-485d5de4-e81a-46ff-b348-ed9bbd997f3b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COSMIC_ID</th>\n",
              "      <th>CELL_LINE_NAME</th>\n",
              "      <th>DRUG_NAME</th>\n",
              "      <th>LN_IC50</th>\n",
              "      <th>ENSG00000004142</th>\n",
              "      <th>ENSG00000005381</th>\n",
              "      <th>ENSG00000005471</th>\n",
              "      <th>ENSG00000006025</th>\n",
              "      <th>ENSG00000006377</th>\n",
              "      <th>ENSG00000010030</th>\n",
              "      <th>ENSG00000011376</th>\n",
              "      <th>ENSG00000011405</th>\n",
              "      <th>ENSG00000013297</th>\n",
              "      <th>ENSG00000013523</th>\n",
              "      <th>ENSG00000019186</th>\n",
              "      <th>ENSG00000022840</th>\n",
              "      <th>ENSG00000029534</th>\n",
              "      <th>ENSG00000030066</th>\n",
              "      <th>ENSG00000033800</th>\n",
              "      <th>ENSG00000042980</th>\n",
              "      <th>ENSG00000049167</th>\n",
              "      <th>ENSG00000053702</th>\n",
              "      <th>ENSG00000055147</th>\n",
              "      <th>ENSG00000056736</th>\n",
              "      <th>ENSG00000063177</th>\n",
              "      <th>ENSG00000064666</th>\n",
              "      <th>ENSG00000064961</th>\n",
              "      <th>ENSG00000065361</th>\n",
              "      <th>ENSG00000065371</th>\n",
              "      <th>ENSG00000066117</th>\n",
              "      <th>ENSG00000066279</th>\n",
              "      <th>ENSG00000067365</th>\n",
              "      <th>ENSG00000068796</th>\n",
              "      <th>ENSG00000068912</th>\n",
              "      <th>ENSG00000068976</th>\n",
              "      <th>ENSG00000070081</th>\n",
              "      <th>ENSG00000070371</th>\n",
              "      <th>ENSG00000070778</th>\n",
              "      <th>ENSG00000073578</th>\n",
              "      <th>ENSG00000073861</th>\n",
              "      <th>...</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "      <th>224</th>\n",
              "      <th>225</th>\n",
              "      <th>226</th>\n",
              "      <th>227</th>\n",
              "      <th>228</th>\n",
              "      <th>229</th>\n",
              "      <th>230</th>\n",
              "      <th>231</th>\n",
              "      <th>232</th>\n",
              "      <th>233</th>\n",
              "      <th>234</th>\n",
              "      <th>235</th>\n",
              "      <th>236</th>\n",
              "      <th>237</th>\n",
              "      <th>238</th>\n",
              "      <th>239</th>\n",
              "      <th>240</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>749709</td>\n",
              "      <td>HCC1954</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-0.251083</td>\n",
              "      <td>0.485528</td>\n",
              "      <td>0.034439</td>\n",
              "      <td>0.032211</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>0.054142</td>\n",
              "      <td>0.161899</td>\n",
              "      <td>0.512239</td>\n",
              "      <td>0.320807</td>\n",
              "      <td>0.016741</td>\n",
              "      <td>0.211246</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.303116</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>0.432740</td>\n",
              "      <td>0.320047</td>\n",
              "      <td>0.042828</td>\n",
              "      <td>0.509640</td>\n",
              "      <td>0.384298</td>\n",
              "      <td>0.503162</td>\n",
              "      <td>0.118236</td>\n",
              "      <td>0.614114</td>\n",
              "      <td>0.600234</td>\n",
              "      <td>0.291391</td>\n",
              "      <td>0.172339</td>\n",
              "      <td>0.109936</td>\n",
              "      <td>0.283640</td>\n",
              "      <td>0.700231</td>\n",
              "      <td>0.280166</td>\n",
              "      <td>0.469874</td>\n",
              "      <td>0.419057</td>\n",
              "      <td>0.076955</td>\n",
              "      <td>0.296040</td>\n",
              "      <td>0.066944</td>\n",
              "      <td>0.185520</td>\n",
              "      <td>0.685843</td>\n",
              "      <td>0.067721</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>749710</td>\n",
              "      <td>HCC1143</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.343315</td>\n",
              "      <td>0.311230</td>\n",
              "      <td>0.025165</td>\n",
              "      <td>0.031411</td>\n",
              "      <td>0.458095</td>\n",
              "      <td>0.191393</td>\n",
              "      <td>0.372622</td>\n",
              "      <td>0.454148</td>\n",
              "      <td>0.711950</td>\n",
              "      <td>0.727950</td>\n",
              "      <td>0.269799</td>\n",
              "      <td>0.071288</td>\n",
              "      <td>0.371427</td>\n",
              "      <td>0.290302</td>\n",
              "      <td>0.577338</td>\n",
              "      <td>0.449637</td>\n",
              "      <td>0.064719</td>\n",
              "      <td>0.252867</td>\n",
              "      <td>0.271434</td>\n",
              "      <td>0.347377</td>\n",
              "      <td>0.183097</td>\n",
              "      <td>0.646863</td>\n",
              "      <td>0.554294</td>\n",
              "      <td>0.454478</td>\n",
              "      <td>0.293674</td>\n",
              "      <td>0.124696</td>\n",
              "      <td>0.225172</td>\n",
              "      <td>0.819032</td>\n",
              "      <td>0.236604</td>\n",
              "      <td>0.445945</td>\n",
              "      <td>0.466896</td>\n",
              "      <td>0.094528</td>\n",
              "      <td>0.617589</td>\n",
              "      <td>0.070329</td>\n",
              "      <td>0.116111</td>\n",
              "      <td>0.877219</td>\n",
              "      <td>0.083713</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>749711</td>\n",
              "      <td>HCC1187</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>1.736985</td>\n",
              "      <td>0.238954</td>\n",
              "      <td>0.051395</td>\n",
              "      <td>0.067070</td>\n",
              "      <td>0.456622</td>\n",
              "      <td>0.043694</td>\n",
              "      <td>0.919986</td>\n",
              "      <td>0.345631</td>\n",
              "      <td>0.640566</td>\n",
              "      <td>0.151405</td>\n",
              "      <td>0.244364</td>\n",
              "      <td>0.037784</td>\n",
              "      <td>0.407550</td>\n",
              "      <td>0.045708</td>\n",
              "      <td>0.638971</td>\n",
              "      <td>0.342508</td>\n",
              "      <td>0.061305</td>\n",
              "      <td>0.535583</td>\n",
              "      <td>0.377523</td>\n",
              "      <td>0.422462</td>\n",
              "      <td>0.523686</td>\n",
              "      <td>0.559227</td>\n",
              "      <td>0.094328</td>\n",
              "      <td>0.402929</td>\n",
              "      <td>0.400033</td>\n",
              "      <td>0.096194</td>\n",
              "      <td>0.303966</td>\n",
              "      <td>0.835617</td>\n",
              "      <td>0.322354</td>\n",
              "      <td>0.412906</td>\n",
              "      <td>0.171166</td>\n",
              "      <td>0.066090</td>\n",
              "      <td>0.485675</td>\n",
              "      <td>0.152859</td>\n",
              "      <td>0.155562</td>\n",
              "      <td>0.639032</td>\n",
              "      <td>0.064492</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>749712</td>\n",
              "      <td>HCC1395</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-2.309078</td>\n",
              "      <td>0.324720</td>\n",
              "      <td>0.042300</td>\n",
              "      <td>0.067512</td>\n",
              "      <td>0.313101</td>\n",
              "      <td>0.397069</td>\n",
              "      <td>0.098445</td>\n",
              "      <td>0.552249</td>\n",
              "      <td>0.209121</td>\n",
              "      <td>0.075942</td>\n",
              "      <td>0.305536</td>\n",
              "      <td>0.041849</td>\n",
              "      <td>0.177567</td>\n",
              "      <td>0.113092</td>\n",
              "      <td>0.343055</td>\n",
              "      <td>0.491634</td>\n",
              "      <td>0.079983</td>\n",
              "      <td>0.301461</td>\n",
              "      <td>0.405244</td>\n",
              "      <td>0.518617</td>\n",
              "      <td>0.163528</td>\n",
              "      <td>0.402730</td>\n",
              "      <td>0.404349</td>\n",
              "      <td>0.520293</td>\n",
              "      <td>0.030230</td>\n",
              "      <td>0.639274</td>\n",
              "      <td>0.572510</td>\n",
              "      <td>0.855242</td>\n",
              "      <td>0.514551</td>\n",
              "      <td>0.364675</td>\n",
              "      <td>0.416497</td>\n",
              "      <td>0.142641</td>\n",
              "      <td>0.563301</td>\n",
              "      <td>0.098760</td>\n",
              "      <td>0.236006</td>\n",
              "      <td>0.625014</td>\n",
              "      <td>0.115143</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>749713</td>\n",
              "      <td>HCC1599</td>\n",
              "      <td>Camptothecin</td>\n",
              "      <td>-3.106684</td>\n",
              "      <td>0.276038</td>\n",
              "      <td>0.017270</td>\n",
              "      <td>0.067748</td>\n",
              "      <td>0.218027</td>\n",
              "      <td>0.517101</td>\n",
              "      <td>0.085292</td>\n",
              "      <td>0.278903</td>\n",
              "      <td>0.358758</td>\n",
              "      <td>0.086211</td>\n",
              "      <td>0.126359</td>\n",
              "      <td>0.046438</td>\n",
              "      <td>0.208784</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.567615</td>\n",
              "      <td>0.512900</td>\n",
              "      <td>0.756006</td>\n",
              "      <td>0.273948</td>\n",
              "      <td>0.355545</td>\n",
              "      <td>0.392632</td>\n",
              "      <td>0.700247</td>\n",
              "      <td>0.383720</td>\n",
              "      <td>0.288251</td>\n",
              "      <td>0.460154</td>\n",
              "      <td>0.346931</td>\n",
              "      <td>0.592128</td>\n",
              "      <td>0.223071</td>\n",
              "      <td>0.941103</td>\n",
              "      <td>0.079103</td>\n",
              "      <td>0.422347</td>\n",
              "      <td>0.550132</td>\n",
              "      <td>0.139459</td>\n",
              "      <td>0.425594</td>\n",
              "      <td>0.136739</td>\n",
              "      <td>0.163232</td>\n",
              "      <td>0.493747</td>\n",
              "      <td>0.050262</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1753</th>\n",
              "      <td>905939</td>\n",
              "      <td>HT-29</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>-0.970947</td>\n",
              "      <td>0.313201</td>\n",
              "      <td>0.038280</td>\n",
              "      <td>0.063812</td>\n",
              "      <td>0.445275</td>\n",
              "      <td>0.046869</td>\n",
              "      <td>0.096091</td>\n",
              "      <td>0.313718</td>\n",
              "      <td>0.623458</td>\n",
              "      <td>0.048760</td>\n",
              "      <td>0.271831</td>\n",
              "      <td>0.086255</td>\n",
              "      <td>0.467896</td>\n",
              "      <td>0.032493</td>\n",
              "      <td>0.455519</td>\n",
              "      <td>0.624686</td>\n",
              "      <td>0.157443</td>\n",
              "      <td>0.406074</td>\n",
              "      <td>0.337643</td>\n",
              "      <td>0.402556</td>\n",
              "      <td>0.374226</td>\n",
              "      <td>0.646009</td>\n",
              "      <td>0.618591</td>\n",
              "      <td>0.358097</td>\n",
              "      <td>0.503028</td>\n",
              "      <td>0.122549</td>\n",
              "      <td>0.377686</td>\n",
              "      <td>0.625709</td>\n",
              "      <td>0.233503</td>\n",
              "      <td>0.326895</td>\n",
              "      <td>0.529073</td>\n",
              "      <td>0.105760</td>\n",
              "      <td>0.336436</td>\n",
              "      <td>0.031344</td>\n",
              "      <td>0.115808</td>\n",
              "      <td>0.735896</td>\n",
              "      <td>0.064147</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>905961</td>\n",
              "      <td>COLO-205</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>-3.416496</td>\n",
              "      <td>0.439068</td>\n",
              "      <td>0.035962</td>\n",
              "      <td>0.035725</td>\n",
              "      <td>0.489103</td>\n",
              "      <td>0.102220</td>\n",
              "      <td>0.175988</td>\n",
              "      <td>0.189343</td>\n",
              "      <td>0.466965</td>\n",
              "      <td>0.056732</td>\n",
              "      <td>0.300002</td>\n",
              "      <td>0.062686</td>\n",
              "      <td>0.542505</td>\n",
              "      <td>0.024669</td>\n",
              "      <td>0.499628</td>\n",
              "      <td>0.561652</td>\n",
              "      <td>0.058566</td>\n",
              "      <td>0.477390</td>\n",
              "      <td>0.352591</td>\n",
              "      <td>0.634896</td>\n",
              "      <td>0.397755</td>\n",
              "      <td>0.510152</td>\n",
              "      <td>0.491862</td>\n",
              "      <td>0.082707</td>\n",
              "      <td>0.479062</td>\n",
              "      <td>0.137466</td>\n",
              "      <td>0.283996</td>\n",
              "      <td>0.339465</td>\n",
              "      <td>0.372258</td>\n",
              "      <td>0.457552</td>\n",
              "      <td>0.685778</td>\n",
              "      <td>0.102094</td>\n",
              "      <td>0.668745</td>\n",
              "      <td>0.084991</td>\n",
              "      <td>0.111544</td>\n",
              "      <td>0.649986</td>\n",
              "      <td>0.065167</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>905962</td>\n",
              "      <td>SW620</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>0.797740</td>\n",
              "      <td>0.453850</td>\n",
              "      <td>0.041990</td>\n",
              "      <td>0.111984</td>\n",
              "      <td>0.748820</td>\n",
              "      <td>0.109232</td>\n",
              "      <td>0.118878</td>\n",
              "      <td>0.638330</td>\n",
              "      <td>0.337161</td>\n",
              "      <td>0.408148</td>\n",
              "      <td>0.478464</td>\n",
              "      <td>0.051985</td>\n",
              "      <td>0.368282</td>\n",
              "      <td>0.045878</td>\n",
              "      <td>0.609077</td>\n",
              "      <td>0.250035</td>\n",
              "      <td>0.104587</td>\n",
              "      <td>0.514765</td>\n",
              "      <td>0.574473</td>\n",
              "      <td>0.440861</td>\n",
              "      <td>0.627534</td>\n",
              "      <td>0.486819</td>\n",
              "      <td>0.504534</td>\n",
              "      <td>0.119803</td>\n",
              "      <td>0.212066</td>\n",
              "      <td>0.186372</td>\n",
              "      <td>0.544376</td>\n",
              "      <td>0.526725</td>\n",
              "      <td>0.539394</td>\n",
              "      <td>0.504472</td>\n",
              "      <td>0.430026</td>\n",
              "      <td>0.105518</td>\n",
              "      <td>0.505341</td>\n",
              "      <td>0.090485</td>\n",
              "      <td>0.198159</td>\n",
              "      <td>0.669806</td>\n",
              "      <td>0.008165</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1756</th>\n",
              "      <td>905971</td>\n",
              "      <td>HCC2998</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>2.452375</td>\n",
              "      <td>0.439910</td>\n",
              "      <td>0.029406</td>\n",
              "      <td>0.044036</td>\n",
              "      <td>0.423808</td>\n",
              "      <td>0.146303</td>\n",
              "      <td>0.153921</td>\n",
              "      <td>0.457220</td>\n",
              "      <td>0.498264</td>\n",
              "      <td>0.031142</td>\n",
              "      <td>0.427243</td>\n",
              "      <td>0.033645</td>\n",
              "      <td>0.367547</td>\n",
              "      <td>0.026127</td>\n",
              "      <td>0.460748</td>\n",
              "      <td>0.338929</td>\n",
              "      <td>0.053081</td>\n",
              "      <td>0.453114</td>\n",
              "      <td>0.409218</td>\n",
              "      <td>0.438522</td>\n",
              "      <td>0.323406</td>\n",
              "      <td>0.544659</td>\n",
              "      <td>0.452354</td>\n",
              "      <td>0.356217</td>\n",
              "      <td>0.313258</td>\n",
              "      <td>0.102439</td>\n",
              "      <td>0.444342</td>\n",
              "      <td>0.744682</td>\n",
              "      <td>0.181319</td>\n",
              "      <td>0.547437</td>\n",
              "      <td>0.517223</td>\n",
              "      <td>0.213699</td>\n",
              "      <td>0.304372</td>\n",
              "      <td>0.092052</td>\n",
              "      <td>0.138254</td>\n",
              "      <td>0.560582</td>\n",
              "      <td>0.031804</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1757</th>\n",
              "      <td>905989</td>\n",
              "      <td>KM12</td>\n",
              "      <td>BMS-754807</td>\n",
              "      <td>-2.725681</td>\n",
              "      <td>0.331874</td>\n",
              "      <td>0.025124</td>\n",
              "      <td>0.035678</td>\n",
              "      <td>0.520597</td>\n",
              "      <td>0.056487</td>\n",
              "      <td>0.193226</td>\n",
              "      <td>0.536482</td>\n",
              "      <td>0.480155</td>\n",
              "      <td>0.061966</td>\n",
              "      <td>0.377320</td>\n",
              "      <td>0.039614</td>\n",
              "      <td>0.518548</td>\n",
              "      <td>0.023480</td>\n",
              "      <td>0.495043</td>\n",
              "      <td>0.386554</td>\n",
              "      <td>0.065246</td>\n",
              "      <td>0.567048</td>\n",
              "      <td>0.270060</td>\n",
              "      <td>0.387119</td>\n",
              "      <td>0.406812</td>\n",
              "      <td>0.532597</td>\n",
              "      <td>0.592743</td>\n",
              "      <td>0.406068</td>\n",
              "      <td>0.357241</td>\n",
              "      <td>0.151223</td>\n",
              "      <td>0.319128</td>\n",
              "      <td>0.779886</td>\n",
              "      <td>0.300751</td>\n",
              "      <td>0.429936</td>\n",
              "      <td>0.509255</td>\n",
              "      <td>0.133823</td>\n",
              "      <td>0.575487</td>\n",
              "      <td>0.071813</td>\n",
              "      <td>0.130061</td>\n",
              "      <td>0.396127</td>\n",
              "      <td>0.050399</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1758 rows × 760 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-485d5de4-e81a-46ff-b348-ed9bbd997f3b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-485d5de4-e81a-46ff-b348-ed9bbd997f3b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-485d5de4-e81a-46ff-b348-ed9bbd997f3b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      COSMIC_ID CELL_LINE_NAME     DRUG_NAME   LN_IC50  ...  252  253  254  255\n",
              "0        749709        HCC1954  Camptothecin -0.251083  ...    0    0    0    0\n",
              "1        749710        HCC1143  Camptothecin  1.343315  ...    0    0    0    0\n",
              "2        749711        HCC1187  Camptothecin  1.736985  ...    0    0    0    0\n",
              "3        749712        HCC1395  Camptothecin -2.309078  ...    0    0    0    0\n",
              "4        749713        HCC1599  Camptothecin -3.106684  ...    0    0    0    0\n",
              "...         ...            ...           ...       ...  ...  ...  ...  ...  ...\n",
              "1753     905939          HT-29    BMS-754807 -0.970947  ...    1    0    1    1\n",
              "1754     905961       COLO-205    BMS-754807 -3.416496  ...    1    0    1    1\n",
              "1755     905962          SW620    BMS-754807  0.797740  ...    1    0    1    1\n",
              "1756     905971        HCC2998    BMS-754807  2.452375  ...    1    0    1    1\n",
              "1757     905989           KM12    BMS-754807 -2.725681  ...    1    0    1    1\n",
              "\n",
              "[1758 rows x 760 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_values = df[[\"CELL_LINE_NAME\"]].values.ravel()\n",
        "unique_values =  pd.unique(column_values)\n",
        "\n",
        "print(unique_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y-q7XHTewuq",
        "outputId": "c96a8b7e-34a9-4b81-c243-84c573b278df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HCC1954' 'HCC1143' 'HCC1187' 'HCC1395' 'HCC1599' 'HCC1937' 'HCC2157'\n",
            " 'HCC2218' 'HCC38' 'HCT-116' 'HCT-15' 'HT-29' 'T47D' 'MCF7' 'BT-549'\n",
            " 'Hs-578-T' 'MDA-MB-231' 'COLO-205' 'SW620' 'HCC2998' 'KM12' 'BT-20']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as scistat\n",
        "import sklearn.metrics as skmts\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from math import sqrt\n",
        "from numpy import absolute\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "#NEURAL NETWORK\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint \n",
        "from sklearn.model_selection import KFold\n",
        "from keras.initializers import HeNormal\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "#from keras.optimizers import Adamax\n",
        "from keras import optimizers\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import absolute\n",
        "\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "StnpxK3igo1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def root_mean_squared_error(y_test, prediction):\n",
        "    return K.sqrt(K.mean(K.square(y_test-prediction)))         \n",
        "X =drug_merged.iloc[:,5:]\n",
        "#X = drug_merged[feature_cols] # Features\n",
        "y = drug_merged['LN_IC50'] # Target variable\n",
        "X=np.asarray(X).astype(np.float32)\n",
        "y=np.asarray(y).astype(np.float32)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "seed = 20\n",
        "\n",
        "def baseline_model():\n",
        "    initializer = HeNormal()\n",
        "    model = Sequential()\n",
        "    model.add(Dense(756, input_dim=756,kernel_initializer=initializer))\n",
        "    model.add(Dense(1000, activation='elu',kernel_initializer=initializer))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(800, activation='elu',kernel_initializer=initializer))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(500, activation='elu',kernel_initializer=initializer))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(100, activation='elu',kernel_initializer=initializer))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,kernel_initializer=initializer))\n",
        "    opt = Adamax(learning_rate=0.0004, clipvalue=5)\n",
        "    #prediction = model.predict(drug_merged)\n",
        "    training_split=0.7\n",
        "    model.compile(loss= root_mean_squared_error, optimizer=opt)\n",
        "    #model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae', 'mape', 'cosine'])\n",
        "    return model\n",
        "\n",
        "# checkpoint\n",
        "filepath=\"WithoutOncoGenesSubSet1weights.best.hdf5\"\n",
        "\n",
        "test_es = EarlyStopping(monitor='val_loss', patience=30)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "callbacks_list = [checkpoint, test_es]\n",
        "estimator = KerasRegressor(build_fn=baseline_model, epochs=1000, batch_size=32,validation_split=.1)\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
        "results = cross_val_score(estimator, X, y,scoring='neg_root_mean_squared_error', cv=kfold, fit_params={'callbacks': callbacks_list})\n",
        "results1 = cross_val_score(estimator, X, y,scoring='neg_mean_squared_error', cv=kfold, fit_params={'callbacks': callbacks_list})\n",
        "scores = cross_val_score(estimator, X, y, scoring='neg_mean_absolute_error', cv=kfold, fit_params={'callbacks': callbacks_list})\n",
        "scores1 = cross_val_score(estimator, X, y, scoring='r2', cv=kfold, fit_params={'callbacks': callbacks_list})\n",
        "# force scores to be positive\n",
        "\n",
        "results = absolute(results)\n",
        "print('Mean RMSE: %.3f (%.3f)' % (mean(results), std(results)))\n",
        "\n",
        "results1 = absolute(results1)\n",
        "print('Mean MSE: %.3f (%.3f)' % (mean(results1), std(results1)))\n",
        "\n",
        "scores = absolute(scores)\n",
        "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))\n",
        "\n",
        "scores1 = absolute(scores)\n",
        "print('Mean R2: %.3f (%.3f)' % (mean(scores1), std(scores1)))\n",
        "\n",
        "#history=model.fit(drug_merged, y, epochs=20, batch_size=20, verbose=2, validation_split=0.3)\n",
        "\n",
        "#pyplot.plot(history.history['mean_squared_error'])\n",
        "\n",
        "# force scores to be positive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAB_SkVygxev",
        "outputId": "e63eb61f-b548-4291-839f-596efefe4605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 60/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.7461\n",
            "Epoch 00060: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7414 - val_loss: 2.7394\n",
            "Epoch 61/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.7474\n",
            "Epoch 00061: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7370 - val_loss: 2.8104\n",
            "Epoch 1/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 2.9543\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.8658 - val_loss: 2.3776\n",
            "Epoch 2/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.7761\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7687 - val_loss: 2.5695\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5713\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5713 - val_loss: 2.7957\n",
            "Epoch 4/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4915\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4913 - val_loss: 2.7699\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4781\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4781 - val_loss: 2.3996\n",
            "Epoch 6/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4648\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4644 - val_loss: 2.6940\n",
            "Epoch 7/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3952\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4007 - val_loss: 2.6654\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3897\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3950 - val_loss: 2.4106\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3558\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3504 - val_loss: 2.6735\n",
            "Epoch 10/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3276\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3166 - val_loss: 2.7153\n",
            "Epoch 11/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.3650\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3644 - val_loss: 2.5673\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2823\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2795 - val_loss: 2.6544\n",
            "Epoch 13/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2272\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2309 - val_loss: 2.8001\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2333\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2455 - val_loss: 2.6225\n",
            "Epoch 15/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1697\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1766 - val_loss: 2.7809\n",
            "Epoch 16/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1416\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1359 - val_loss: 2.7769\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1515\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1504 - val_loss: 2.6996\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1474\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1498 - val_loss: 2.7735\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1788\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1802 - val_loss: 2.5209\n",
            "Epoch 20/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0992\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1028 - val_loss: 2.6376\n",
            "Epoch 21/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0975\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0942 - val_loss: 2.6139\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0447\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0447 - val_loss: 2.4925\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0741\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0741 - val_loss: 2.5338\n",
            "Epoch 24/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0159\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0151 - val_loss: 2.5911\n",
            "Epoch 25/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0023\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0120 - val_loss: 2.6391\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9860\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9864 - val_loss: 2.7349\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9891\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9891 - val_loss: 2.7613\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9900\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9900 - val_loss: 2.7495\n",
            "Epoch 29/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9760\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9777 - val_loss: 2.6071\n",
            "Epoch 30/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9306\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9488 - val_loss: 2.7690\n",
            "Epoch 31/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9571\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9558 - val_loss: 2.7658\n",
            "Epoch 1/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 2.8530\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.8368 - val_loss: 2.2488\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.7439\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7339 - val_loss: 2.2387\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5211\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5267 - val_loss: 2.3976\n",
            "Epoch 4/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4990\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4879 - val_loss: 2.3887\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4515\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4629 - val_loss: 2.6094\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3848\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3910 - val_loss: 2.2891\n",
            "Epoch 7/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3935\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3982 - val_loss: 2.4119\n",
            "Epoch 8/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3526\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3513 - val_loss: 2.3247\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3082\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3074 - val_loss: 2.2111\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2878\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2878 - val_loss: 2.2599\n",
            "Epoch 11/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2550\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2512 - val_loss: 2.6082\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2434\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2444 - val_loss: 2.2666\n",
            "Epoch 13/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1990\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1896 - val_loss: 2.3351\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2376\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2376 - val_loss: 2.2780\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2063\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2054 - val_loss: 2.2957\n",
            "Epoch 16/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2060\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1951 - val_loss: 2.4760\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1859\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1859 - val_loss: 2.5037\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1521\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1521 - val_loss: 2.3726\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0821\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0774 - val_loss: 2.5291\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1148\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1148 - val_loss: 2.4258\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0998\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0998 - val_loss: 2.3314\n",
            "Epoch 22/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0578\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0708 - val_loss: 2.3773\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0632\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0632 - val_loss: 2.4980\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0000\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0000 - val_loss: 2.4661\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0076\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0076 - val_loss: 2.4152\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9985\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9977 - val_loss: 2.4934\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0188\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0239 - val_loss: 2.4560\n",
            "Epoch 28/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9520\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9560 - val_loss: 2.4854\n",
            "Epoch 29/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9919\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9875 - val_loss: 2.4962\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9670\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9670 - val_loss: 2.3943\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9137\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9273 - val_loss: 2.4065\n",
            "Epoch 32/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9288\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9285 - val_loss: 2.4050\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8973\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8973 - val_loss: 2.4190\n",
            "Epoch 34/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9164\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9140 - val_loss: 2.4830\n",
            "Epoch 35/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8731\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8734 - val_loss: 2.4509\n",
            "Epoch 36/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8652\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8725 - val_loss: 2.6745\n",
            "Epoch 37/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8586\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8550 - val_loss: 2.5711\n",
            "Epoch 38/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8618\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8666 - val_loss: 2.5158\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8841\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8841 - val_loss: 2.5554\n",
            "Epoch 1/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 2.4643\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.3851 - val_loss: 2.3193\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.6247\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.6247 - val_loss: 2.4054\n",
            "Epoch 3/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.5289\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5301 - val_loss: 2.3447\n",
            "Epoch 4/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4545\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4532 - val_loss: 2.4209\n",
            "Epoch 5/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4928\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4981 - val_loss: 2.2846\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3937\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3937 - val_loss: 2.3082\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4068\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4038 - val_loss: 2.2276\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3467\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3467 - val_loss: 2.2645\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3281\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3132 - val_loss: 2.5781\n",
            "Epoch 10/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3002\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3014 - val_loss: 2.3146\n",
            "Epoch 11/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2886\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2896 - val_loss: 2.5914\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2210\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2299 - val_loss: 2.5147\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1844\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2049 - val_loss: 2.5020\n",
            "Epoch 14/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2406\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2328 - val_loss: 2.3634\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1521\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1663 - val_loss: 2.4757\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1688\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1649 - val_loss: 2.4950\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1084\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1084 - val_loss: 2.5191\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0847\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0847 - val_loss: 2.4139\n",
            "Epoch 19/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0922\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1112 - val_loss: 2.4454\n",
            "Epoch 20/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0631\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0642 - val_loss: 2.3730\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0284\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0222 - val_loss: 2.4827\n",
            "Epoch 22/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0311\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0283 - val_loss: 2.5266\n",
            "Epoch 23/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9807\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9785 - val_loss: 2.5092\n",
            "Epoch 24/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9854\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9877 - val_loss: 2.4627\n",
            "Epoch 25/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9964\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9959 - val_loss: 2.4867\n",
            "Epoch 26/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9357\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9357 - val_loss: 2.6188\n",
            "Epoch 27/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9932\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9852 - val_loss: 2.4286\n",
            "Epoch 28/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9748\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9691 - val_loss: 2.5008\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9347\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9347 - val_loss: 2.5660\n",
            "Epoch 30/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9435\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9415 - val_loss: 2.5738\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8952\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8952 - val_loss: 2.5777\n",
            "Epoch 32/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9156\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9167 - val_loss: 2.4499\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8950\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8950 - val_loss: 2.5332\n",
            "Epoch 34/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9005\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8885 - val_loss: 2.6138\n",
            "Epoch 35/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8725\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8712 - val_loss: 2.5153\n",
            "Epoch 36/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8735\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8750 - val_loss: 2.5515\n",
            "Epoch 37/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8790\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8760 - val_loss: 2.5166\n",
            "Epoch 1/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 2.2201\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.2048 - val_loss: 2.3025\n",
            "Epoch 2/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.6411\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6356 - val_loss: 2.6111\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5318\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5366 - val_loss: 2.4080\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5007\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5007 - val_loss: 2.3793\n",
            "Epoch 5/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4224\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4188 - val_loss: 2.3427\n",
            "Epoch 6/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4505\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4503 - val_loss: 2.3973\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3943\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3943 - val_loss: 2.4946\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3641\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3616 - val_loss: 2.6461\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2989\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2994 - val_loss: 2.4322\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3043\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3043 - val_loss: 2.5130\n",
            "Epoch 11/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.3033\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3038 - val_loss: 2.7113\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2818\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2836 - val_loss: 2.3019\n",
            "Epoch 13/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2418\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2403 - val_loss: 2.5209\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1857\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1857 - val_loss: 2.5096\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2282\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2191 - val_loss: 2.5320\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1763\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1763 - val_loss: 2.2384\n",
            "Epoch 17/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1490\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1400 - val_loss: 2.5450\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1317\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1317 - val_loss: 2.5203\n",
            "Epoch 19/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1283\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1336 - val_loss: 2.5142\n",
            "Epoch 20/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1013\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0921 - val_loss: 2.4294\n",
            "Epoch 21/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0622\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0622 - val_loss: 2.5571\n",
            "Epoch 22/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0816\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0713 - val_loss: 2.4791\n",
            "Epoch 23/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0386\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0338 - val_loss: 2.4687\n",
            "Epoch 24/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0999\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0895 - val_loss: 2.5059\n",
            "Epoch 25/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0558\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0513 - val_loss: 2.5547\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0239\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0159 - val_loss: 2.6196\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9810\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9810 - val_loss: 2.4697\n",
            "Epoch 28/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9660\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9567 - val_loss: 2.6045\n",
            "Epoch 29/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9613\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9594 - val_loss: 2.6007\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9338\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9336 - val_loss: 2.5438\n",
            "Epoch 31/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9664\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9637 - val_loss: 2.5255\n",
            "Epoch 32/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9661\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9732 - val_loss: 2.5170\n",
            "Epoch 33/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9546\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9503 - val_loss: 2.6433\n",
            "Epoch 34/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9324\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9426 - val_loss: 2.5628\n",
            "Epoch 35/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.8534\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8520 - val_loss: 2.6008\n",
            "Epoch 36/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8649\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8680 - val_loss: 2.4622\n",
            "Epoch 37/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8522\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8526 - val_loss: 2.7355\n",
            "Epoch 38/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9037\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8959 - val_loss: 2.5882\n",
            "Epoch 39/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8435\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8385 - val_loss: 2.6459\n",
            "Epoch 40/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8491\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8545 - val_loss: 2.5664\n",
            "Epoch 41/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8701\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8701 - val_loss: 2.6045\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8337\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8337 - val_loss: 2.6052\n",
            "Epoch 43/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8599\n",
            "Epoch 00043: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8565 - val_loss: 2.5785\n",
            "Epoch 44/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8446\n",
            "Epoch 00044: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8432 - val_loss: 2.5168\n",
            "Epoch 45/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8570\n",
            "Epoch 00045: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8570 - val_loss: 2.4905\n",
            "Epoch 46/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8246\n",
            "Epoch 00046: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8288 - val_loss: 2.5672\n",
            "Epoch 1/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 2.7637\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.6739 - val_loss: 2.5621\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.7489\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7540 - val_loss: 2.6765\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5971\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5981 - val_loss: 2.6286\n",
            "Epoch 4/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.5416\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5460 - val_loss: 2.7098\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4559\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4544 - val_loss: 2.6194\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4388\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4388 - val_loss: 2.6370\n",
            "Epoch 7/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3756\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3734 - val_loss: 2.4885\n",
            "Epoch 8/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4206\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4217 - val_loss: 2.6720\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3527\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3510 - val_loss: 2.5261\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2860\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3034 - val_loss: 2.7382\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3113\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3113 - val_loss: 2.6927\n",
            "Epoch 12/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2782\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2845 - val_loss: 2.5342\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2905\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2905 - val_loss: 2.6332\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2608\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2608 - val_loss: 2.5336\n",
            "Epoch 15/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2078\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2179 - val_loss: 2.4815\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2050\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2052 - val_loss: 2.5619\n",
            "Epoch 17/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1990\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2130 - val_loss: 2.6036\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1797\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1772 - val_loss: 2.6121\n",
            "Epoch 19/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1370\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1317 - val_loss: 2.6425\n",
            "Epoch 20/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1335\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1343 - val_loss: 2.8491\n",
            "Epoch 21/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1218\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1205 - val_loss: 2.5943\n",
            "Epoch 22/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1180\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1149 - val_loss: 2.6467\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0273\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0390 - val_loss: 2.5585\n",
            "Epoch 24/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0101\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0179 - val_loss: 2.6326\n",
            "Epoch 25/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9854\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0023 - val_loss: 2.5381\n",
            "Epoch 26/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0222\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0218 - val_loss: 2.6426\n",
            "Epoch 27/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9520\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9620 - val_loss: 2.6872\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9986\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9994 - val_loss: 2.5091\n",
            "Epoch 29/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9805\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9844 - val_loss: 2.5538\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9487\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9487 - val_loss: 2.6456\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9209\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9227 - val_loss: 2.5041\n",
            "Epoch 32/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8966\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8949 - val_loss: 2.6931\n",
            "Epoch 33/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9097\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9082 - val_loss: 2.5679\n",
            "Epoch 34/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9420\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9410 - val_loss: 2.6427\n",
            "Epoch 35/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9106\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9090 - val_loss: 2.5923\n",
            "Epoch 36/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8790\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8786 - val_loss: 2.6590\n",
            "Epoch 37/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8644\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8677 - val_loss: 2.5823\n",
            "Epoch 38/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8840\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8767 - val_loss: 2.5487\n",
            "Epoch 39/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8823\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8743 - val_loss: 2.6821\n",
            "Epoch 40/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8267\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8217 - val_loss: 2.6002\n",
            "Epoch 41/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8824\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8831 - val_loss: 2.5265\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8322\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8322 - val_loss: 2.6318\n",
            "Epoch 43/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8402\n",
            "Epoch 00043: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8388 - val_loss: 2.5465\n",
            "Epoch 44/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8405\n",
            "Epoch 00044: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8390 - val_loss: 2.5850\n",
            "Epoch 45/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8504\n",
            "Epoch 00045: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8518 - val_loss: 2.5495\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.5965\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.5604 - val_loss: 2.4083\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.6925\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6862 - val_loss: 2.4740\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5917\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5917 - val_loss: 2.1785\n",
            "Epoch 4/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4804\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4766 - val_loss: 2.1055\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4753\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4693 - val_loss: 2.1822\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4489\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4460 - val_loss: 2.1213\n",
            "Epoch 7/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3782\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3798 - val_loss: 2.2517\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3664\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3626 - val_loss: 2.1539\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3400\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3400 - val_loss: 2.2103\n",
            "Epoch 10/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3242\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3314 - val_loss: 2.1324\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3279\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3281 - val_loss: 2.3129\n",
            "Epoch 12/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2768\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2815 - val_loss: 2.2873\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2120\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2478 - val_loss: 2.2389\n",
            "Epoch 14/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1683\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1965 - val_loss: 2.4019\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2220\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2174 - val_loss: 2.3048\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1928\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1947 - val_loss: 2.3727\n",
            "Epoch 17/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1267\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1251 - val_loss: 2.5894\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1430\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1442 - val_loss: 2.2528\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0908\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0985 - val_loss: 2.2612\n",
            "Epoch 20/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1233\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1232 - val_loss: 2.3100\n",
            "Epoch 21/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0893\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0963 - val_loss: 2.1669\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0494\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0461 - val_loss: 2.3144\n",
            "Epoch 23/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0251\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0352 - val_loss: 2.3979\n",
            "Epoch 24/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0258\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0315 - val_loss: 2.5064\n",
            "Epoch 25/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0041\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0100 - val_loss: 2.2658\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9759\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9852 - val_loss: 2.3248\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9826\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9814 - val_loss: 2.4605\n",
            "Epoch 28/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9985\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9965 - val_loss: 2.3532\n",
            "Epoch 29/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9853\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9797 - val_loss: 2.1698\n",
            "Epoch 30/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9779\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9798 - val_loss: 2.2164\n",
            "Epoch 31/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9450\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9578 - val_loss: 2.3843\n",
            "Epoch 32/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8919\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9015 - val_loss: 2.2895\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8870\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8870 - val_loss: 2.2771\n",
            "Epoch 34/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8790\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8782 - val_loss: 2.3859\n",
            "Epoch 1/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 2.5767\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.5377 - val_loss: 2.4898\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.6743\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.6675 - val_loss: 2.4562\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5308\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5315 - val_loss: 2.5347\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4744\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4861 - val_loss: 2.1891\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4747\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4753 - val_loss: 2.3762\n",
            "Epoch 6/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4105\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4147 - val_loss: 2.2988\n",
            "Epoch 7/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4178\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4202 - val_loss: 2.2976\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3710\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3710 - val_loss: 2.4733\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3448\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3448 - val_loss: 2.4201\n",
            "Epoch 10/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3079\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3042 - val_loss: 2.3933\n",
            "Epoch 11/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2629\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2636 - val_loss: 2.3090\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3035\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3017 - val_loss: 2.2308\n",
            "Epoch 13/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2230\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2397 - val_loss: 2.4810\n",
            "Epoch 14/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2161\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2183 - val_loss: 2.5286\n",
            "Epoch 15/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1874\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1713 - val_loss: 2.4257\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1550\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1589 - val_loss: 2.6350\n",
            "Epoch 17/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1200\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1304 - val_loss: 2.5136\n",
            "Epoch 18/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1219\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1151 - val_loss: 2.3874\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1082\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1082 - val_loss: 2.5400\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0426\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0426 - val_loss: 2.4480\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0459\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0459 - val_loss: 2.4327\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0864\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0864 - val_loss: 2.6064\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0498\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0498 - val_loss: 2.3904\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0307\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0307 - val_loss: 2.5875\n",
            "Epoch 25/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0077\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0002 - val_loss: 2.6548\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0261\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0259 - val_loss: 2.4724\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9572\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9630 - val_loss: 2.6818\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9411\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9411 - val_loss: 2.4653\n",
            "Epoch 29/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9661\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9659 - val_loss: 2.6671\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9399\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9368 - val_loss: 2.6023\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9492\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9492 - val_loss: 2.4495\n",
            "Epoch 32/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9400\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9431 - val_loss: 2.4755\n",
            "Epoch 33/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9280\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9274 - val_loss: 2.4113\n",
            "Epoch 34/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9204\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9262 - val_loss: 2.5934\n",
            "Epoch 1/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 2.9500\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.9028 - val_loss: 2.4977\n",
            "Epoch 2/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.7457\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7287 - val_loss: 2.5504\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5642\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5630 - val_loss: 2.5196\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5052\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5081 - val_loss: 2.4160\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4679\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4680 - val_loss: 2.3728\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4198\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4091 - val_loss: 2.6770\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4081\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4026 - val_loss: 2.6679\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3348\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3472 - val_loss: 2.6017\n",
            "Epoch 9/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3288\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3299 - val_loss: 2.3594\n",
            "Epoch 10/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3001\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3027 - val_loss: 2.5658\n",
            "Epoch 11/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2423\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2608 - val_loss: 2.4141\n",
            "Epoch 12/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2751\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2751 - val_loss: 2.4641\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2526\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2524 - val_loss: 2.3870\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2241\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2241 - val_loss: 2.5667\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1790\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1762 - val_loss: 2.5267\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1659\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1667 - val_loss: 2.4575\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1379\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1345 - val_loss: 2.3791\n",
            "Epoch 18/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1219\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1207 - val_loss: 2.7062\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0800\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0830 - val_loss: 2.5670\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0781\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0778 - val_loss: 2.4828\n",
            "Epoch 21/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0605\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0551 - val_loss: 2.5589\n",
            "Epoch 22/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0670\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0647 - val_loss: 2.4339\n",
            "Epoch 23/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0085\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0275 - val_loss: 2.5000\n",
            "Epoch 24/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0479\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0474 - val_loss: 2.6579\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9972\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9972 - val_loss: 2.5998\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9870\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9868 - val_loss: 2.4805\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9724\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9709 - val_loss: 2.4251\n",
            "Epoch 28/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9241\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9256 - val_loss: 2.5954\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9670\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9670 - val_loss: 2.5097\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9123\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9123 - val_loss: 2.4168\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9202\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9211 - val_loss: 2.6211\n",
            "Epoch 32/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9059\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9126 - val_loss: 2.5283\n",
            "Epoch 33/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9432\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9434 - val_loss: 2.6665\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8872\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8872 - val_loss: 2.5851\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8861\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8861 - val_loss: 2.5529\n",
            "Epoch 36/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8822\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8869 - val_loss: 2.4768\n",
            "Epoch 37/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8745\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8647 - val_loss: 2.5565\n",
            "Epoch 38/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8122\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8161 - val_loss: 2.6558\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8545\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8545 - val_loss: 2.6385\n",
            "Epoch 1/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 2.9981\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 2.9167 - val_loss: 2.6509\n",
            "Epoch 2/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.7572\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7377 - val_loss: 2.7381\n",
            "Epoch 3/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.5242\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5312 - val_loss: 2.9548\n",
            "Epoch 4/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4791\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4784 - val_loss: 2.4948\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4276\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4261 - val_loss: 2.5256\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4430\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4430 - val_loss: 2.6196\n",
            "Epoch 7/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3513\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3527 - val_loss: 2.3899\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3833\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3688 - val_loss: 2.6458\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3073\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3028 - val_loss: 2.7482\n",
            "Epoch 10/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2732\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2758 - val_loss: 2.5871\n",
            "Epoch 11/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2573\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2515 - val_loss: 2.7057\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2024\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2101 - val_loss: 2.5875\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2440\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2440 - val_loss: 2.5849\n",
            "Epoch 14/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1707\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1713 - val_loss: 2.6669\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1759\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1734 - val_loss: 2.5752\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1544\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1610 - val_loss: 2.5500\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0996\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0996 - val_loss: 2.7283\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1480\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1469 - val_loss: 2.6275\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0836\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0836 - val_loss: 2.6449\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0741\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0714 - val_loss: 2.6106\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0666\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0612 - val_loss: 2.5318\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0344\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0344 - val_loss: 2.7520\n",
            "Epoch 23/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0510\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0494 - val_loss: 2.7032\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9813\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9813 - val_loss: 2.5927\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0025\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0025 - val_loss: 2.4714\n",
            "Epoch 26/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9459\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9509 - val_loss: 2.6903\n",
            "Epoch 27/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9646\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9654 - val_loss: 2.4738\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9201\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9186 - val_loss: 2.5750\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9454\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9454 - val_loss: 2.3625\n",
            "Epoch 30/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9115\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9048 - val_loss: 2.5804\n",
            "Epoch 31/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9171\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9287 - val_loss: 2.5326\n",
            "Epoch 32/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8889\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8866 - val_loss: 2.4906\n",
            "Epoch 33/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8539\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8518 - val_loss: 2.4750\n",
            "Epoch 34/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8541\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8671 - val_loss: 2.4405\n",
            "Epoch 35/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8819\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8804 - val_loss: 2.4525\n",
            "Epoch 36/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8808\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8866 - val_loss: 2.4983\n",
            "Epoch 37/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8247\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8224 - val_loss: 2.4967\n",
            "Epoch 38/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.7969\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8023 - val_loss: 2.5082\n",
            "Epoch 39/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8306\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8266 - val_loss: 2.4912\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8373\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8373 - val_loss: 2.6019\n",
            "Epoch 41/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8319\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8320 - val_loss: 2.5214\n",
            "Epoch 42/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8076\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7957 - val_loss: 2.4635\n",
            "Epoch 43/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.7952\n",
            "Epoch 00043: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7963 - val_loss: 2.6259\n",
            "Epoch 44/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8173\n",
            "Epoch 00044: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8173 - val_loss: 2.6564\n",
            "Epoch 45/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8132\n",
            "Epoch 00045: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8091 - val_loss: 2.4741\n",
            "Epoch 46/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.7722\n",
            "Epoch 00046: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7718 - val_loss: 2.5375\n",
            "Epoch 47/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7523\n",
            "Epoch 00047: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7542 - val_loss: 2.6015\n",
            "Epoch 48/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.7455\n",
            "Epoch 00048: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7476 - val_loss: 2.7752\n",
            "Epoch 49/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7406\n",
            "Epoch 00049: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7406 - val_loss: 2.5493\n",
            "Epoch 50/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7466\n",
            "Epoch 00050: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7466 - val_loss: 2.5520\n",
            "Epoch 51/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7630\n",
            "Epoch 00051: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7655 - val_loss: 2.5689\n",
            "Epoch 52/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.7462\n",
            "Epoch 00052: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7445 - val_loss: 2.4114\n",
            "Epoch 53/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.7388\n",
            "Epoch 00053: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7467 - val_loss: 2.4175\n",
            "Epoch 54/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7512\n",
            "Epoch 00054: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7515 - val_loss: 2.4758\n",
            "Epoch 55/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7787\n",
            "Epoch 00055: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7787 - val_loss: 2.4366\n",
            "Epoch 56/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.7252\n",
            "Epoch 00056: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7138 - val_loss: 2.5317\n",
            "Epoch 57/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7336\n",
            "Epoch 00057: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7355 - val_loss: 2.5062\n",
            "Epoch 58/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.7186\n",
            "Epoch 00058: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7198 - val_loss: 2.5003\n",
            "Epoch 59/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7408\n",
            "Epoch 00059: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7402 - val_loss: 2.4613\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.8752\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 14ms/step - loss: 2.8544 - val_loss: 2.5980\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.6753\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6796 - val_loss: 2.5639\n",
            "Epoch 3/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.6090\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.6135 - val_loss: 2.3849\n",
            "Epoch 4/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.5710\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5669 - val_loss: 2.3058\n",
            "Epoch 5/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4698\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4798 - val_loss: 2.5320\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4531\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4531 - val_loss: 2.3026\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3950\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3950 - val_loss: 2.5605\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4728\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4728 - val_loss: 2.4235\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3291\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3291 - val_loss: 2.3406\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3265\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3118 - val_loss: 2.4349\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3403\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3323 - val_loss: 2.6024\n",
            "Epoch 12/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2624\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2642 - val_loss: 2.5491\n",
            "Epoch 13/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2501\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2582 - val_loss: 2.4867\n",
            "Epoch 14/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2130\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2079 - val_loss: 2.5084\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1803\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1765 - val_loss: 2.5970\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2106\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2127 - val_loss: 2.8869\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1537\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1537 - val_loss: 2.6370\n",
            "Epoch 18/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0959\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1041 - val_loss: 2.5215\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1331\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1307 - val_loss: 2.5626\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1104\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1257 - val_loss: 2.6423\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0947\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0936 - val_loss: 2.7339\n",
            "Epoch 22/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0713\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0653 - val_loss: 2.6358\n",
            "Epoch 23/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0762\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0713 - val_loss: 2.4379\n",
            "Epoch 24/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0391\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0462 - val_loss: 2.7864\n",
            "Epoch 25/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0039\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0082 - val_loss: 2.5553\n",
            "Epoch 26/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0162\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0106 - val_loss: 2.7751\n",
            "Epoch 27/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9841\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9885 - val_loss: 2.6769\n",
            "Epoch 28/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9546\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9670 - val_loss: 2.8566\n",
            "Epoch 29/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9784\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9762 - val_loss: 2.5298\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9412\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9397 - val_loss: 2.6650\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9753\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9753 - val_loss: 2.6537\n",
            "Epoch 32/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9446\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9446 - val_loss: 2.6774\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9273\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9273 - val_loss: 2.7272\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9097\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9097 - val_loss: 2.7035\n",
            "Epoch 35/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9622\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9561 - val_loss: 2.6220\n",
            "Epoch 36/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9049\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8988 - val_loss: 2.6126\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 3.0183\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.9862 - val_loss: 2.4952\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.7970\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.7935 - val_loss: 3.0704\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.6250\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6238 - val_loss: 2.6674\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4988\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4988 - val_loss: 2.4832\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5098\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5110 - val_loss: 2.7187\n",
            "Epoch 6/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4250\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4267 - val_loss: 2.6789\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4183\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4130 - val_loss: 2.4475\n",
            "Epoch 8/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3924\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3996 - val_loss: 2.4971\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3455\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3491 - val_loss: 2.4923\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3541\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3427 - val_loss: 2.5145\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2744\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2849 - val_loss: 2.5850\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2461\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2442 - val_loss: 2.5701\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2537\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2520 - val_loss: 2.6090\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1755\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1755 - val_loss: 2.4003\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1597\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1547 - val_loss: 2.6721\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2049\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1981 - val_loss: 2.6216\n",
            "Epoch 17/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1304\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1381 - val_loss: 2.6193\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0985\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0929 - val_loss: 2.7502\n",
            "Epoch 19/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0837\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0847 - val_loss: 2.4407\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0914\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0901 - val_loss: 2.6605\n",
            "Epoch 21/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0832\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0826 - val_loss: 2.4727\n",
            "Epoch 22/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0490\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0494 - val_loss: 2.5628\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0475\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0530 - val_loss: 2.6168\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0193\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0193 - val_loss: 2.5929\n",
            "Epoch 25/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9744\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9792 - val_loss: 2.8693\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0350\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0434 - val_loss: 2.4816\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9983\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 1.0058 - val_loss: 2.4342\n",
            "Epoch 28/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9448\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9418 - val_loss: 2.5763\n",
            "Epoch 29/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9489\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9357 - val_loss: 2.7064\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9873\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9873 - val_loss: 2.5686\n",
            "Epoch 31/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9488\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9484 - val_loss: 2.6009\n",
            "Epoch 32/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9054\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9054 - val_loss: 2.6249\n",
            "Epoch 33/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9141\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8988 - val_loss: 2.6663\n",
            "Epoch 34/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8876\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8847 - val_loss: 2.6120\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9184\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9184 - val_loss: 2.6642\n",
            "Epoch 36/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9046\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9048 - val_loss: 2.5728\n",
            "Epoch 37/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8795\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8870 - val_loss: 2.6438\n",
            "Epoch 38/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.8675\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8736 - val_loss: 2.6966\n",
            "Epoch 39/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8705\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8705 - val_loss: 2.6350\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8530\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8530 - val_loss: 2.7336\n",
            "Epoch 41/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8615\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8568 - val_loss: 2.5193\n",
            "Epoch 42/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8724\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8724 - val_loss: 2.5723\n",
            "Epoch 43/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8136\n",
            "Epoch 00043: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8392 - val_loss: 2.4908\n",
            "Epoch 44/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8181\n",
            "Epoch 00044: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8213 - val_loss: 2.5393\n",
            "Epoch 1/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 2.7928\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.7438 - val_loss: 2.4587\n",
            "Epoch 2/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.6584\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6765 - val_loss: 2.4791\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5728\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5728 - val_loss: 2.2903\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5653\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5653 - val_loss: 2.2741\n",
            "Epoch 5/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4732\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4601 - val_loss: 2.3865\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4078\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4010 - val_loss: 2.3849\n",
            "Epoch 7/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4001\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4074 - val_loss: 2.6141\n",
            "Epoch 8/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3757\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3745 - val_loss: 2.3062\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2968\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3017 - val_loss: 2.2782\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3139\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3075 - val_loss: 2.2758\n",
            "Epoch 11/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3103\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3120 - val_loss: 2.4911\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2339\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2268 - val_loss: 2.1826\n",
            "Epoch 13/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2321\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2278 - val_loss: 2.4762\n",
            "Epoch 14/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1819\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1787 - val_loss: 2.3534\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1856\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1856 - val_loss: 2.5926\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1677\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1677 - val_loss: 2.3928\n",
            "Epoch 17/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1114\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1207 - val_loss: 2.5603\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1069\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1031 - val_loss: 2.5779\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1027\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1112 - val_loss: 2.3332\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0927\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0927 - val_loss: 2.5768\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0639\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0590 - val_loss: 2.5894\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0106\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0106 - val_loss: 2.4197\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0509\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0447 - val_loss: 2.4125\n",
            "Epoch 24/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0348\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0361 - val_loss: 2.4182\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0111\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0111 - val_loss: 2.4046\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9745\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9782 - val_loss: 2.6334\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9729\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9729 - val_loss: 2.4633\n",
            "Epoch 28/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9783\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9803 - val_loss: 2.6187\n",
            "Epoch 29/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9357\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9391 - val_loss: 2.4541\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9372\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9372 - val_loss: 2.4911\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8960\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8960 - val_loss: 2.5616\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9087\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9062 - val_loss: 2.3467\n",
            "Epoch 33/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8569\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8694 - val_loss: 2.5114\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8914\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8914 - val_loss: 2.6015\n",
            "Epoch 35/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8775\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8786 - val_loss: 2.4743\n",
            "Epoch 36/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8626\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8660 - val_loss: 2.5200\n",
            "Epoch 37/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8823\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8797 - val_loss: 2.5038\n",
            "Epoch 38/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8914\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8937 - val_loss: 2.6213\n",
            "Epoch 39/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8720\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8755 - val_loss: 2.4911\n",
            "Epoch 40/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8646\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8619 - val_loss: 2.5357\n",
            "Epoch 41/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8368\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8392 - val_loss: 2.4463\n",
            "Epoch 42/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8246\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8253 - val_loss: 2.4835\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 2.3301\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 15ms/step - loss: 2.3301 - val_loss: 2.4646\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.6325\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6307 - val_loss: 2.5426\n",
            "Epoch 3/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5423\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5568 - val_loss: 2.4288\n",
            "Epoch 4/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.5026\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4863 - val_loss: 2.3273\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4812\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4766 - val_loss: 2.3943\n",
            "Epoch 6/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4472\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4447 - val_loss: 2.5997\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3975\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4012 - val_loss: 2.4119\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3787\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3708 - val_loss: 2.5658\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3481\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3475 - val_loss: 2.6768\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3408\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3408 - val_loss: 2.5294\n",
            "Epoch 11/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2856\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2823 - val_loss: 2.3768\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3073\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3095 - val_loss: 2.5912\n",
            "Epoch 13/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2411\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2472 - val_loss: 2.6460\n",
            "Epoch 14/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2548\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2526 - val_loss: 2.4085\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2239\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2239 - val_loss: 2.4242\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1902\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1893 - val_loss: 2.4741\n",
            "Epoch 17/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1563\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1577 - val_loss: 2.6703\n",
            "Epoch 18/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1216\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1188 - val_loss: 2.6424\n",
            "Epoch 19/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1111\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1163 - val_loss: 2.5848\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0978\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1028 - val_loss: 2.7222\n",
            "Epoch 21/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1329\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1352 - val_loss: 2.5894\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0614\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0614 - val_loss: 2.6806\n",
            "Epoch 23/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0473\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0468 - val_loss: 2.6189\n",
            "Epoch 24/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0104\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0171 - val_loss: 2.6865\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0101\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0101 - val_loss: 2.5543\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0139\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0180 - val_loss: 2.5399\n",
            "Epoch 27/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9462\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9531 - val_loss: 2.4481\n",
            "Epoch 28/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9839\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9760 - val_loss: 2.5320\n",
            "Epoch 29/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9445\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9441 - val_loss: 2.5889\n",
            "Epoch 30/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9390\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9458 - val_loss: 2.5527\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9259\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9259 - val_loss: 2.5323\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9090\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9087 - val_loss: 2.6391\n",
            "Epoch 33/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9237\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9237 - val_loss: 2.5699\n",
            "Epoch 34/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8946\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8998 - val_loss: 2.5430\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.8708\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.8418 - val_loss: 2.3854\n",
            "Epoch 2/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.7803\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7816 - val_loss: 2.3240\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.6081\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6081 - val_loss: 2.5581\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5032\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4923 - val_loss: 2.4832\n",
            "Epoch 5/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4878\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4853 - val_loss: 2.7043\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3955\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3955 - val_loss: 2.6163\n",
            "Epoch 7/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3783\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4012 - val_loss: 2.5287\n",
            "Epoch 8/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3868\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3940 - val_loss: 2.4281\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3320\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3327 - val_loss: 2.6408\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3191\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3198 - val_loss: 2.6422\n",
            "Epoch 11/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3238\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3040 - val_loss: 2.4997\n",
            "Epoch 12/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2833\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2777 - val_loss: 2.6433\n",
            "Epoch 13/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2284\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2347 - val_loss: 2.4911\n",
            "Epoch 14/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2177\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2220 - val_loss: 2.4665\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2035\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2035 - val_loss: 2.7326\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1773\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1773 - val_loss: 2.6599\n",
            "Epoch 17/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1335\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1409 - val_loss: 2.5126\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1497\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1499 - val_loss: 2.6093\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1250\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1261 - val_loss: 2.5648\n",
            "Epoch 20/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0920\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0950 - val_loss: 2.6408\n",
            "Epoch 21/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0692\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0642 - val_loss: 2.6950\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0748\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0765 - val_loss: 2.6777\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0616\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0616 - val_loss: 2.5113\n",
            "Epoch 24/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0294\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0437 - val_loss: 2.5769\n",
            "Epoch 25/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0557\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0515 - val_loss: 2.6252\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0165\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0313 - val_loss: 2.5025\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9818\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9778 - val_loss: 2.6753\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9776\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9747 - val_loss: 2.5061\n",
            "Epoch 29/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9729\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9755 - val_loss: 2.6760\n",
            "Epoch 30/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9903\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9919 - val_loss: 2.5606\n",
            "Epoch 31/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9424\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9429 - val_loss: 2.6898\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9249\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9220 - val_loss: 2.5699\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.8697\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.8366 - val_loss: 2.4666\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.8051\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.8034 - val_loss: 2.4554\n",
            "Epoch 3/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5721\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5801 - val_loss: 2.9591\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5751\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5693 - val_loss: 2.6143\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4726\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4726 - val_loss: 2.5907\n",
            "Epoch 6/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4086\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4380 - val_loss: 2.9098\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4072\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4057 - val_loss: 2.6144\n",
            "Epoch 8/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3497\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3529 - val_loss: 2.7895\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3715\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3739 - val_loss: 2.5212\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3627\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3627 - val_loss: 2.6770\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3141\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3262 - val_loss: 2.8502\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3221\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3247 - val_loss: 2.4999\n",
            "Epoch 13/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2974\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2939 - val_loss: 2.6337\n",
            "Epoch 14/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2517\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2535 - val_loss: 2.6308\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2439\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2439 - val_loss: 2.6183\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2040\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2018 - val_loss: 2.6102\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1755\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1791 - val_loss: 2.8356\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1641\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1641 - val_loss: 2.7537\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1218\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1225 - val_loss: 2.7797\n",
            "Epoch 20/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0540\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0578 - val_loss: 2.6281\n",
            "Epoch 21/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0876\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0956 - val_loss: 2.7783\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1004\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0954 - val_loss: 2.7994\n",
            "Epoch 23/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0751\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0759 - val_loss: 2.7739\n",
            "Epoch 24/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0242\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0322 - val_loss: 2.8263\n",
            "Epoch 25/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0075\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0038 - val_loss: 2.7639\n",
            "Epoch 26/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9900\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9913 - val_loss: 2.6285\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9882\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0036 - val_loss: 2.7665\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0261\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0332 - val_loss: 2.6485\n",
            "Epoch 29/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9731\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9632 - val_loss: 2.7275\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9557\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9557 - val_loss: 2.4568\n",
            "Epoch 31/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9809\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9830 - val_loss: 2.7603\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9225\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9311 - val_loss: 2.7561\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.8479\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.8252 - val_loss: 2.0206\n",
            "Epoch 2/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.7073\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.6898 - val_loss: 2.2433\n",
            "Epoch 3/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.5919\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.6057 - val_loss: 2.3099\n",
            "Epoch 4/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.5415\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5295 - val_loss: 2.3678\n",
            "Epoch 5/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4688\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4772 - val_loss: 2.1718\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4976\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5045 - val_loss: 2.2102\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4998\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4998 - val_loss: 2.1508\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3928\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3894 - val_loss: 2.1990\n",
            "Epoch 9/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.3718\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3523 - val_loss: 2.1554\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3508\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3611 - val_loss: 2.2535\n",
            "Epoch 11/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3126\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3132 - val_loss: 2.1941\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2936\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2918 - val_loss: 2.3247\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2378\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2378 - val_loss: 2.1877\n",
            "Epoch 14/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2368\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2349 - val_loss: 2.3269\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2277\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2213 - val_loss: 2.2096\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1873\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1873 - val_loss: 2.3421\n",
            "Epoch 17/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1696\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1526 - val_loss: 2.2458\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2144\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2179 - val_loss: 2.3833\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1458\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1440 - val_loss: 2.1321\n",
            "Epoch 20/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1091\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1183 - val_loss: 2.3674\n",
            "Epoch 21/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1763\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1605 - val_loss: 2.3941\n",
            "Epoch 22/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0639\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0688 - val_loss: 2.2558\n",
            "Epoch 23/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0440\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0474 - val_loss: 2.4985\n",
            "Epoch 24/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0654\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0665 - val_loss: 2.3330\n",
            "Epoch 25/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0343\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0341 - val_loss: 2.4064\n",
            "Epoch 26/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0701\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0799 - val_loss: 2.4414\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9981\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9979 - val_loss: 2.1703\n",
            "Epoch 28/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0374\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0401 - val_loss: 2.3982\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0126\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0126 - val_loss: 2.1269\n",
            "Epoch 30/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9685\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9700 - val_loss: 2.3268\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9480\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9531 - val_loss: 2.2340\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 3.0333\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 3.0209 - val_loss: 2.4863\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.7291\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7228 - val_loss: 2.6225\n",
            "Epoch 3/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.5547\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5574 - val_loss: 2.6261\n",
            "Epoch 4/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.5682\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5659 - val_loss: 2.6451\n",
            "Epoch 5/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.5089\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4934 - val_loss: 2.4499\n",
            "Epoch 6/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4458\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4345 - val_loss: 2.3488\n",
            "Epoch 7/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4378\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4447 - val_loss: 2.2523\n",
            "Epoch 8/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4019\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4187 - val_loss: 2.1867\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3418\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3418 - val_loss: 2.5100\n",
            "Epoch 10/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3192\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3161 - val_loss: 2.4780\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2797\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2797 - val_loss: 2.3221\n",
            "Epoch 12/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2626\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2702 - val_loss: 2.4982\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2298\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2298 - val_loss: 2.2832\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2568\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2430 - val_loss: 2.3031\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1568\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1542 - val_loss: 2.4618\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1846\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1854 - val_loss: 2.2933\n",
            "Epoch 17/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1481\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1428 - val_loss: 2.3128\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1008\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1093 - val_loss: 2.5253\n",
            "Epoch 19/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1077\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1077 - val_loss: 2.3598\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1174\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1190 - val_loss: 2.5865\n",
            "Epoch 21/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0371\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0438 - val_loss: 2.4736\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0665\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0665 - val_loss: 2.6676\n",
            "Epoch 23/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0235\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0276 - val_loss: 2.4189\n",
            "Epoch 24/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0387\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0178 - val_loss: 2.5141\n",
            "Epoch 25/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0059\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0057 - val_loss: 2.4586\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9748\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9910 - val_loss: 2.5199\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9824\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9837 - val_loss: 2.4953\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9721\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9721 - val_loss: 2.5215\n",
            "Epoch 29/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9927\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9988 - val_loss: 2.4297\n",
            "Epoch 30/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9483\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9482 - val_loss: 2.4482\n",
            "Epoch 31/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9542\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9528 - val_loss: 2.5088\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9602\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9541 - val_loss: 2.5207\n",
            "Epoch 33/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9176\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9145 - val_loss: 2.3681\n",
            "Epoch 34/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9263\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9277 - val_loss: 2.4793\n",
            "Epoch 35/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9297\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9273 - val_loss: 2.4435\n",
            "Epoch 36/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8828\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8829 - val_loss: 2.6109\n",
            "Epoch 37/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.8874\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8866 - val_loss: 2.5068\n",
            "Epoch 38/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8802\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8820 - val_loss: 2.4621\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.5863\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.5641 - val_loss: 2.6282\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.6269\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6269 - val_loss: 2.3759\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5614\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5580 - val_loss: 2.3782\n",
            "Epoch 4/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5096\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5126 - val_loss: 2.2921\n",
            "Epoch 5/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4541\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4501 - val_loss: 2.1866\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4280\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4248 - val_loss: 2.2610\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3877\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3828 - val_loss: 2.2369\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3663\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3705 - val_loss: 2.4213\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2983\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3096 - val_loss: 2.2777\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3389\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3510 - val_loss: 2.5537\n",
            "Epoch 11/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2778\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2808 - val_loss: 2.3778\n",
            "Epoch 12/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2430\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2280 - val_loss: 2.4539\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2175\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2250 - val_loss: 2.3934\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1823\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1772 - val_loss: 2.6799\n",
            "Epoch 15/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1394\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1431 - val_loss: 2.3121\n",
            "Epoch 16/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1366\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1404 - val_loss: 2.5863\n",
            "Epoch 17/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1078\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1147 - val_loss: 2.5370\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1123\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1123 - val_loss: 2.4392\n",
            "Epoch 19/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1088\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1063 - val_loss: 2.4018\n",
            "Epoch 20/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0914\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.0918 - val_loss: 2.5376\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0614\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0565 - val_loss: 2.4309\n",
            "Epoch 22/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0260\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0275 - val_loss: 2.5098\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0346\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0363 - val_loss: 2.6565\n",
            "Epoch 24/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9854\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9816 - val_loss: 2.4353\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9977\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9977 - val_loss: 2.4931\n",
            "Epoch 26/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9515\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9561 - val_loss: 2.6418\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9624\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9640 - val_loss: 2.6627\n",
            "Epoch 28/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9495\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9541 - val_loss: 2.7848\n",
            "Epoch 29/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9516\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9534 - val_loss: 2.5961\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9339\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9319 - val_loss: 2.5627\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9323\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9414 - val_loss: 2.5955\n",
            "Epoch 32/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9125\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9149 - val_loss: 2.5158\n",
            "Epoch 33/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9651\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9585 - val_loss: 2.5772\n",
            "Epoch 34/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8987\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9020 - val_loss: 2.4642\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8758\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8758 - val_loss: 2.7269\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.6205\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.5936 - val_loss: 2.1775\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.6489\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6489 - val_loss: 2.4183\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5151\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5151 - val_loss: 2.2585\n",
            "Epoch 4/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4205\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4432 - val_loss: 2.2952\n",
            "Epoch 5/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4581\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4703 - val_loss: 2.4159\n",
            "Epoch 6/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4134\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4071 - val_loss: 2.2655\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4525\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4462 - val_loss: 2.3633\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3994\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4001 - val_loss: 2.4893\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3654\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3724 - val_loss: 2.5717\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3092\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3204 - val_loss: 2.2239\n",
            "Epoch 11/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2461\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2659 - val_loss: 2.3486\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2283\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2286 - val_loss: 2.3501\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2199\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2199 - val_loss: 2.2782\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2669\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2686 - val_loss: 2.4122\n",
            "Epoch 15/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1517\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1475 - val_loss: 2.4289\n",
            "Epoch 16/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1431\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1451 - val_loss: 2.3725\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1580\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1555 - val_loss: 2.3278\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1388\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1318 - val_loss: 2.3185\n",
            "Epoch 19/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1143\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1200 - val_loss: 2.4129\n",
            "Epoch 20/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0661\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0694 - val_loss: 2.3952\n",
            "Epoch 21/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0329\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0479 - val_loss: 2.3375\n",
            "Epoch 22/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0429\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0496 - val_loss: 2.4205\n",
            "Epoch 23/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0436\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0348 - val_loss: 2.3849\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0142\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0142 - val_loss: 2.3947\n",
            "Epoch 25/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9706\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9801 - val_loss: 2.3867\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0057\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0056 - val_loss: 2.4660\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9454\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9518 - val_loss: 2.3839\n",
            "Epoch 28/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9413\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9452 - val_loss: 2.3924\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9322\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9322 - val_loss: 2.4303\n",
            "Epoch 30/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9135\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9163 - val_loss: 2.4527\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9324\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9324 - val_loss: 2.5310\n",
            "Epoch 1/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 2.6082\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 14ms/step - loss: 2.5977 - val_loss: 2.7021\n",
            "Epoch 2/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.6842\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.6796 - val_loss: 2.5629\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5869\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5838 - val_loss: 2.5669\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4796\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4753 - val_loss: 2.7225\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4261\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4368 - val_loss: 2.4726\n",
            "Epoch 6/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4147\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4150 - val_loss: 2.7236\n",
            "Epoch 7/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4617\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4605 - val_loss: 2.5414\n",
            "Epoch 8/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4039\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4051 - val_loss: 2.5410\n",
            "Epoch 9/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.3602\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3772 - val_loss: 2.5495\n",
            "Epoch 10/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2971\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2965 - val_loss: 2.6489\n",
            "Epoch 11/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2972\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2999 - val_loss: 2.5441\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2817\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2843 - val_loss: 2.6064\n",
            "Epoch 13/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2461\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2502 - val_loss: 2.7808\n",
            "Epoch 14/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2098\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2246 - val_loss: 2.6366\n",
            "Epoch 15/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1621\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1768 - val_loss: 2.5616\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2161\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2143 - val_loss: 2.5062\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1248\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1244 - val_loss: 2.6057\n",
            "Epoch 18/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1504\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1484 - val_loss: 2.3499\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1243\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1174 - val_loss: 2.5570\n",
            "Epoch 20/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0877\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0966 - val_loss: 2.7027\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0731\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0717 - val_loss: 2.6339\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0336\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0291 - val_loss: 2.5829\n",
            "Epoch 23/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9780\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9716 - val_loss: 2.4956\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0210\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0210 - val_loss: 2.5594\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0161\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0161 - val_loss: 2.4905\n",
            "Epoch 26/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9751\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9749 - val_loss: 2.5852\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9423\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9401 - val_loss: 2.6000\n",
            "Epoch 28/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9818\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9746 - val_loss: 2.6820\n",
            "Epoch 29/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9310\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9226 - val_loss: 2.6198\n",
            "Epoch 30/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9185\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9218 - val_loss: 2.7488\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9018\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9084 - val_loss: 2.5779\n",
            "Epoch 32/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9091\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9084 - val_loss: 2.5944\n",
            "Epoch 33/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9050\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8985 - val_loss: 2.6048\n",
            "Epoch 34/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9595\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9602 - val_loss: 2.7148\n",
            "Epoch 35/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8863\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8944 - val_loss: 2.5209\n",
            "Epoch 36/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8337\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8334 - val_loss: 2.6308\n",
            "Epoch 37/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8612\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8612 - val_loss: 2.6646\n",
            "Epoch 38/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9022\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9043 - val_loss: 2.5732\n",
            "Epoch 39/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8595\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8651 - val_loss: 2.7180\n",
            "Epoch 40/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8683\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8665 - val_loss: 2.5066\n",
            "Epoch 41/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8392\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8422 - val_loss: 2.5544\n",
            "Epoch 42/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8381\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8347 - val_loss: 2.5767\n",
            "Epoch 43/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8348\n",
            "Epoch 00043: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8344 - val_loss: 2.6350\n",
            "Epoch 44/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8244\n",
            "Epoch 00044: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8204 - val_loss: 2.5110\n",
            "Epoch 45/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8105\n",
            "Epoch 00045: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7990 - val_loss: 2.6791\n",
            "Epoch 46/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.7842\n",
            "Epoch 00046: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7895 - val_loss: 2.6050\n",
            "Epoch 47/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8072\n",
            "Epoch 00047: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8033 - val_loss: 2.5645\n",
            "Epoch 48/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7487\n",
            "Epoch 00048: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7487 - val_loss: 2.5326\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.9066\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.8815 - val_loss: 2.3804\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.7439\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7439 - val_loss: 2.1830\n",
            "Epoch 3/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5937\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5916 - val_loss: 2.1369\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5053\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5133 - val_loss: 2.4356\n",
            "Epoch 5/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4937\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4897 - val_loss: 2.7755\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4210\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4210 - val_loss: 2.1325\n",
            "Epoch 7/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4225\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4161 - val_loss: 2.4287\n",
            "Epoch 8/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4089\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4113 - val_loss: 2.4670\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3589\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3668 - val_loss: 2.3141\n",
            "Epoch 10/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3487\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3529 - val_loss: 2.3743\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2959\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2959 - val_loss: 2.5406\n",
            "Epoch 12/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2555\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2603 - val_loss: 2.2479\n",
            "Epoch 13/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2312\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2291 - val_loss: 2.6535\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1970\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2043 - val_loss: 2.3035\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2093\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2089 - val_loss: 2.3137\n",
            "Epoch 16/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1372\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1475 - val_loss: 2.5283\n",
            "Epoch 17/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1392\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1453 - val_loss: 2.5687\n",
            "Epoch 18/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1181\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1256 - val_loss: 2.3700\n",
            "Epoch 19/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0990\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1058 - val_loss: 2.4812\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0603\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.0603 - val_loss: 2.4632\n",
            "Epoch 21/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0628\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0778 - val_loss: 2.4473\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0440\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0459 - val_loss: 2.6811\n",
            "Epoch 23/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0279\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0251 - val_loss: 2.4156\n",
            "Epoch 24/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0450\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.0450 - val_loss: 2.7137\n",
            "Epoch 25/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0055\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0130 - val_loss: 2.4992\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9721\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.9703 - val_loss: 2.5660\n",
            "Epoch 27/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9815\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.9831 - val_loss: 2.5161\n",
            "Epoch 28/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9172\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9199 - val_loss: 2.4339\n",
            "Epoch 29/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9687\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9678 - val_loss: 2.6203\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9006\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9006 - val_loss: 2.5254\n",
            "Epoch 31/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9414\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9415 - val_loss: 2.5776\n",
            "Epoch 32/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9173\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9205 - val_loss: 2.4121\n",
            "Epoch 33/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8895\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8936 - val_loss: 2.5892\n",
            "Epoch 34/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9353\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9353 - val_loss: 2.5255\n",
            "Epoch 35/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8787\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8813 - val_loss: 2.6429\n",
            "Epoch 36/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8635\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8749 - val_loss: 2.4157\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.7999\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.7714 - val_loss: 2.3141\n",
            "Epoch 2/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.6750\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6877 - val_loss: 2.2319\n",
            "Epoch 3/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.5204\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5143 - val_loss: 2.2088\n",
            "Epoch 4/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4418\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4301 - val_loss: 2.3227\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3808\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3808 - val_loss: 2.3312\n",
            "Epoch 6/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4339\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4523 - val_loss: 2.2992\n",
            "Epoch 7/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3963\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4031 - val_loss: 2.3257\n",
            "Epoch 8/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3465\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3419 - val_loss: 2.4442\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3254\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3228 - val_loss: 2.3292\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2982\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3035 - val_loss: 2.5012\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2260\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2298 - val_loss: 2.3229\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2663\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2667 - val_loss: 2.5539\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1571\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1603 - val_loss: 2.2852\n",
            "Epoch 14/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1949\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1894 - val_loss: 2.4682\n",
            "Epoch 15/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1596\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1504 - val_loss: 2.4951\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1735\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1735 - val_loss: 2.5344\n",
            "Epoch 17/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1358\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1529 - val_loss: 2.4086\n",
            "Epoch 18/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0846\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0940 - val_loss: 2.4401\n",
            "Epoch 19/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0710\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 1.0786 - val_loss: 2.5686\n",
            "Epoch 20/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0632\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0674 - val_loss: 2.4655\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0418\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0417 - val_loss: 2.4024\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0162\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0230 - val_loss: 2.5126\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0638\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0632 - val_loss: 2.4478\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0099\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0099 - val_loss: 2.3550\n",
            "Epoch 25/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0177\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0146 - val_loss: 2.4058\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9344\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9485 - val_loss: 2.5807\n",
            "Epoch 27/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9580\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9564 - val_loss: 2.5484\n",
            "Epoch 28/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9500\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9378 - val_loss: 2.3661\n",
            "Epoch 29/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9374\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9363 - val_loss: 2.5477\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9356\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9356 - val_loss: 2.5084\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9372\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9372 - val_loss: 2.3910\n",
            "Epoch 32/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8754\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8848 - val_loss: 2.3858\n",
            "Epoch 33/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8496\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8563 - val_loss: 2.4481\n",
            "Epoch 1/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 3.0222\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.9720 - val_loss: 2.5530\n",
            "Epoch 2/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.8397\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.8115 - val_loss: 2.1794\n",
            "Epoch 3/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.5698\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5564 - val_loss: 2.3395\n",
            "Epoch 4/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.5030\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5076 - val_loss: 2.3490\n",
            "Epoch 5/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4671\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4709 - val_loss: 2.2946\n",
            "Epoch 6/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4162\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4168 - val_loss: 2.4176\n",
            "Epoch 7/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4037\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4088 - val_loss: 2.2653\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3818\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3651 - val_loss: 2.2873\n",
            "Epoch 9/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.3372\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3408 - val_loss: 2.2658\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3287\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3235 - val_loss: 2.3178\n",
            "Epoch 11/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3286\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3380 - val_loss: 2.2420\n",
            "Epoch 12/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3072\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3082 - val_loss: 2.5169\n",
            "Epoch 13/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3050\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2999 - val_loss: 2.3285\n",
            "Epoch 14/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1793\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2061 - val_loss: 2.3287\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2350\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2350 - val_loss: 2.3657\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2194\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2177 - val_loss: 2.3950\n",
            "Epoch 17/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1541\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 1.1569 - val_loss: 2.2980\n",
            "Epoch 18/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1635\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1655 - val_loss: 2.3265\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1175\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1145 - val_loss: 2.3279\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1448\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1348 - val_loss: 2.5315\n",
            "Epoch 21/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1189\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1103 - val_loss: 2.4610\n",
            "Epoch 22/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0694\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0588 - val_loss: 2.5549\n",
            "Epoch 23/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0605\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0649 - val_loss: 2.4560\n",
            "Epoch 24/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0238\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0163 - val_loss: 2.5933\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0029\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0029 - val_loss: 2.3704\n",
            "Epoch 26/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0099\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0099 - val_loss: 2.5444\n",
            "Epoch 27/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0074\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0015 - val_loss: 2.4009\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9886\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9886 - val_loss: 2.4406\n",
            "Epoch 29/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9723\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9751 - val_loss: 2.5686\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9346\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9346 - val_loss: 2.5042\n",
            "Epoch 31/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9118\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9232 - val_loss: 2.6182\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9728\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9722 - val_loss: 2.6052\n",
            "Epoch 1/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 2.9452\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 14ms/step - loss: 2.9020 - val_loss: 2.6379\n",
            "Epoch 2/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.7070\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.7069 - val_loss: 2.5054\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5425\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5425 - val_loss: 2.5726\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4675\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4753 - val_loss: 2.4475\n",
            "Epoch 5/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4242\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4338 - val_loss: 2.4272\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4116\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4176 - val_loss: 2.6160\n",
            "Epoch 7/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3604\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3524 - val_loss: 2.5682\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3032\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3128 - val_loss: 2.4291\n",
            "Epoch 9/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2892\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2905 - val_loss: 2.5174\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2876\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.2900 - val_loss: 2.4500\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2091\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2091 - val_loss: 2.3902\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2534\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2480 - val_loss: 2.3581\n",
            "Epoch 13/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2176\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2156 - val_loss: 2.3462\n",
            "Epoch 14/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1601\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1619 - val_loss: 2.3335\n",
            "Epoch 15/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1491\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1474 - val_loss: 2.3261\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1581\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1549 - val_loss: 2.3640\n",
            "Epoch 17/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1433\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1433 - val_loss: 2.3626\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1014\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1076 - val_loss: 2.4192\n",
            "Epoch 19/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0552\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0660 - val_loss: 2.4696\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0526\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0526 - val_loss: 2.4868\n",
            "Epoch 21/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0416\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0416 - val_loss: 2.4721\n",
            "Epoch 22/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0226\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0207 - val_loss: 2.5374\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0249\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0249 - val_loss: 2.5053\n",
            "Epoch 24/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9773\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9743 - val_loss: 2.4621\n",
            "Epoch 25/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9628\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9625 - val_loss: 2.4134\n",
            "Epoch 26/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9862\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9902 - val_loss: 2.5815\n",
            "Epoch 27/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9727\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9621 - val_loss: 2.3558\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9371\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9355 - val_loss: 2.3258\n",
            "Epoch 29/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9419\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9357 - val_loss: 2.5178\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9301\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9279 - val_loss: 2.5337\n",
            "Epoch 31/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9266\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9120 - val_loss: 2.4605\n",
            "Epoch 32/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8977\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8892 - val_loss: 2.4414\n",
            "Epoch 33/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9314\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9262 - val_loss: 2.4403\n",
            "Epoch 34/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9066\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9053 - val_loss: 2.4110\n",
            "Epoch 35/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8373\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8496 - val_loss: 2.5382\n",
            "Epoch 36/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8547\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8665 - val_loss: 2.5317\n",
            "Epoch 37/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8327\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8313 - val_loss: 2.4953\n",
            "Epoch 38/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8604\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8604 - val_loss: 2.5835\n",
            "Epoch 39/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8363\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8380 - val_loss: 2.3478\n",
            "Epoch 40/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8158\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8158 - val_loss: 2.4318\n",
            "Epoch 41/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8275\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8279 - val_loss: 2.4984\n",
            "Epoch 42/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.8201\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8283 - val_loss: 2.3578\n",
            "Epoch 43/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8253\n",
            "Epoch 00043: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8211 - val_loss: 2.4527\n",
            "Epoch 44/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8112\n",
            "Epoch 00044: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8095 - val_loss: 2.4597\n",
            "Epoch 45/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8043\n",
            "Epoch 00045: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8043 - val_loss: 2.4855\n",
            "Epoch 46/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8234\n",
            "Epoch 00046: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8235 - val_loss: 2.3742\n",
            "Epoch 47/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.7965\n",
            "Epoch 00047: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7931 - val_loss: 2.3963\n",
            "Epoch 48/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7977\n",
            "Epoch 00048: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7970 - val_loss: 2.4325\n",
            "Epoch 49/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.7796\n",
            "Epoch 00049: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.7878 - val_loss: 2.5290\n",
            "Epoch 50/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.7421\n",
            "Epoch 00050: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7463 - val_loss: 2.4423\n",
            "Epoch 51/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.7793\n",
            "Epoch 00051: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7705 - val_loss: 2.4262\n",
            "Epoch 52/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.7403\n",
            "Epoch 00052: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7414 - val_loss: 2.4213\n",
            "Epoch 53/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.7670\n",
            "Epoch 00053: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7700 - val_loss: 2.4582\n",
            "Epoch 54/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.7275\n",
            "Epoch 00054: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.7215 - val_loss: 2.3781\n",
            "Epoch 55/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.7685\n",
            "Epoch 00055: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7710 - val_loss: 2.4911\n",
            "Epoch 56/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.7572\n",
            "Epoch 00056: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.7560 - val_loss: 2.4082\n",
            "Epoch 57/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7288\n",
            "Epoch 00057: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7288 - val_loss: 2.3470\n",
            "Epoch 58/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.7535\n",
            "Epoch 00058: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.7535 - val_loss: 2.4232\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 3.1307\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 3.1307 - val_loss: 2.3297\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.9509\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.9303 - val_loss: 2.3069\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.6105\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6105 - val_loss: 2.7859\n",
            "Epoch 4/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.5093\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5063 - val_loss: 2.6808\n",
            "Epoch 5/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4703\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4743 - val_loss: 2.6587\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4677\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4709 - val_loss: 2.8489\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4300\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4364 - val_loss: 2.4417\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4192\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4192 - val_loss: 2.5527\n",
            "Epoch 9/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4153\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4207 - val_loss: 2.4190\n",
            "Epoch 10/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3474\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3531 - val_loss: 2.4821\n",
            "Epoch 11/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3091\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3123 - val_loss: 2.6699\n",
            "Epoch 12/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3150\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3152 - val_loss: 2.4586\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2721\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2721 - val_loss: 2.7143\n",
            "Epoch 14/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2486\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2733 - val_loss: 2.5764\n",
            "Epoch 15/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2318\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2416 - val_loss: 2.4673\n",
            "Epoch 16/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2352\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2336 - val_loss: 2.5696\n",
            "Epoch 17/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2350\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2367 - val_loss: 2.6865\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1578\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1578 - val_loss: 2.4490\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1693\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1727 - val_loss: 2.5788\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1411\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1495 - val_loss: 2.5682\n",
            "Epoch 21/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2047\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1993 - val_loss: 2.4754\n",
            "Epoch 22/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1147\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1128 - val_loss: 2.5698\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1066\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1064 - val_loss: 2.4964\n",
            "Epoch 24/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0872\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0784 - val_loss: 2.7167\n",
            "Epoch 25/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0622\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0622 - val_loss: 2.6739\n",
            "Epoch 26/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0799\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0827 - val_loss: 2.5081\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9915\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9914 - val_loss: 2.5477\n",
            "Epoch 28/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0047\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9963 - val_loss: 2.4803\n",
            "Epoch 29/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0407\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0360 - val_loss: 2.4830\n",
            "Epoch 30/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0103\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0103 - val_loss: 2.5135\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9495\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9495 - val_loss: 2.5671\n",
            "Epoch 32/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9417\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9455 - val_loss: 2.6978\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 2.7685\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 16ms/step - loss: 2.7685 - val_loss: 2.4493\n",
            "Epoch 2/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.7375\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.7275 - val_loss: 2.3298\n",
            "Epoch 3/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.6451\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6499 - val_loss: 2.8225\n",
            "Epoch 4/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4986\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4935 - val_loss: 2.8491\n",
            "Epoch 5/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4873\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4873 - val_loss: 2.5923\n",
            "Epoch 6/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4528\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4730 - val_loss: 2.5033\n",
            "Epoch 7/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4491\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4491 - val_loss: 2.5528\n",
            "Epoch 8/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3826\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3741 - val_loss: 2.5956\n",
            "Epoch 9/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3493\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3745 - val_loss: 2.4293\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3506\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3481 - val_loss: 2.4656\n",
            "Epoch 11/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3066\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2907 - val_loss: 2.4614\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3291\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3247 - val_loss: 2.5526\n",
            "Epoch 13/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2508\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.2678 - val_loss: 2.5217\n",
            "Epoch 14/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2371\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2370 - val_loss: 2.4651\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2295\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2271 - val_loss: 2.3647\n",
            "Epoch 16/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2171\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2171 - val_loss: 2.7064\n",
            "Epoch 17/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1875\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1872 - val_loss: 2.6109\n",
            "Epoch 18/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1634\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1591 - val_loss: 2.7352\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1446\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1433 - val_loss: 2.5749\n",
            "Epoch 20/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1015\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0982 - val_loss: 2.4767\n",
            "Epoch 21/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0571\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0557 - val_loss: 2.4779\n",
            "Epoch 22/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1192\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1156 - val_loss: 2.6087\n",
            "Epoch 23/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0442\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0443 - val_loss: 2.3862\n",
            "Epoch 24/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0340\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0531 - val_loss: 2.4822\n",
            "Epoch 25/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0273\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0255 - val_loss: 2.6439\n",
            "Epoch 26/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0352\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0257 - val_loss: 2.6159\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9358\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9351 - val_loss: 2.6506\n",
            "Epoch 28/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9657\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9662 - val_loss: 2.6605\n",
            "Epoch 29/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9923\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9892 - val_loss: 2.4788\n",
            "Epoch 30/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9700\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9691 - val_loss: 2.4672\n",
            "Epoch 31/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9589\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9721 - val_loss: 2.6703\n",
            "Epoch 32/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9064\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9039 - val_loss: 2.5399\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.3480\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.3188 - val_loss: 2.4469\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.6385\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6352 - val_loss: 2.4562\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.5033\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5009 - val_loss: 2.8666\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5068\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5068 - val_loss: 2.5635\n",
            "Epoch 5/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4737\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4788 - val_loss: 2.6231\n",
            "Epoch 6/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3999\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3960 - val_loss: 2.4682\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3630\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3723 - val_loss: 2.2355\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3509\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3509 - val_loss: 2.6038\n",
            "Epoch 9/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3035\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3035 - val_loss: 2.5717\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2888\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3082 - val_loss: 2.7934\n",
            "Epoch 11/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2362\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.2470 - val_loss: 2.4292\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2125\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2105 - val_loss: 2.4333\n",
            "Epoch 13/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2257\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2256 - val_loss: 2.4116\n",
            "Epoch 14/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1601\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1629 - val_loss: 2.5061\n",
            "Epoch 15/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1485\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1522 - val_loss: 2.6129\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1189\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1171 - val_loss: 2.6791\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1358\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1314 - val_loss: 2.6651\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1130\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1106 - val_loss: 2.6846\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1076\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1070 - val_loss: 2.5879\n",
            "Epoch 20/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0435\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0544 - val_loss: 2.5465\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0179\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0319 - val_loss: 2.6135\n",
            "Epoch 22/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9939\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9972 - val_loss: 2.4752\n",
            "Epoch 23/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0245\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0137 - val_loss: 2.6832\n",
            "Epoch 24/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0384\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0384 - val_loss: 2.7977\n",
            "Epoch 25/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0336\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0351 - val_loss: 2.5930\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9133\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9297 - val_loss: 2.5120\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9302\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9295 - val_loss: 2.6374\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9440\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9432 - val_loss: 2.7676\n",
            "Epoch 29/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8903\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8948 - val_loss: 2.5524\n",
            "Epoch 30/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9213\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9089 - val_loss: 2.6374\n",
            "Epoch 31/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9439\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9416 - val_loss: 2.6343\n",
            "Epoch 32/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9125\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.9203 - val_loss: 2.6296\n",
            "Epoch 33/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8715\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8674 - val_loss: 2.6122\n",
            "Epoch 34/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8305\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8288 - val_loss: 2.5070\n",
            "Epoch 35/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8711\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8711 - val_loss: 2.5840\n",
            "Epoch 36/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8581\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8654 - val_loss: 2.5621\n",
            "Epoch 37/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9027\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9026 - val_loss: 2.5368\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 3.0077\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 15ms/step - loss: 2.9727 - val_loss: 2.7591\n",
            "Epoch 2/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.7437\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7331 - val_loss: 2.5178\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.5600\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5600 - val_loss: 2.6210\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5024\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5101 - val_loss: 2.7380\n",
            "Epoch 5/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4254\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4313 - val_loss: 2.6353\n",
            "Epoch 6/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3877\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4093 - val_loss: 2.5981\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3908\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3892 - val_loss: 2.4487\n",
            "Epoch 8/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3587\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3583 - val_loss: 2.6555\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3118\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3156 - val_loss: 2.5682\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3152\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3196 - val_loss: 2.3533\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2949\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2921 - val_loss: 2.4460\n",
            "Epoch 12/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3156\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2954 - val_loss: 2.5323\n",
            "Epoch 13/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2121\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2272 - val_loss: 2.6233\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2126\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2126 - val_loss: 2.6269\n",
            "Epoch 15/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1689\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1541 - val_loss: 2.5833\n",
            "Epoch 16/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1693\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1676 - val_loss: 2.6117\n",
            "Epoch 17/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1130\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1145 - val_loss: 2.5831\n",
            "Epoch 18/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1064\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1080 - val_loss: 2.5213\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0721\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0725 - val_loss: 2.6027\n",
            "Epoch 20/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0707\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0744 - val_loss: 2.4333\n",
            "Epoch 21/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0416\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0416 - val_loss: 2.5527\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0295\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0355 - val_loss: 2.5174\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0548\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0548 - val_loss: 2.5538\n",
            "Epoch 24/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0013\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0062 - val_loss: 2.4953\n",
            "Epoch 25/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9944\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9900 - val_loss: 2.4094\n",
            "Epoch 26/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0168\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0138 - val_loss: 2.4908\n",
            "Epoch 27/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9763\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9743 - val_loss: 2.6421\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9584\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9563 - val_loss: 2.4668\n",
            "Epoch 29/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9505\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9444 - val_loss: 2.4802\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9176\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.9184 - val_loss: 2.4803\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9239\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9239 - val_loss: 2.5258\n",
            "Epoch 32/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8833\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8909 - val_loss: 2.4036\n",
            "Epoch 33/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8891\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8862 - val_loss: 2.4653\n",
            "Epoch 34/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8969\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8923 - val_loss: 2.5577\n",
            "Epoch 35/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8967\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9061 - val_loss: 2.4377\n",
            "Epoch 36/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8799\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8822 - val_loss: 2.6094\n",
            "Epoch 37/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8576\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8622 - val_loss: 2.4069\n",
            "Epoch 38/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8803\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8781 - val_loss: 2.5672\n",
            "Epoch 39/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8941\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8920 - val_loss: 2.4881\n",
            "Epoch 40/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8385\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8427 - val_loss: 2.5015\n",
            "Epoch 1/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 2.7250\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.7097 - val_loss: 2.3613\n",
            "Epoch 2/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.7021\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7021 - val_loss: 2.6656\n",
            "Epoch 3/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.5019\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5113 - val_loss: 2.2935\n",
            "Epoch 4/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.5643\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5647 - val_loss: 2.4980\n",
            "Epoch 5/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4177\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4185 - val_loss: 2.3582\n",
            "Epoch 6/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4596\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4566 - val_loss: 2.4104\n",
            "Epoch 7/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4254\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4211 - val_loss: 2.3595\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4081\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4112 - val_loss: 2.4524\n",
            "Epoch 9/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3284\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3261 - val_loss: 2.4065\n",
            "Epoch 10/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3296\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3190 - val_loss: 2.4799\n",
            "Epoch 11/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2785\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2877 - val_loss: 2.6181\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2751\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2742 - val_loss: 2.4192\n",
            "Epoch 13/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2337\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2323 - val_loss: 2.4785\n",
            "Epoch 14/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2162\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2187 - val_loss: 2.6113\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2239\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2216 - val_loss: 2.3534\n",
            "Epoch 16/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2505\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2247 - val_loss: 2.6704\n",
            "Epoch 17/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1468\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1516 - val_loss: 2.5579\n",
            "Epoch 18/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.1464\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1505 - val_loss: 2.6525\n",
            "Epoch 19/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1024\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0993 - val_loss: 2.6066\n",
            "Epoch 20/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0825\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0825 - val_loss: 2.6315\n",
            "Epoch 21/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1067\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1059 - val_loss: 2.7128\n",
            "Epoch 22/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0670\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0599 - val_loss: 2.5447\n",
            "Epoch 23/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9968\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0049 - val_loss: 2.6039\n",
            "Epoch 24/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0351\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0413 - val_loss: 2.5938\n",
            "Epoch 25/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9910\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9929 - val_loss: 2.6499\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9951\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9900 - val_loss: 2.6273\n",
            "Epoch 27/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9908\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9925 - val_loss: 2.6558\n",
            "Epoch 28/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9905\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9852 - val_loss: 2.5702\n",
            "Epoch 29/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9484\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9516 - val_loss: 2.5426\n",
            "Epoch 30/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9379\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9359 - val_loss: 2.4941\n",
            "Epoch 31/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9373\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9373 - val_loss: 2.5971\n",
            "Epoch 32/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9123\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9190 - val_loss: 2.6000\n",
            "Epoch 33/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9527\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9504 - val_loss: 2.5011\n",
            "Epoch 1/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2.9373\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 16ms/step - loss: 2.9204 - val_loss: 2.1228\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.9279\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.9234 - val_loss: 2.4142\n",
            "Epoch 3/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.6587\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6367 - val_loss: 2.3321\n",
            "Epoch 4/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.5213\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5176 - val_loss: 2.7228\n",
            "Epoch 5/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.4300\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4362 - val_loss: 2.6355\n",
            "Epoch 6/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.4307\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4265 - val_loss: 2.5631\n",
            "Epoch 7/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.4003\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.4010 - val_loss: 2.5855\n",
            "Epoch 8/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3912\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3912 - val_loss: 2.6641\n",
            "Epoch 9/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3712\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3703 - val_loss: 2.6988\n",
            "Epoch 10/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3532\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.3670 - val_loss: 2.8147\n",
            "Epoch 11/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.3379\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3348 - val_loss: 2.4344\n",
            "Epoch 12/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2445\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2517 - val_loss: 2.8078\n",
            "Epoch 13/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.2692\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2596 - val_loss: 2.7266\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.2144\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2349 - val_loss: 2.6890\n",
            "Epoch 15/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2157\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2158 - val_loss: 2.4983\n",
            "Epoch 16/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1638\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1884 - val_loss: 2.3353\n",
            "Epoch 17/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1584\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1559 - val_loss: 2.4288\n",
            "Epoch 18/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1592\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1592 - val_loss: 2.4534\n",
            "Epoch 19/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.1044\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1033 - val_loss: 2.4442\n",
            "Epoch 20/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0755\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0708 - val_loss: 2.5714\n",
            "Epoch 21/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0858\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0787 - val_loss: 2.6087\n",
            "Epoch 22/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0367\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0325 - val_loss: 2.5594\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0403\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0403 - val_loss: 2.3964\n",
            "Epoch 24/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0482\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0519 - val_loss: 2.4143\n",
            "Epoch 25/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0323\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0348 - val_loss: 2.4727\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9670\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9777 - val_loss: 2.6558\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9499\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9499 - val_loss: 2.4604\n",
            "Epoch 28/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9785\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9799 - val_loss: 2.4988\n",
            "Epoch 29/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9501\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9615 - val_loss: 2.7189\n",
            "Epoch 30/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9006\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8991 - val_loss: 2.4807\n",
            "Epoch 31/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9362\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9410 - val_loss: 2.6692\n",
            "Epoch 1/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 3.0223\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 3s 16ms/step - loss: 2.9250 - val_loss: 2.5239\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.8110\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7767 - val_loss: 2.5055\n",
            "Epoch 3/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.6271\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6228 - val_loss: 2.6970\n",
            "Epoch 4/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4773\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4773 - val_loss: 2.5297\n",
            "Epoch 5/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.4596\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4501 - val_loss: 2.6284\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3999\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3999 - val_loss: 2.4420\n",
            "Epoch 7/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4301\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4196 - val_loss: 2.3994\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3885\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3893 - val_loss: 2.5016\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3290\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3332 - val_loss: 2.4730\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2912\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.2912 - val_loss: 2.5973\n",
            "Epoch 11/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2255\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2597 - val_loss: 2.4700\n",
            "Epoch 12/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2426\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2391 - val_loss: 2.3903\n",
            "Epoch 13/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.2369\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2341 - val_loss: 2.3988\n",
            "Epoch 14/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2343\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2343 - val_loss: 2.5633\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.1795\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1795 - val_loss: 2.5405\n",
            "Epoch 16/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1914\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1915 - val_loss: 2.6121\n",
            "Epoch 17/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1304\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1335 - val_loss: 2.4505\n",
            "Epoch 18/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1391\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1413 - val_loss: 2.4833\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1091\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1146 - val_loss: 2.6617\n",
            "Epoch 20/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0869\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0961 - val_loss: 2.6379\n",
            "Epoch 21/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0656\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0652 - val_loss: 2.5146\n",
            "Epoch 22/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0616\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0717 - val_loss: 2.7449\n",
            "Epoch 23/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0487\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0418 - val_loss: 2.6535\n",
            "Epoch 24/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.0232\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0501 - val_loss: 2.7510\n",
            "Epoch 25/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0430\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0431 - val_loss: 2.6123\n",
            "Epoch 26/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9852\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9952 - val_loss: 2.5510\n",
            "Epoch 27/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0493\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0493 - val_loss: 2.4328\n",
            "Epoch 28/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9684\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9670 - val_loss: 2.6049\n",
            "Epoch 29/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9671\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9642 - val_loss: 2.6618\n",
            "Epoch 30/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.9369\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9336 - val_loss: 2.6147\n",
            "Epoch 31/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9563\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9547 - val_loss: 2.5667\n",
            "Epoch 32/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9037\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9117 - val_loss: 2.5515\n",
            "Epoch 33/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9380\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9344 - val_loss: 2.7184\n",
            "Epoch 34/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.8619\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8753 - val_loss: 2.4783\n",
            "Epoch 35/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9168\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9145 - val_loss: 2.6243\n",
            "Epoch 36/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.8805\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8805 - val_loss: 2.5079\n",
            "Epoch 37/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.8686\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8688 - val_loss: 2.4265\n",
            "Epoch 38/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.8766\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8815 - val_loss: 2.6447\n",
            "Epoch 39/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8654\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8598 - val_loss: 2.5788\n",
            "Epoch 40/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8775\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8782 - val_loss: 2.5493\n",
            "Epoch 41/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8528\n",
            "Epoch 00041: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8583 - val_loss: 2.6454\n",
            "Epoch 42/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8541\n",
            "Epoch 00042: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8595 - val_loss: 2.7261\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 2.6269\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 2s 15ms/step - loss: 2.6269 - val_loss: 2.5631\n",
            "Epoch 2/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.6704\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.6690 - val_loss: 2.5787\n",
            "Epoch 3/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.5921\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.5757 - val_loss: 2.4067\n",
            "Epoch 4/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.5155\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.5155 - val_loss: 2.2389\n",
            "Epoch 5/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4521\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4556 - val_loss: 2.4261\n",
            "Epoch 6/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4259\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4259 - val_loss: 2.2837\n",
            "Epoch 7/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3972\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4057 - val_loss: 2.3053\n",
            "Epoch 8/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3586\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3516 - val_loss: 2.3926\n",
            "Epoch 9/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3644\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3559 - val_loss: 2.4435\n",
            "Epoch 10/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3660\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3660 - val_loss: 2.5692\n",
            "Epoch 11/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2931\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2959 - val_loss: 2.2553\n",
            "Epoch 12/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.2800\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.2780 - val_loss: 2.3887\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2304\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2304 - val_loss: 2.6615\n",
            "Epoch 14/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 1.2302\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2536 - val_loss: 2.5891\n",
            "Epoch 15/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2148\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2162 - val_loss: 2.4050\n",
            "Epoch 16/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.1638\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1817 - val_loss: 2.5928\n",
            "Epoch 17/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1949\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1842 - val_loss: 2.5391\n",
            "Epoch 18/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1935\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1916 - val_loss: 2.5755\n",
            "Epoch 19/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.1300\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.1275 - val_loss: 2.6012\n",
            "Epoch 20/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.0578\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0750 - val_loss: 2.5366\n",
            "Epoch 21/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0874\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0817 - val_loss: 2.6493\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0643\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0643 - val_loss: 2.5477\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0416\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0416 - val_loss: 2.5778\n",
            "Epoch 24/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0158\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.0176 - val_loss: 2.5745\n",
            "Epoch 25/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.0570\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0557 - val_loss: 2.5749\n",
            "Epoch 26/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0142\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0140 - val_loss: 2.6824\n",
            "Epoch 27/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9564\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9588 - val_loss: 2.5908\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9512\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.9512 - val_loss: 2.4564\n",
            "Epoch 29/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9443\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9619 - val_loss: 2.6101\n",
            "Epoch 30/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9141\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9118 - val_loss: 2.7043\n",
            "Epoch 31/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9338\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9470 - val_loss: 2.6183\n",
            "Epoch 32/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9148\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9082 - val_loss: 2.6369\n",
            "Epoch 33/1000\n",
            "39/45 [=========================>....] - ETA: 0s - loss: 0.9392\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9454 - val_loss: 2.7661\n",
            "Epoch 34/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.9310\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9277 - val_loss: 2.6381\n",
            "Epoch 1/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 2.9831\n",
            "Epoch 00001: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 2.9831 - val_loss: 2.5151\n",
            "Epoch 2/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.8024\n",
            "Epoch 00002: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.7843 - val_loss: 2.3827\n",
            "Epoch 3/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.4967\n",
            "Epoch 00003: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4967 - val_loss: 2.3586\n",
            "Epoch 4/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.4659\n",
            "Epoch 00004: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4636 - val_loss: 2.4369\n",
            "Epoch 5/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.4620\n",
            "Epoch 00005: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.4650 - val_loss: 2.6274\n",
            "Epoch 6/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.3955\n",
            "Epoch 00006: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 1.3958 - val_loss: 2.4982\n",
            "Epoch 7/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3649\n",
            "Epoch 00007: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.3622 - val_loss: 2.2900\n",
            "Epoch 8/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.3262\n",
            "Epoch 00008: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3316 - val_loss: 2.5628\n",
            "Epoch 9/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.3377\n",
            "Epoch 00009: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3348 - val_loss: 2.7504\n",
            "Epoch 10/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 1.3056\n",
            "Epoch 00010: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3028 - val_loss: 2.2734\n",
            "Epoch 11/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.3016\n",
            "Epoch 00011: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.3016 - val_loss: 2.6836\n",
            "Epoch 12/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.2546\n",
            "Epoch 00012: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2567 - val_loss: 2.4897\n",
            "Epoch 13/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2228\n",
            "Epoch 00013: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.2228 - val_loss: 2.4960\n",
            "Epoch 14/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1932\n",
            "Epoch 00014: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1856 - val_loss: 2.5228\n",
            "Epoch 15/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.2081\n",
            "Epoch 00015: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.2081 - val_loss: 2.5335\n",
            "Epoch 16/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.1402\n",
            "Epoch 00016: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1480 - val_loss: 2.5426\n",
            "Epoch 17/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 1.1386\n",
            "Epoch 00017: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 1.1413 - val_loss: 2.5200\n",
            "Epoch 18/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0986\n",
            "Epoch 00018: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.1014 - val_loss: 2.4995\n",
            "Epoch 19/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0658\n",
            "Epoch 00019: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0667 - val_loss: 2.4458\n",
            "Epoch 20/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 1.0917\n",
            "Epoch 00020: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0916 - val_loss: 2.3882\n",
            "Epoch 21/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 1.0614\n",
            "Epoch 00021: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0639 - val_loss: 2.5782\n",
            "Epoch 22/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0155\n",
            "Epoch 00022: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0155 - val_loss: 2.6412\n",
            "Epoch 23/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 1.0245\n",
            "Epoch 00023: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0245 - val_loss: 2.5365\n",
            "Epoch 24/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9593\n",
            "Epoch 00024: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9584 - val_loss: 2.4533\n",
            "Epoch 25/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 1.0005\n",
            "Epoch 00025: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 1.0026 - val_loss: 2.4902\n",
            "Epoch 26/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9828\n",
            "Epoch 00026: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9805 - val_loss: 2.4653\n",
            "Epoch 27/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9529\n",
            "Epoch 00027: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9528 - val_loss: 2.4530\n",
            "Epoch 28/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9269\n",
            "Epoch 00028: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9269 - val_loss: 2.5777\n",
            "Epoch 29/1000\n",
            "45/45 [==============================] - ETA: 0s - loss: 0.9600\n",
            "Epoch 00029: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9600 - val_loss: 2.4639\n",
            "Epoch 30/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9105\n",
            "Epoch 00030: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9132 - val_loss: 2.5634\n",
            "Epoch 31/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.9039\n",
            "Epoch 00031: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9015 - val_loss: 2.4141\n",
            "Epoch 32/1000\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 0.9065\n",
            "Epoch 00032: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.9053 - val_loss: 2.4059\n",
            "Epoch 33/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8943\n",
            "Epoch 00033: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8940 - val_loss: 2.5594\n",
            "Epoch 34/1000\n",
            "41/45 [==========================>...] - ETA: 0s - loss: 0.9037\n",
            "Epoch 00034: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8927 - val_loss: 2.5063\n",
            "Epoch 35/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8621\n",
            "Epoch 00035: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.8601 - val_loss: 2.5150\n",
            "Epoch 36/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8256\n",
            "Epoch 00036: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8331 - val_loss: 2.5457\n",
            "Epoch 37/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8523\n",
            "Epoch 00037: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8525 - val_loss: 2.4675\n",
            "Epoch 38/1000\n",
            "42/45 [===========================>..] - ETA: 0s - loss: 0.8227\n",
            "Epoch 00038: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.8184 - val_loss: 2.5321\n",
            "Epoch 39/1000\n",
            "44/45 [============================>.] - ETA: 0s - loss: 0.8330\n",
            "Epoch 00039: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8332 - val_loss: 2.5802\n",
            "Epoch 40/1000\n",
            "40/45 [=========================>....] - ETA: 0s - loss: 0.8028\n",
            "Epoch 00040: val_loss did not improve from 1.93487\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8005 - val_loss: 2.4647\n",
            "Mean RMSE: 1.570 (0.127)\n",
            "Mean MSE: 2.509 (0.491)\n",
            "Mean MAE: 1.145 (0.081)\n",
            "Mean R2: 1.145 (0.081)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3_DwEyw78y6"
      },
      "source": [
        "## **Explainable AI**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drug_merged = pd.read_csv(\"/content/drugmerged_final.csv\")"
      ],
      "metadata": {
        "id": "MNb3Cv_jutvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "Y = drug_merged['LN_IC50']  \n",
        "X = drug_merged.iloc[:,5:505]\n",
        "\n",
        "# Split the data into train and test data:\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
        "# Build the model with the random forest regression algorithm:\n",
        "\n",
        "model = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=10)\n",
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTmvnbPzpqJ2",
        "outputId": "cfeee1f4-3509-4b06-d509-737ebc74dc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(max_depth=6, n_estimators=10, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "shap_values = shap.TreeExplainer(model).shap_values(X_train)\n",
        "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "o9J4bA6HztUd",
        "outputId": "528c9758-c0b6-44fe-e13e-4b37966aecd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x684 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}